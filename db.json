{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/raytaylorism/source/favicon.png","path":"favicon.png","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/js/prettify.js","path":"js/prettify.js","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/js/jquery.min.js","path":"js/jquery.min.js","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/lib/font-awesome.min.css","path":"css/lib/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/lib/prettify-tomorrow-night-eighties.css","path":"css/lib/prettify-tomorrow-night-eighties.css","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/alipay-rewardcode.jpg","path":"css/images/alipay-rewardcode.jpg","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/avatar.jpg","path":"css/images/avatar.jpg","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/side-user-cover.jpg","path":"css/images/side-user-cover.jpg","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/js/materialize.min.js","path":"js/materialize.min.js","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/lib/materialize.min.css","path":"css/lib/materialize.min.css","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/iclass.png","path":"css/images/iclass.png","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/pythoner.png","path":"css/images/pythoner.png","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/wetchat-rewardcode.jpg","path":"css/images/wetchat-rewardcode.jpg","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Bold.eot","path":"css/font/roboto/Roboto-Bold.eot","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Light.eot","path":"css/font/roboto/Roboto-Light.eot","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Bold.woff2","path":"css/font/roboto/Roboto-Bold.woff2","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Bold.woff","path":"css/font/roboto/Roboto-Bold.woff","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Light.woff","path":"css/font/roboto/Roboto-Light.woff","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Light.woff2","path":"css/font/roboto/Roboto-Light.woff2","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Medium.eot","path":"css/font/roboto/Roboto-Medium.eot","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Medium.woff","path":"css/font/roboto/Roboto-Medium.woff","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Medium.woff2","path":"css/font/roboto/Roboto-Medium.woff2","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Regular.eot","path":"css/font/roboto/Roboto-Regular.eot","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Regular.woff","path":"css/font/roboto/Roboto-Regular.woff","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Regular.woff2","path":"css/font/roboto/Roboto-Regular.woff2","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/font-awesome/FontAwesome.otf","path":"css/font/font-awesome/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.eot","path":"css/font/font-awesome/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.woff","path":"css/font/font-awesome/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.woff2","path":"css/font/font-awesome/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Bold.ttf","path":"css/font/roboto/Roboto-Bold.ttf","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Light.ttf","path":"css/font/roboto/Roboto-Light.ttf","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Medium.ttf","path":"css/font/roboto/Roboto-Medium.ttf","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Regular.ttf","path":"css/font/roboto/Roboto-Regular.ttf","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/histequa.png","path":"css/images/histequa.png","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.ttf","path":"css/font/font-awesome/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/fantasy.jpg","path":"css/images/fantasy.jpg","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.svg","path":"css/font/font-awesome/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/game.png","path":"css/images/game.png","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/img-cov.png","path":"css/images/img-cov.png","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/wall.png","path":"css/images/wall.png","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/coloreggs.jpg","path":"css/images/coloreggs.jpg","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/rain.png","path":"css/images/rain.png","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/phone.png","path":"css/images/phone.png","modified":1,"renderable":1}],"Cache":[{"_id":"themes/raytaylorism/Gruntfile.js","hash":"f69b2e716f955c9d5a23ca1b75394098c1494858","modified":1521800509193},{"_id":"themes/raytaylorism/.gitignore","hash":"cda50c55bb8864e0d96101140b62f880f690da5e","modified":1521800509193},{"_id":"themes/raytaylorism/_config.yml","hash":"c24f24a0b72476b40b6addf0bdb2893fcb8facb9","modified":1521800509194},{"_id":"themes/raytaylorism/README.md","hash":"a195db5b7c40e99d4da1fdf252e78c496f51f48e","modified":1521800509194},{"_id":"themes/raytaylorism/LICENSE","hash":"115cd028ae511ac9e3d30eb4933da38136a68513","modified":1521800509193},{"_id":"themes/raytaylorism/log.md","hash":"99d57a50f8f328d1a313b47bb636d0dc5656d813","modified":1521800509211},{"_id":"source/_data/about.json","hash":"488f91afc073615ca76f9c3cbb33271a4655a7cd","modified":1521800509156},{"_id":"source/_data/hint.json","hash":"7433c56bdcc76fab584670a80442200d9b605f5e","modified":1521800509156},{"_id":"source/_data/link.json","hash":"fb7c0deefc9952cf7819234fadb2ea751777e609","modified":1521800509156},{"_id":"source/_data/slider.json","hash":"4f1c5509b20900aff3e6d69c8f69c6feef2a5ce4","modified":1521800509157},{"_id":"source/_data/reading.json","hash":"4b91b2b0d7d06d3cd3bf2fbe59c51884d6304b13","modified":1521800509157},{"_id":"source/_posts/Hexo多电脑同步写作.md","hash":"03307813d58aa842e930a62b5e8557bfbbe856d9","modified":1521800509157},{"_id":"source/_posts/Mnist手写数字体识别-tensorflow.md","hash":"a191f3b253a4f1faa9ea1dfb1a4241f5211387aa","modified":1521800509158},{"_id":"source/_posts/关于k阶矩的理解.md","hash":"5381d5d5739318fd2c871d308d16a050ba37aae5","modified":1521800509158},{"_id":"source/_posts/直方图均衡化图片.md","hash":"79577c6c8a0c3b080518c162294fc3797251e20f","modified":1521800509159},{"_id":"source/_posts/图像与常用算子进行卷积运算.md","hash":"ab7162391af3dc09d8326384d9aeb05a7381bb54","modified":1521800509159},{"_id":"source/about/index.md","hash":"fa416d307e7d2e4f0162c58a0d6ffe8a40e28ee8","modified":1521800509160},{"_id":"source/reading/index.md","hash":"8f8179d7dac09b88bfc085465350a753e9eebded","modified":1521800509160},{"_id":"themes/raytaylorism/_data/about.json","hash":"488f91afc073615ca76f9c3cbb33271a4655a7cd","modified":1521800509194},{"_id":"themes/raytaylorism/_data/hint.json","hash":"7433c56bdcc76fab584670a80442200d9b605f5e","modified":1521800509195},{"_id":"themes/raytaylorism/_data/link.json","hash":"fb7c0deefc9952cf7819234fadb2ea751777e609","modified":1521800509195},{"_id":"themes/raytaylorism/_data/reading.json","hash":"4b91b2b0d7d06d3cd3bf2fbe59c51884d6304b13","modified":1521800509196},{"_id":"themes/raytaylorism/_data/slider.json","hash":"4f1c5509b20900aff3e6d69c8f69c6feef2a5ce4","modified":1521800509196},{"_id":"themes/raytaylorism/languages/en.yml","hash":"ac672903f9c45f244db56e9408b4546d026fee8f","modified":1521800509197},{"_id":"themes/raytaylorism/languages/zh-CN.yml","hash":"b2211c4d88a3f319316f6ecbad748a0ae4b4b91b","modified":1521800509198},{"_id":"themes/raytaylorism/languages/zh-TW.yml","hash":"ae281c898cea81f4c897c0a69c45e2ce6a4314a6","modified":1521800509198},{"_id":"themes/raytaylorism/layout/about.ejs","hash":"599b3bb334b3f88b918e67f7a709287b8effee6d","modified":1521800509209},{"_id":"themes/raytaylorism/layout/index.ejs","hash":"50c1e7dab5a065fd10dd3a28fdffa5e3d342de82","modified":1521800509209},{"_id":"themes/raytaylorism/layout/archive.ejs","hash":"0a21af8903e95c6d8bb7554b089ac219e8708ad7","modified":1521800509209},{"_id":"themes/raytaylorism/layout/layout.ejs","hash":"43beb54ac81519cf5e88a3a1494649beeb856066","modified":1521800509209},{"_id":"themes/raytaylorism/layout/page.ejs","hash":"90441f114859ce63ef7c7d93d668dbe5939995c2","modified":1521800509210},{"_id":"themes/raytaylorism/layout/post.ejs","hash":"8e550fd95ef761909294ed3a4aa428ff0509fbf0","modified":1521800509210},{"_id":"themes/raytaylorism/layout/reading.ejs","hash":"3b2f77f0a154d2f6966b684eee69f26709968936","modified":1521800509211},{"_id":"themes/raytaylorism/layout/tag.ejs","hash":"42ecab14917abd40c0a38e6ab629f089352a24b1","modified":1521800509211},{"_id":"themes/raytaylorism/source/favicon.png","hash":"f28180f9a5026132b36b4a786c0577e68ea1fe55","modified":1521800509300},{"_id":"themes/raytaylorism/layout/_partial/archive.ejs","hash":"68c7db951ffb5323d49d4de74e3b0de7f70fb4c3","modified":1521800509199},{"_id":"themes/raytaylorism/layout/_partial/after_footer.ejs","hash":"9fafc2cb14cbca89e48335d64ab058b5f256a36e","modified":1521800509198},{"_id":"themes/raytaylorism/layout/_partial/archive_title.ejs","hash":"dfc6c670702e64abce5fd87e3e2ea43c966ace32","modified":1521800509199},{"_id":"themes/raytaylorism/layout/_partial/article.ejs","hash":"8269f333b405412510454a2a2dd4ef75a19d7465","modified":1521800509199},{"_id":"themes/raytaylorism/layout/_partial/construction.ejs","hash":"21190b5a0d567ed4ea5d5289459690b72c1452f0","modified":1521800509200},{"_id":"themes/raytaylorism/layout/_partial/feature_guide.ejs","hash":"7aefb6bdc65d1e6113cb83190fcd2f29af2c9125","modified":1521800509200},{"_id":"themes/raytaylorism/layout/_partial/float.ejs","hash":"a5594e23bff2047156b647fbdd0ef8247ee4ec65","modified":1521800509200},{"_id":"themes/raytaylorism/layout/_partial/footer.ejs","hash":"7d8ade0e17012bf0006d234a8e8efd633d2658f2","modified":1521800509200},{"_id":"themes/raytaylorism/layout/_partial/head.ejs","hash":"7ceea72401426588cd7778f92585ab9487b463da","modified":1521800509201},{"_id":"themes/raytaylorism/layout/_partial/header.ejs","hash":"0616dd744262dd4cc98cd1cabe959643c845141f","modified":1521800509201},{"_id":"themes/raytaylorism/layout/_partial/menu_drawer.ejs","hash":"028ecbf59089cc4d1907a2d91d8da937f92d321c","modified":1521800509201},{"_id":"themes/raytaylorism/layout/_partial/pagenav.ejs","hash":"e7ada8faaee878ea4dde267d1b420bb45421670d","modified":1521800509201},{"_id":"themes/raytaylorism/layout/_partial/pagination.ejs","hash":"00de7746cf4ef8c4b67a72e825e5ff236f9d5814","modified":1521800509202},{"_id":"themes/raytaylorism/layout/_partial/search.ejs","hash":"0eca40de0d39c1ae52040fcb8c9d7f79afce35dc","modified":1521800509207},{"_id":"themes/raytaylorism/layout/_partial/side_nav.ejs","hash":"c69c45de069c348bf3906f1bd941920887a85c98","modified":1521800509207},{"_id":"themes/raytaylorism/layout/_partial/simple_article.ejs","hash":"6480e101b2f29dddd661410c56516c767d88b79f","modified":1521800509207},{"_id":"themes/raytaylorism/layout/_partial/slider.ejs","hash":"bb7b53f6ca9c852808d955fb074f88112e51ea59","modified":1521800509207},{"_id":"themes/raytaylorism/layout/_widget/blogroll.ejs","hash":"1a6808fa62906e7fb1fac3e16208fa6b1fc8d0ea","modified":1521800509208},{"_id":"themes/raytaylorism/layout/_widget/category.ejs","hash":"95292eb643be63d98f08e28f759c9b01bbfcb9b8","modified":1521800509208},{"_id":"themes/raytaylorism/layout/_widget/recent_posts.ejs","hash":"935bfacce10a726eed6cd82fe39d2c6f9cce9e2a","modified":1521800509208},{"_id":"themes/raytaylorism/layout/_widget/tag.ejs","hash":"90e0ba4412285903420ee3b43125a56743edf0c6","modified":1521800509208},{"_id":"themes/raytaylorism/layout/_widget/tagcloud.ejs","hash":"f256f028c247bdcb7927351df89f2284c64b7b6c","modified":1521800509209},{"_id":"themes/raytaylorism/_md/about/index.md","hash":"fa416d307e7d2e4f0162c58a0d6ffe8a40e28ee8","modified":1521800509197},{"_id":"themes/raytaylorism/_md/reading/index.md","hash":"ab4ae4fad36f371f60b49973797a115423a784d4","modified":1521800509197},{"_id":"themes/raytaylorism/source/css/style.styl","hash":"a05bcd2543b7bdcd3f725db6d053cd76ccf154be","modified":1521800509300},{"_id":"themes/raytaylorism/source/js/prettify.js","hash":"d592e6f771c2955cea3764d819221b91bc343961","modified":1521800509303},{"_id":"themes/raytaylorism/source/js/jquery.min.js","hash":"f694238d616f579a0690001f37984af430c19963","modified":1521800509301},{"_id":"themes/raytaylorism/layout/_partial/plugin/analytics.ejs","hash":"b7dbd8342866929e683e9b013caa7324547ff704","modified":1521800509202},{"_id":"themes/raytaylorism/layout/_partial/plugin/comment.ejs","hash":"9d8e3cda9e11cfcb199da90e79baf11e71c2cfec","modified":1521800509202},{"_id":"themes/raytaylorism/layout/_partial/plugin/google_code_prettify.ejs","hash":"336f01048440f0c9f7b75f24aafcc3a1ffefd9a0","modified":1521800509202},{"_id":"themes/raytaylorism/layout/_partial/plugin/mathjax.ejs","hash":"6f6b85a5876ae150d3e5f08e384aff68652c0335","modified":1521800509203},{"_id":"themes/raytaylorism/layout/_partial/plugin/main_javascript.ejs","hash":"6629eec982aa789767b83e80af12fa40189ac344","modified":1521800509203},{"_id":"themes/raytaylorism/layout/_partial/plugin/noscript.ejs","hash":"182650c8be93b093997ac4d5fe14af2f835b98d9","modified":1521800509204},{"_id":"themes/raytaylorism/layout/_partial/plugin/page_stat.ejs","hash":"9b667cbe0e8031997da065b667d12b0c944a9dad","modified":1521800509204},{"_id":"themes/raytaylorism/layout/_partial/plugin/reward.ejs","hash":"284ab1d5cb4f43eb23b6d7a8aba2477b34abdc00","modified":1521800509204},{"_id":"themes/raytaylorism/layout/_partial/post/category.ejs","hash":"e17f452079201bd2a5a37bc76b51b132afd04faa","modified":1521800509204},{"_id":"themes/raytaylorism/layout/_partial/post/gallery.ejs","hash":"bd2285802766572736663e61852eb49f6acc744f","modified":1521800509205},{"_id":"themes/raytaylorism/layout/_partial/post/livere.ejs","hash":"bfad3e53acffd56b950017ed1754c7fdb8ec1486","modified":1521800509205},{"_id":"themes/raytaylorism/layout/_partial/post/readtimes.ejs","hash":"c829d0598f9906f663a8ace1c86f2aa6024d642c","modified":1521800509205},{"_id":"themes/raytaylorism/layout/_partial/post/prevnext.ejs","hash":"6556eea4fb351639006c16e9831fd72ab46076ba","modified":1521800509205},{"_id":"themes/raytaylorism/layout/_partial/post/tablecontents.ejs","hash":"585ea42410648f193184931864a64b41635af956","modified":1521800509206},{"_id":"themes/raytaylorism/layout/_partial/post/tag.ejs","hash":"0f84c1aded9ba1887566d34e7f0d696c015295f0","modified":1521800509206},{"_id":"themes/raytaylorism/layout/_partial/post/time.ejs","hash":"42210d6b5a132f5c18352dcff2983d3fdbe26956","modified":1521800509206},{"_id":"themes/raytaylorism/layout/_partial/post/title.ejs","hash":"f0733a134b375172a2cec830d7d09bdba33891fe","modified":1521800509206},{"_id":"themes/raytaylorism/source/css/_base/icons.css","hash":"ab167f1694ffe10c3c51d18a633efd41be121555","modified":1521800509212},{"_id":"themes/raytaylorism/source/css/_base/lib_customize.styl","hash":"5f25b295a3ad99991952f864573c0f1ccc6a1591","modified":1521800509212},{"_id":"themes/raytaylorism/source/css/_base/variable.styl","hash":"ce4e056d1bbfb80734d98a6898950e7c0136edf4","modified":1521800509213},{"_id":"themes/raytaylorism/source/css/_base/layout.styl","hash":"b2f718418de61946504a3f8bf28b75be165913a7","modified":1521800509212},{"_id":"themes/raytaylorism/source/css/_partial/about.styl","hash":"def183d6908ebcbd59341b09e9f7e06dc277b9ca","modified":1521800509214},{"_id":"themes/raytaylorism/source/css/_partial/archive.styl","hash":"4d48566e9f72b8eac8875b6985885418f56fbafa","modified":1521800509214},{"_id":"themes/raytaylorism/source/css/_partial/article.styl","hash":"293e38a8ab9aee346cc8e52421f1519c5a46a667","modified":1521800509214},{"_id":"themes/raytaylorism/source/css/_partial/comment.styl","hash":"590f1386581181ab588be06e4189861f5a209467","modified":1521800509215},{"_id":"themes/raytaylorism/source/css/_partial/footer.styl","hash":"7f2c22ebc3fe551496625e9453017e512d670aea","modified":1521800509215},{"_id":"themes/raytaylorism/source/css/_partial/header.styl","hash":"ebfd0155cda8a0876c36595708f02c294a7c82a0","modified":1521800509215},{"_id":"themes/raytaylorism/source/css/_partial/index.styl","hash":"ac83523dd14a1fc1fe55f98c84ed84cb03be864b","modified":1521800509216},{"_id":"themes/raytaylorism/source/css/_partial/link_context.styl","hash":"5b23db4dee53cbbe9eef257f4a542823100fde72","modified":1521800509216},{"_id":"themes/raytaylorism/source/css/_partial/other.styl","hash":"32bf499037a45ad2e0007a9ab3054067adc02506","modified":1521800509216},{"_id":"themes/raytaylorism/source/css/_partial/reading.styl","hash":"f81929fa12212465b02456d0bb3b8263355e3281","modified":1521800509216},{"_id":"themes/raytaylorism/source/css/_partial/search.styl","hash":"f9ca6f5626c795ae73ff7412ff58207b62fd64ac","modified":1521800509217},{"_id":"themes/raytaylorism/source/css/_partial/side_nav.styl","hash":"b239b6b55e87e86d038d6aa821beeb66a9cbaf39","modified":1521800509217},{"_id":"themes/raytaylorism/source/css/_partial/slider.styl","hash":"ad757e74b3500aa774636ebbe5bdcee7e52e5ad7","modified":1521800509217},{"_id":"themes/raytaylorism/source/css/_partial/syntax.styl","hash":"f39e7bb08abcc220f7c57fb413e76f4043ab9c35","modified":1521800509217},{"_id":"themes/raytaylorism/source/css/_partial/tablecontents.styl","hash":"e04fa0e7664065077750a7223ae3390cc84a4c56","modified":1521800509218},{"_id":"themes/raytaylorism/source/css/lib/font-awesome.min.css","hash":"14be7d7ae1894d2cc7c1a8e847df4db42a310b2f","modified":1521800509298},{"_id":"themes/raytaylorism/source/css/lib/prettify-tomorrow-night-eighties.css","hash":"e320b2be926124d30998af0e149b7f06303b8f8b","modified":1521800509300},{"_id":"themes/raytaylorism/source/css/images/alipay-rewardcode.jpg","hash":"7093a60c54438b347cb13d79b7a34c99b0d6a4e3","modified":1521800509235},{"_id":"themes/raytaylorism/source/css/images/avatar.jpg","hash":"ad4c9872fa0b5c143a8778d95437452e2186a2e6","modified":1521800509236},{"_id":"themes/raytaylorism/source/css/images/side-user-cover.jpg","hash":"d8d73a64d6d5af83a27e6af1d4fedef808955ba0","modified":1521800509292},{"_id":"themes/raytaylorism/source/js/materialize.min.js","hash":"04fe8bbc9a3165eb7bfb13b7166306ed671268d8","modified":1521800509302},{"_id":"themes/raytaylorism/source/css/lib/materialize.min.css","hash":"2cdb74e6b61dc8f08352ba61979d3de314fe2af7","modified":1521800509299},{"_id":"themes/raytaylorism/source/css/images/iclass.png","hash":"ee48ed2068acfcd8f3bbc1101134a9a68043ff4b","modified":1521800509261},{"_id":"themes/raytaylorism/source/css/images/pythoner.png","hash":"926f3e215b9b527227303e2a6ec13f3cf0612d5c","modified":1521800509280},{"_id":"themes/raytaylorism/source/css/images/wetchat-rewardcode.jpg","hash":"37f65c6d09fca7a09dd10da6987268daa42203b4","modified":1521800509298},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Bold.eot","hash":"a76cd602f5188b9fbd4ba7443dcb9c064e3dbf10","modified":1521800509224},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Light.eot","hash":"42fe156996197e5eb0c0264c5d1bb3b4681f4595","modified":1521800509227},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Bold.woff2","hash":"933b866d09c2b087707a98dab64b3888865eeb96","modified":1521800509226},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Bold.woff","hash":"ee99cd87a59a9a5d4092c83232bb3eec67547425","modified":1521800509225},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Light.woff","hash":"6300f659be9e834ab263efe2fb3c581d48b1e7b2","modified":1521800509229},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Light.woff2","hash":"bbdc28b887400fcb340b504ec2904993af42a5d7","modified":1521800509229},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Medium.eot","hash":"1517f4b6e1c5d0e5198f937557253aac8fab0416","modified":1521800509229},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Medium.woff","hash":"d45f84922131364989ad6578c7a06b6b4fc22c34","modified":1521800509231},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Medium.woff2","hash":"6cc1b73571af9e827c4e7e91418f476703cd4c4b","modified":1521800509232},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Regular.eot","hash":"77ae3e980ec03863ebe2587a8ef9ddfd06941db0","modified":1521800509232},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Regular.woff","hash":"74734dde8d94e7268170f9b994dedfbdcb5b3a15","modified":1521800509234},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Regular.woff2","hash":"ed1558b0541f5e01ce48c7db1588371b990eec19","modified":1521800509234},{"_id":"themes/raytaylorism/source/css/font/font-awesome/FontAwesome.otf","hash":"42c179eef588854b5ec151bcf6a3f58aa8b79b11","modified":1521800509219},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.eot","hash":"986eed8dca049714e43eeebcb3932741a4bec76d","modified":1521800509220},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.woff","hash":"4a313eb93b959cc4154c684b915b0a31ddb68d84","modified":1521800509223},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.woff2","hash":"638c652d623280a58144f93e7b552c66d1667a11","modified":1521800509223},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Bold.ttf","hash":"47327df0f35e7cd7c8645874897a7449697544ae","modified":1521800509225},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Light.ttf","hash":"e321c183e2b75ee19813892b7bac8d7c411cb88a","modified":1521800509228},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Medium.ttf","hash":"6060ca726b9760b76f7c347dce9d2fa1fe42ec92","modified":1521800509231},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Regular.ttf","hash":"824b5480c977a8166e177e5357d13164ccc45f47","modified":1521800509233},{"_id":"themes/raytaylorism/source/css/images/histequa.png","hash":"89eb9d30577401536f20ab07ae8e5647ce79e867","modified":1521800509261},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.ttf","hash":"6484f1af6b485d5096b71b344e67f4164c33dd1f","modified":1521800509222},{"_id":"themes/raytaylorism/source/css/images/fantasy.jpg","hash":"b4c6b8b34259e01bc78909be257ec2a4230a6684","modified":1521800509255},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.svg","hash":"550ef5c1253c8376f2ead32b654eb58d3c106ca3","modified":1521800509221},{"_id":"themes/raytaylorism/source/css/images/game.png","hash":"ca05a21991384b3fe0eaf3f529b1fbfb09439e10","modified":1521800509259},{"_id":"themes/raytaylorism/source/css/images/img-cov.png","hash":"71f7616a6e54befc3d7019b6e0b85e1bfb7cc784","modified":1521800509268},{"_id":"themes/raytaylorism/source/css/images/wall.png","hash":"d47ce4e9c164c9563cd230767bbc29f29a738981","modified":1521800509296},{"_id":"themes/raytaylorism/source/css/images/coloreggs.jpg","hash":"518341c5e974a98f8bc00b9e5972954071bf645a","modified":1521800509253},{"_id":"themes/raytaylorism/source/css/images/rain.png","hash":"5d382d60591561923d178dd24d89cb1189b193f6","modified":1521800509291},{"_id":"themes/raytaylorism/source/css/images/phone.png","hash":"91a48999c2a264233bc46f209aba35bd9d65ad38","modified":1521800509279}],"Category":[{"name":"技术文章","_id":"cjf3srot70004usu8tr3lo6nc"},{"name":"tensorflow学习","_id":"cjf3srotd0009usu8lmxd6p18"},{"name":"数学基础","_id":"cjf3srotf000busu81tkjy8d2"},{"name":"图像处理","_id":"cjf3srotg000fusu8ag0a1sne"},{"name":"博客搭建","parent":"cjf3srot70004usu8tr3lo6nc","_id":"cjf3sroti000husu8zqq9x8tz"},{"name":"tensorflow-Demo","parent":"cjf3srotd0009usu8lmxd6p18","_id":"cjf3srotl000nusu8p4e8ewtz"},{"name":"随机过程","parent":"cjf3srotf000busu81tkjy8d2","_id":"cjf3srotm000rusu812spzgb6"},{"name":"图像增强","parent":"cjf3srotg000fusu8ag0a1sne","_id":"cjf3srotn000uusu80q81jtuz"}],"Data":[{"_id":"link","data":{"social":{"github":"https://github.com/mic-jasontang"},"extern":{"Github地址":"https://github.com/mic-jasontang"}}},{"_id":"reading","data":{"define":{"readed":"已读","reading":"在读","wanted":"想读"},"contents":{"readed":[{"title":"嫌疑人X的献身","cover":"https://img3.doubanio.com/lpic/s3254244.jpg","review":"百年一遇的数学天才石神，每天唯一的乐趣，便是去固定的便当店买午餐，只为看一眼在便当店做事的邻居靖子。","score":"8.9","doubanLink":"https://book.douban.com/subject/3211779/"},{"title":"Python核心编程（第二版）","cover":"https://img3.doubanio.com/lpic/s3140466.jpg","review":"本书是Python开发者的完全指南——针对 Python 2.5全面升级","score":"7.7","doubanLink":"https://book.douban.com/subject/3112503/"},{"title":"程序员代码面试指南：IT名企算法与数据结构题目最优解","cover":"https://img3.doubanio.com/lpic/s28313721.jpg","review":"这是一本程序员面试宝典！书中对IT名企代码面试各类题目的最优解进行了总结，并提供了相关代码实现。","score":"8.8","doubanLink":"https://book.douban.com/subject/26638586/"},{"title":"机器学习实战","cover":"https://img3.doubanio.com/lpic/s26696371.jpg","review":"全书通过精心编排的实例，切入日常工作任务，摒弃学术化语言，利用高效的可复用Python代码来阐释如何处理统计数据，进行数据分析及可视化。通过各种实例，读者可从中学会机器学习的核心算法，并能将其运用于一些策略性任务中，如分类、预测、推荐。另外，还可用它们来实现一些更高级的功能，如汇总和简化等。","score":"8.2","doubanLink":"https://book.douban.com/subject/24703171/"},{"title":"TensorFlow实战","cover":"https://img3.doubanio.com/lpic/s29343414.jpg","review":"《TensorFlow实战》希望能帮读者快速入门TensorFlow和深度学习，在工业界或者研究中快速地将想法落地为可实践的模型。","score":"7.3","doubanLink":"https://book.douban.com/subject/26974266/"}],"reading":[{"title":"深度学习","cover":"https://img1.doubanio.com/lpic/s29518349.jpg","review":"《深度学习》适合各类读者阅读，包括相关专业的大学生或研究生，以及不具有机器学习或统计背景、但是想要快速补充深度学习知识，以便在实际产品或平台中应用的软件工程师。","score":"8.7","doubanLink":"https://book.douban.com/subject/27087503/"},{"title":"Tensorflow：实战Google深度学习框架","cover":"https://img3.doubanio.com/lpic/s29349250.jpg","review":"《Tensorflow实战》包含了深度学习的入门知识和大量实践经验，是走进这个最新、最火的人工智能领域的首选参考书。","score":"8.2","doubanLink":"https://book.douban.com/subject/26976457/"},{"title":"机器学习","cover":"https://img1.doubanio.com/lpic/s28735609.jpg","review":"本书作为该领域的入门教材，在内容上尽可能涵盖机器学习基础知识的各方面。 为了使尽可能多的读者通过本书对机器学习有所了解, 作者试图尽可能少地使用数学知识. 然而, 少量的概率、统计、代数、优化、逻辑知识似乎不可避免. 因此, 本书更适合大学三年级以上的理工科本科生和研究生, 以及具有类似背景的对机器学 习感兴趣的人士. 为方便读者, 本书附录给出了一些相关数学基础知识简介.","score":"8.7","doubanLink":"https://book.douban.com/subject/26708119/"}],"wanted":[{"title":"OpenCV 3计算机视觉：Python语言实现（原书第2版）","cover":"https://img3.doubanio.com/lpic/s28902360.jpg","review":"本书针对具有一定Python工作经验的程序员以及想要利用OpenCV库研究计算机视觉课题的读者。本书不要求读者具有计算机视觉或OpenCV经验，但要具有编程经验。","score":"7.8","doubanLink":"https://book.douban.com/subject/26816975/"},{"title":"Python计算机视觉编程","cover":"https://img3.doubanio.com/lpic/s27305520.jpg","review":"《python计算机视觉编程》适合的读者是：有一定编程与数学基础，想要了解计算机视觉的基本理论与算法的学生，以及计算机科学、信号处理、物理学、应用数学和统计学、神经生理学、认知科学等领域的研究人员和从业者。","score":"7.5","doubanLink":"https://book.douban.com/subject/25906843/"}]}}},{"_id":"about","data":{"avatar":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/avatar.jpg","name":"tech.radish","tag":"python/Java/ML/CV","desc":"行走在边缘的coder","skills":{"ptyhon":5,"Java":6,"invisible-split-line-1":-1,"ML":4},"projects":[{"name":"合金战争(Java Swing + MySql + Socket)","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/game.png","tags":["Java","游戏开发"],"description":"合金战争是一款使用JavaSwing作为界面，MySQL作为数据库服务器，使用Socket通信的网络版RPG游戏","link_text":"合金战争","link":null},{"name":"iclass智能课堂助手","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/iclass.png","description":"iclass是一款实用SSM框架开发的轻量级课堂辅助教学系统，旨在加强和方便师生之间的交流合作，提高教学效率。拥有web端和安卓端（本人完成web端和安卓后端的开发）","tags":["毕业设计","SSM框架"],"link_text":"Github地址","link":"https://github.com/Mic-JasonTang/iclass"}],"reward":["https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/alipay-rewardcode.jpg","https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/wetchat-rewardcode.jpg"]}},{"_id":"slider","data":[{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/coloreggs.jpg","align":"center","title":"computer vision","subtitle":"whole world","link":"/"},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/fantasy.jpg","align":"left","title":"import tensorflow as tf","subtitle":"sess.run(hello)","link":null},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/pythoner.png","align":"right","title":"import __helloworld__","subtitle":">>> Hello World","link":null}]},{"_id":"hint","data":{"new":{"selector":[".menu-reading"]}}}],"Page":[{"title":"关于","layout":"about","_content":"大家好，我是tech.radish。欢迎来到我的个人技术博客。\n","source":"about/index.md","raw":"title: 关于\nlayout: about\n---\n大家好，我是tech.radish。欢迎来到我的个人技术博客。\n","date":"2018-03-23T10:21:49.160Z","updated":"2018-03-23T10:21:49.160Z","path":"about/index.html","comments":1,"_id":"cjf3srot40001usu8bdrnzbtw","content":"<p>大家好，我是tech.radish。欢迎来到我的个人技术博客。</p>\n","site":{"data":{"link":{"social":{"github":"https://github.com/mic-jasontang"},"extern":{"Github地址":"https://github.com/mic-jasontang"}},"reading":{"define":{"readed":"已读","reading":"在读","wanted":"想读"},"contents":{"readed":[{"title":"嫌疑人X的献身","cover":"https://img3.doubanio.com/lpic/s3254244.jpg","review":"百年一遇的数学天才石神，每天唯一的乐趣，便是去固定的便当店买午餐，只为看一眼在便当店做事的邻居靖子。","score":"8.9","doubanLink":"https://book.douban.com/subject/3211779/"},{"title":"Python核心编程（第二版）","cover":"https://img3.doubanio.com/lpic/s3140466.jpg","review":"本书是Python开发者的完全指南——针对 Python 2.5全面升级","score":"7.7","doubanLink":"https://book.douban.com/subject/3112503/"},{"title":"程序员代码面试指南：IT名企算法与数据结构题目最优解","cover":"https://img3.doubanio.com/lpic/s28313721.jpg","review":"这是一本程序员面试宝典！书中对IT名企代码面试各类题目的最优解进行了总结，并提供了相关代码实现。","score":"8.8","doubanLink":"https://book.douban.com/subject/26638586/"},{"title":"机器学习实战","cover":"https://img3.doubanio.com/lpic/s26696371.jpg","review":"全书通过精心编排的实例，切入日常工作任务，摒弃学术化语言，利用高效的可复用Python代码来阐释如何处理统计数据，进行数据分析及可视化。通过各种实例，读者可从中学会机器学习的核心算法，并能将其运用于一些策略性任务中，如分类、预测、推荐。另外，还可用它们来实现一些更高级的功能，如汇总和简化等。","score":"8.2","doubanLink":"https://book.douban.com/subject/24703171/"},{"title":"TensorFlow实战","cover":"https://img3.doubanio.com/lpic/s29343414.jpg","review":"《TensorFlow实战》希望能帮读者快速入门TensorFlow和深度学习，在工业界或者研究中快速地将想法落地为可实践的模型。","score":"7.3","doubanLink":"https://book.douban.com/subject/26974266/"}],"reading":[{"title":"深度学习","cover":"https://img1.doubanio.com/lpic/s29518349.jpg","review":"《深度学习》适合各类读者阅读，包括相关专业的大学生或研究生，以及不具有机器学习或统计背景、但是想要快速补充深度学习知识，以便在实际产品或平台中应用的软件工程师。","score":"8.7","doubanLink":"https://book.douban.com/subject/27087503/"},{"title":"Tensorflow：实战Google深度学习框架","cover":"https://img3.doubanio.com/lpic/s29349250.jpg","review":"《Tensorflow实战》包含了深度学习的入门知识和大量实践经验，是走进这个最新、最火的人工智能领域的首选参考书。","score":"8.2","doubanLink":"https://book.douban.com/subject/26976457/"},{"title":"机器学习","cover":"https://img1.doubanio.com/lpic/s28735609.jpg","review":"本书作为该领域的入门教材，在内容上尽可能涵盖机器学习基础知识的各方面。 为了使尽可能多的读者通过本书对机器学习有所了解, 作者试图尽可能少地使用数学知识. 然而, 少量的概率、统计、代数、优化、逻辑知识似乎不可避免. 因此, 本书更适合大学三年级以上的理工科本科生和研究生, 以及具有类似背景的对机器学 习感兴趣的人士. 为方便读者, 本书附录给出了一些相关数学基础知识简介.","score":"8.7","doubanLink":"https://book.douban.com/subject/26708119/"}],"wanted":[{"title":"OpenCV 3计算机视觉：Python语言实现（原书第2版）","cover":"https://img3.doubanio.com/lpic/s28902360.jpg","review":"本书针对具有一定Python工作经验的程序员以及想要利用OpenCV库研究计算机视觉课题的读者。本书不要求读者具有计算机视觉或OpenCV经验，但要具有编程经验。","score":"7.8","doubanLink":"https://book.douban.com/subject/26816975/"},{"title":"Python计算机视觉编程","cover":"https://img3.doubanio.com/lpic/s27305520.jpg","review":"《python计算机视觉编程》适合的读者是：有一定编程与数学基础，想要了解计算机视觉的基本理论与算法的学生，以及计算机科学、信号处理、物理学、应用数学和统计学、神经生理学、认知科学等领域的研究人员和从业者。","score":"7.5","doubanLink":"https://book.douban.com/subject/25906843/"}]}},"about":{"avatar":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/avatar.jpg","name":"tech.radish","tag":"python/Java/ML/CV","desc":"行走在边缘的coder","skills":{"ptyhon":5,"Java":6,"invisible-split-line-1":-1,"ML":4},"projects":[{"name":"合金战争(Java Swing + MySql + Socket)","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/game.png","tags":["Java","游戏开发"],"description":"合金战争是一款使用JavaSwing作为界面，MySQL作为数据库服务器，使用Socket通信的网络版RPG游戏","link_text":"合金战争","link":null},{"name":"iclass智能课堂助手","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/iclass.png","description":"iclass是一款实用SSM框架开发的轻量级课堂辅助教学系统，旨在加强和方便师生之间的交流合作，提高教学效率。拥有web端和安卓端（本人完成web端和安卓后端的开发）","tags":["毕业设计","SSM框架"],"link_text":"Github地址","link":"https://github.com/Mic-JasonTang/iclass"}],"reward":["https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/alipay-rewardcode.jpg","https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/wetchat-rewardcode.jpg"]},"slider":[{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/coloreggs.jpg","align":"center","title":"computer vision","subtitle":"whole world","link":"/"},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/fantasy.jpg","align":"left","title":"import tensorflow as tf","subtitle":"sess.run(hello)","link":null},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/pythoner.png","align":"right","title":"import __helloworld__","subtitle":">>> Hello World","link":null}],"hint":{"new":{"selector":[".menu-reading"]}}}},"excerpt":"","more":"<p>大家好，我是tech.radish。欢迎来到我的个人技术博客。</p>\n"},{"title":"读书","layout":"reading","_content":"# 我想读 #\n\n书籍1\n\n----------\n\n书籍2\n","source":"reading/index.md","raw":"title: 读书\nlayout: reading\n---\n# 我想读 #\n\n书籍1\n\n----------\n\n书籍2\n","date":"2018-03-23T10:21:49.160Z","updated":"2018-03-23T10:21:49.160Z","path":"reading/index.html","comments":1,"_id":"cjf3srot60003usu80qjr9fj8","content":"<h1 id=\"我想读\"><a href=\"#我想读\" class=\"headerlink\" title=\"我想读\"></a>我想读</h1><p>书籍1</p>\n<hr>\n<p>书籍2</p>\n","site":{"data":{"link":{"social":{"github":"https://github.com/mic-jasontang"},"extern":{"Github地址":"https://github.com/mic-jasontang"}},"reading":{"define":{"readed":"已读","reading":"在读","wanted":"想读"},"contents":{"readed":[{"title":"嫌疑人X的献身","cover":"https://img3.doubanio.com/lpic/s3254244.jpg","review":"百年一遇的数学天才石神，每天唯一的乐趣，便是去固定的便当店买午餐，只为看一眼在便当店做事的邻居靖子。","score":"8.9","doubanLink":"https://book.douban.com/subject/3211779/"},{"title":"Python核心编程（第二版）","cover":"https://img3.doubanio.com/lpic/s3140466.jpg","review":"本书是Python开发者的完全指南——针对 Python 2.5全面升级","score":"7.7","doubanLink":"https://book.douban.com/subject/3112503/"},{"title":"程序员代码面试指南：IT名企算法与数据结构题目最优解","cover":"https://img3.doubanio.com/lpic/s28313721.jpg","review":"这是一本程序员面试宝典！书中对IT名企代码面试各类题目的最优解进行了总结，并提供了相关代码实现。","score":"8.8","doubanLink":"https://book.douban.com/subject/26638586/"},{"title":"机器学习实战","cover":"https://img3.doubanio.com/lpic/s26696371.jpg","review":"全书通过精心编排的实例，切入日常工作任务，摒弃学术化语言，利用高效的可复用Python代码来阐释如何处理统计数据，进行数据分析及可视化。通过各种实例，读者可从中学会机器学习的核心算法，并能将其运用于一些策略性任务中，如分类、预测、推荐。另外，还可用它们来实现一些更高级的功能，如汇总和简化等。","score":"8.2","doubanLink":"https://book.douban.com/subject/24703171/"},{"title":"TensorFlow实战","cover":"https://img3.doubanio.com/lpic/s29343414.jpg","review":"《TensorFlow实战》希望能帮读者快速入门TensorFlow和深度学习，在工业界或者研究中快速地将想法落地为可实践的模型。","score":"7.3","doubanLink":"https://book.douban.com/subject/26974266/"}],"reading":[{"title":"深度学习","cover":"https://img1.doubanio.com/lpic/s29518349.jpg","review":"《深度学习》适合各类读者阅读，包括相关专业的大学生或研究生，以及不具有机器学习或统计背景、但是想要快速补充深度学习知识，以便在实际产品或平台中应用的软件工程师。","score":"8.7","doubanLink":"https://book.douban.com/subject/27087503/"},{"title":"Tensorflow：实战Google深度学习框架","cover":"https://img3.doubanio.com/lpic/s29349250.jpg","review":"《Tensorflow实战》包含了深度学习的入门知识和大量实践经验，是走进这个最新、最火的人工智能领域的首选参考书。","score":"8.2","doubanLink":"https://book.douban.com/subject/26976457/"},{"title":"机器学习","cover":"https://img1.doubanio.com/lpic/s28735609.jpg","review":"本书作为该领域的入门教材，在内容上尽可能涵盖机器学习基础知识的各方面。 为了使尽可能多的读者通过本书对机器学习有所了解, 作者试图尽可能少地使用数学知识. 然而, 少量的概率、统计、代数、优化、逻辑知识似乎不可避免. 因此, 本书更适合大学三年级以上的理工科本科生和研究生, 以及具有类似背景的对机器学 习感兴趣的人士. 为方便读者, 本书附录给出了一些相关数学基础知识简介.","score":"8.7","doubanLink":"https://book.douban.com/subject/26708119/"}],"wanted":[{"title":"OpenCV 3计算机视觉：Python语言实现（原书第2版）","cover":"https://img3.doubanio.com/lpic/s28902360.jpg","review":"本书针对具有一定Python工作经验的程序员以及想要利用OpenCV库研究计算机视觉课题的读者。本书不要求读者具有计算机视觉或OpenCV经验，但要具有编程经验。","score":"7.8","doubanLink":"https://book.douban.com/subject/26816975/"},{"title":"Python计算机视觉编程","cover":"https://img3.doubanio.com/lpic/s27305520.jpg","review":"《python计算机视觉编程》适合的读者是：有一定编程与数学基础，想要了解计算机视觉的基本理论与算法的学生，以及计算机科学、信号处理、物理学、应用数学和统计学、神经生理学、认知科学等领域的研究人员和从业者。","score":"7.5","doubanLink":"https://book.douban.com/subject/25906843/"}]}},"about":{"avatar":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/avatar.jpg","name":"tech.radish","tag":"python/Java/ML/CV","desc":"行走在边缘的coder","skills":{"ptyhon":5,"Java":6,"invisible-split-line-1":-1,"ML":4},"projects":[{"name":"合金战争(Java Swing + MySql + Socket)","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/game.png","tags":["Java","游戏开发"],"description":"合金战争是一款使用JavaSwing作为界面，MySQL作为数据库服务器，使用Socket通信的网络版RPG游戏","link_text":"合金战争","link":null},{"name":"iclass智能课堂助手","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/iclass.png","description":"iclass是一款实用SSM框架开发的轻量级课堂辅助教学系统，旨在加强和方便师生之间的交流合作，提高教学效率。拥有web端和安卓端（本人完成web端和安卓后端的开发）","tags":["毕业设计","SSM框架"],"link_text":"Github地址","link":"https://github.com/Mic-JasonTang/iclass"}],"reward":["https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/alipay-rewardcode.jpg","https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/wetchat-rewardcode.jpg"]},"slider":[{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/coloreggs.jpg","align":"center","title":"computer vision","subtitle":"whole world","link":"/"},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/fantasy.jpg","align":"left","title":"import tensorflow as tf","subtitle":"sess.run(hello)","link":null},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/pythoner.png","align":"right","title":"import __helloworld__","subtitle":">>> Hello World","link":null}],"hint":{"new":{"selector":[".menu-reading"]}}}},"excerpt":"","more":"<h1 id=\"我想读\"><a href=\"#我想读\" class=\"headerlink\" title=\"我想读\"></a>我想读</h1><p>书籍1</p>\n<hr>\n<p>书籍2</p>\n"}],"Post":[{"title":"Hexo多电脑同步写作","date":"2018-03-22T13:01:20.000Z","_content":"利用Hexo安装完博客之后，如何实现多电脑写作捏？下面分几步来说明\n\n# 1.上传文件到仓库 #\n前提是已经安装好Git客户端。这个应该在你安装博客的时候就已经安装好了吧。不会的话，百度下下载链接安装就好。\n首先你要明白，你创建的博客通过`hexo d`命令部署到github之后,和你的本地博客根目录下的`.deploy_git`文件夹中的目录结构是一样的，所以，这只能算是个web工程，若要想实现多客户端写作的话，需要通过下面的步骤。\n\n<!-- more -->\n\n1. 首先在你Github账户上新建一个仓库，例如名为`hexo-blog`\n2. 将本地博客根目录下的5个文件分别copy到一个新文件夹(例：hexo-blog)里面。\n\t1. scaffolds\n\t2. source\n\t3. themes（记得删除你下载主题的.git目录，它通常是隐藏的，需要取消隐藏之后删除，或者使用Git客户端来删除，`ls -a && rm .git`）\n\t4. _config.yml\n\t5. package.json\n3.  在hexo-blog目录中执行\n\t1.  `git init`\n\t2.  `git add .`\n\t3.  `git remote add origin git@github@你github用户名/hexo-blog(换成你仓库名).github.io.git`（使用你新建的仓库的SSH地址）\n\t4.  `git commit -m 'blog source bakcup'`(commit之后才能创建分支)\n\t5.  `git branch hexo`创建一个hexo分支\n\t6.  `git checkout hexo`切换到hexo分支\n\t5.  `git push origin hexo`\n4. 在第2步中，起始可以直接执行第3步的命令，也即可以不用复制那5个文件到新的目录中，只是因为那5个目录是必须的，其他的都是次要的。\n\n# 2. 下载文件 #\n上一步已经将你本地的博客托管到了github仓库中，接下来需要在你另一台需要写博客的电脑中，安装Node.js（这个自行百度吧，直接next安装即可）然后执行clone命令即可。\n\n1. 进入到你放置博客的目录中，然后执行`git clone -b hexo git@github@你github用户名/hexo-blog(换成你仓库名).github.io.git`\n2. `cd hexo-blog`进入此仓库目录中\n3. 执行`npm install`安装所需组件\n4. 使用`hexo g && hexo s -p 8080` 在本地打开浏览器输入`localhost:8080` 查看与在线的博客是否一致。\n5. 使用`hexo new \"page name\"`新建一片博客，写完一篇博客，然后部署`hexo clean && hexo g && hexo d`,再执行以下命令来完成同步\n\t1. `git add .`\n\t2. `git commit -m 'add a new page'`\n\t3. `git push origin hexo`\n6. 此时就可以在你原先电脑上执行`git pull origin hexo`来完成同步了。 \n\n# 留言 #\n如果还有不懂请在下面留言，我会及时回复。","source":"_posts/Hexo多电脑同步写作.md","raw":"---\ntitle: Hexo多电脑同步写作\ndate: 2018-03-22 21:01:20\ncategories:\n- 技术文章\n- 博客搭建\ntags:\n- hexo\n- 多电脑同步\n---\n利用Hexo安装完博客之后，如何实现多电脑写作捏？下面分几步来说明\n\n# 1.上传文件到仓库 #\n前提是已经安装好Git客户端。这个应该在你安装博客的时候就已经安装好了吧。不会的话，百度下下载链接安装就好。\n首先你要明白，你创建的博客通过`hexo d`命令部署到github之后,和你的本地博客根目录下的`.deploy_git`文件夹中的目录结构是一样的，所以，这只能算是个web工程，若要想实现多客户端写作的话，需要通过下面的步骤。\n\n<!-- more -->\n\n1. 首先在你Github账户上新建一个仓库，例如名为`hexo-blog`\n2. 将本地博客根目录下的5个文件分别copy到一个新文件夹(例：hexo-blog)里面。\n\t1. scaffolds\n\t2. source\n\t3. themes（记得删除你下载主题的.git目录，它通常是隐藏的，需要取消隐藏之后删除，或者使用Git客户端来删除，`ls -a && rm .git`）\n\t4. _config.yml\n\t5. package.json\n3.  在hexo-blog目录中执行\n\t1.  `git init`\n\t2.  `git add .`\n\t3.  `git remote add origin git@github@你github用户名/hexo-blog(换成你仓库名).github.io.git`（使用你新建的仓库的SSH地址）\n\t4.  `git commit -m 'blog source bakcup'`(commit之后才能创建分支)\n\t5.  `git branch hexo`创建一个hexo分支\n\t6.  `git checkout hexo`切换到hexo分支\n\t5.  `git push origin hexo`\n4. 在第2步中，起始可以直接执行第3步的命令，也即可以不用复制那5个文件到新的目录中，只是因为那5个目录是必须的，其他的都是次要的。\n\n# 2. 下载文件 #\n上一步已经将你本地的博客托管到了github仓库中，接下来需要在你另一台需要写博客的电脑中，安装Node.js（这个自行百度吧，直接next安装即可）然后执行clone命令即可。\n\n1. 进入到你放置博客的目录中，然后执行`git clone -b hexo git@github@你github用户名/hexo-blog(换成你仓库名).github.io.git`\n2. `cd hexo-blog`进入此仓库目录中\n3. 执行`npm install`安装所需组件\n4. 使用`hexo g && hexo s -p 8080` 在本地打开浏览器输入`localhost:8080` 查看与在线的博客是否一致。\n5. 使用`hexo new \"page name\"`新建一片博客，写完一篇博客，然后部署`hexo clean && hexo g && hexo d`,再执行以下命令来完成同步\n\t1. `git add .`\n\t2. `git commit -m 'add a new page'`\n\t3. `git push origin hexo`\n6. 此时就可以在你原先电脑上执行`git pull origin hexo`来完成同步了。 \n\n# 留言 #\n如果还有不懂请在下面留言，我会及时回复。","slug":"Hexo多电脑同步写作","published":1,"updated":"2018-03-23T10:21:49.157Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf3srot00000usu8fjo35wkj","content":"<p>利用Hexo安装完博客之后，如何实现多电脑写作捏？下面分几步来说明</p>\n<h1 id=\"1-上传文件到仓库\"><a href=\"#1-上传文件到仓库\" class=\"headerlink\" title=\"1.上传文件到仓库\"></a>1.上传文件到仓库</h1><p>前提是已经安装好Git客户端。这个应该在你安装博客的时候就已经安装好了吧。不会的话，百度下下载链接安装就好。<br>首先你要明白，你创建的博客通过<code>hexo d</code>命令部署到github之后,和你的本地博客根目录下的<code>.deploy_git</code>文件夹中的目录结构是一样的，所以，这只能算是个web工程，若要想实现多客户端写作的话，需要通过下面的步骤。</p>\n<a id=\"more\"></a>\n<ol>\n<li>首先在你Github账户上新建一个仓库，例如名为<code>hexo-blog</code></li>\n<li>将本地博客根目录下的5个文件分别copy到一个新文件夹(例：hexo-blog)里面。<ol>\n<li>scaffolds</li>\n<li>source</li>\n<li>themes（记得删除你下载主题的.git目录，它通常是隐藏的，需要取消隐藏之后删除，或者使用Git客户端来删除，<code>ls -a &amp;&amp; rm .git</code>）</li>\n<li>_config.yml</li>\n<li>package.json</li>\n</ol>\n</li>\n<li>在hexo-blog目录中执行<ol>\n<li><code>git init</code></li>\n<li><code>git add .</code></li>\n<li><code>git remote add origin git@github@你github用户名/hexo-blog(换成你仓库名).github.io.git</code>（使用你新建的仓库的SSH地址）</li>\n<li><code>git commit -m &#39;blog source bakcup&#39;</code>(commit之后才能创建分支)</li>\n<li><code>git branch hexo</code>创建一个hexo分支</li>\n<li><code>git checkout hexo</code>切换到hexo分支</li>\n<li><code>git push origin hexo</code></li>\n</ol>\n</li>\n<li>在第2步中，起始可以直接执行第3步的命令，也即可以不用复制那5个文件到新的目录中，只是因为那5个目录是必须的，其他的都是次要的。</li>\n</ol>\n<h1 id=\"2-下载文件\"><a href=\"#2-下载文件\" class=\"headerlink\" title=\"2. 下载文件\"></a>2. 下载文件</h1><p>上一步已经将你本地的博客托管到了github仓库中，接下来需要在你另一台需要写博客的电脑中，安装Node.js（这个自行百度吧，直接next安装即可）然后执行clone命令即可。</p>\n<ol>\n<li>进入到你放置博客的目录中，然后执行<code>git clone -b hexo git@github@你github用户名/hexo-blog(换成你仓库名).github.io.git</code></li>\n<li><code>cd hexo-blog</code>进入此仓库目录中</li>\n<li>执行<code>npm install</code>安装所需组件</li>\n<li>使用<code>hexo g &amp;&amp; hexo s -p 8080</code> 在本地打开浏览器输入<code>localhost:8080</code> 查看与在线的博客是否一致。</li>\n<li>使用<code>hexo new &quot;page name&quot;</code>新建一片博客，写完一篇博客，然后部署<code>hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</code>,再执行以下命令来完成同步<ol>\n<li><code>git add .</code></li>\n<li><code>git commit -m &#39;add a new page&#39;</code></li>\n<li><code>git push origin hexo</code></li>\n</ol>\n</li>\n<li>此时就可以在你原先电脑上执行<code>git pull origin hexo</code>来完成同步了。 </li>\n</ol>\n<h1 id=\"留言\"><a href=\"#留言\" class=\"headerlink\" title=\"留言\"></a>留言</h1><p>如果还有不懂请在下面留言，我会及时回复。</p>\n","site":{"data":{"link":{"social":{"github":"https://github.com/mic-jasontang"},"extern":{"Github地址":"https://github.com/mic-jasontang"}},"reading":{"define":{"readed":"已读","reading":"在读","wanted":"想读"},"contents":{"readed":[{"title":"嫌疑人X的献身","cover":"https://img3.doubanio.com/lpic/s3254244.jpg","review":"百年一遇的数学天才石神，每天唯一的乐趣，便是去固定的便当店买午餐，只为看一眼在便当店做事的邻居靖子。","score":"8.9","doubanLink":"https://book.douban.com/subject/3211779/"},{"title":"Python核心编程（第二版）","cover":"https://img3.doubanio.com/lpic/s3140466.jpg","review":"本书是Python开发者的完全指南——针对 Python 2.5全面升级","score":"7.7","doubanLink":"https://book.douban.com/subject/3112503/"},{"title":"程序员代码面试指南：IT名企算法与数据结构题目最优解","cover":"https://img3.doubanio.com/lpic/s28313721.jpg","review":"这是一本程序员面试宝典！书中对IT名企代码面试各类题目的最优解进行了总结，并提供了相关代码实现。","score":"8.8","doubanLink":"https://book.douban.com/subject/26638586/"},{"title":"机器学习实战","cover":"https://img3.doubanio.com/lpic/s26696371.jpg","review":"全书通过精心编排的实例，切入日常工作任务，摒弃学术化语言，利用高效的可复用Python代码来阐释如何处理统计数据，进行数据分析及可视化。通过各种实例，读者可从中学会机器学习的核心算法，并能将其运用于一些策略性任务中，如分类、预测、推荐。另外，还可用它们来实现一些更高级的功能，如汇总和简化等。","score":"8.2","doubanLink":"https://book.douban.com/subject/24703171/"},{"title":"TensorFlow实战","cover":"https://img3.doubanio.com/lpic/s29343414.jpg","review":"《TensorFlow实战》希望能帮读者快速入门TensorFlow和深度学习，在工业界或者研究中快速地将想法落地为可实践的模型。","score":"7.3","doubanLink":"https://book.douban.com/subject/26974266/"}],"reading":[{"title":"深度学习","cover":"https://img1.doubanio.com/lpic/s29518349.jpg","review":"《深度学习》适合各类读者阅读，包括相关专业的大学生或研究生，以及不具有机器学习或统计背景、但是想要快速补充深度学习知识，以便在实际产品或平台中应用的软件工程师。","score":"8.7","doubanLink":"https://book.douban.com/subject/27087503/"},{"title":"Tensorflow：实战Google深度学习框架","cover":"https://img3.doubanio.com/lpic/s29349250.jpg","review":"《Tensorflow实战》包含了深度学习的入门知识和大量实践经验，是走进这个最新、最火的人工智能领域的首选参考书。","score":"8.2","doubanLink":"https://book.douban.com/subject/26976457/"},{"title":"机器学习","cover":"https://img1.doubanio.com/lpic/s28735609.jpg","review":"本书作为该领域的入门教材，在内容上尽可能涵盖机器学习基础知识的各方面。 为了使尽可能多的读者通过本书对机器学习有所了解, 作者试图尽可能少地使用数学知识. 然而, 少量的概率、统计、代数、优化、逻辑知识似乎不可避免. 因此, 本书更适合大学三年级以上的理工科本科生和研究生, 以及具有类似背景的对机器学 习感兴趣的人士. 为方便读者, 本书附录给出了一些相关数学基础知识简介.","score":"8.7","doubanLink":"https://book.douban.com/subject/26708119/"}],"wanted":[{"title":"OpenCV 3计算机视觉：Python语言实现（原书第2版）","cover":"https://img3.doubanio.com/lpic/s28902360.jpg","review":"本书针对具有一定Python工作经验的程序员以及想要利用OpenCV库研究计算机视觉课题的读者。本书不要求读者具有计算机视觉或OpenCV经验，但要具有编程经验。","score":"7.8","doubanLink":"https://book.douban.com/subject/26816975/"},{"title":"Python计算机视觉编程","cover":"https://img3.doubanio.com/lpic/s27305520.jpg","review":"《python计算机视觉编程》适合的读者是：有一定编程与数学基础，想要了解计算机视觉的基本理论与算法的学生，以及计算机科学、信号处理、物理学、应用数学和统计学、神经生理学、认知科学等领域的研究人员和从业者。","score":"7.5","doubanLink":"https://book.douban.com/subject/25906843/"}]}},"about":{"avatar":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/avatar.jpg","name":"tech.radish","tag":"python/Java/ML/CV","desc":"行走在边缘的coder","skills":{"ptyhon":5,"Java":6,"invisible-split-line-1":-1,"ML":4},"projects":[{"name":"合金战争(Java Swing + MySql + Socket)","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/game.png","tags":["Java","游戏开发"],"description":"合金战争是一款使用JavaSwing作为界面，MySQL作为数据库服务器，使用Socket通信的网络版RPG游戏","link_text":"合金战争","link":null},{"name":"iclass智能课堂助手","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/iclass.png","description":"iclass是一款实用SSM框架开发的轻量级课堂辅助教学系统，旨在加强和方便师生之间的交流合作，提高教学效率。拥有web端和安卓端（本人完成web端和安卓后端的开发）","tags":["毕业设计","SSM框架"],"link_text":"Github地址","link":"https://github.com/Mic-JasonTang/iclass"}],"reward":["https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/alipay-rewardcode.jpg","https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/wetchat-rewardcode.jpg"]},"slider":[{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/coloreggs.jpg","align":"center","title":"computer vision","subtitle":"whole world","link":"/"},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/fantasy.jpg","align":"left","title":"import tensorflow as tf","subtitle":"sess.run(hello)","link":null},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/pythoner.png","align":"right","title":"import __helloworld__","subtitle":">>> Hello World","link":null}],"hint":{"new":{"selector":[".menu-reading"]}}}},"excerpt":"<p>利用Hexo安装完博客之后，如何实现多电脑写作捏？下面分几步来说明</p>\n<h1 id=\"1-上传文件到仓库\"><a href=\"#1-上传文件到仓库\" class=\"headerlink\" title=\"1.上传文件到仓库\"></a>1.上传文件到仓库</h1><p>前提是已经安装好Git客户端。这个应该在你安装博客的时候就已经安装好了吧。不会的话，百度下下载链接安装就好。<br>首先你要明白，你创建的博客通过<code>hexo d</code>命令部署到github之后,和你的本地博客根目录下的<code>.deploy_git</code>文件夹中的目录结构是一样的，所以，这只能算是个web工程，若要想实现多客户端写作的话，需要通过下面的步骤。</p>","more":"<ol>\n<li>首先在你Github账户上新建一个仓库，例如名为<code>hexo-blog</code></li>\n<li>将本地博客根目录下的5个文件分别copy到一个新文件夹(例：hexo-blog)里面。<ol>\n<li>scaffolds</li>\n<li>source</li>\n<li>themes（记得删除你下载主题的.git目录，它通常是隐藏的，需要取消隐藏之后删除，或者使用Git客户端来删除，<code>ls -a &amp;&amp; rm .git</code>）</li>\n<li>_config.yml</li>\n<li>package.json</li>\n</ol>\n</li>\n<li>在hexo-blog目录中执行<ol>\n<li><code>git init</code></li>\n<li><code>git add .</code></li>\n<li><code>git remote add origin git@github@你github用户名/hexo-blog(换成你仓库名).github.io.git</code>（使用你新建的仓库的SSH地址）</li>\n<li><code>git commit -m &#39;blog source bakcup&#39;</code>(commit之后才能创建分支)</li>\n<li><code>git branch hexo</code>创建一个hexo分支</li>\n<li><code>git checkout hexo</code>切换到hexo分支</li>\n<li><code>git push origin hexo</code></li>\n</ol>\n</li>\n<li>在第2步中，起始可以直接执行第3步的命令，也即可以不用复制那5个文件到新的目录中，只是因为那5个目录是必须的，其他的都是次要的。</li>\n</ol>\n<h1 id=\"2-下载文件\"><a href=\"#2-下载文件\" class=\"headerlink\" title=\"2. 下载文件\"></a>2. 下载文件</h1><p>上一步已经将你本地的博客托管到了github仓库中，接下来需要在你另一台需要写博客的电脑中，安装Node.js（这个自行百度吧，直接next安装即可）然后执行clone命令即可。</p>\n<ol>\n<li>进入到你放置博客的目录中，然后执行<code>git clone -b hexo git@github@你github用户名/hexo-blog(换成你仓库名).github.io.git</code></li>\n<li><code>cd hexo-blog</code>进入此仓库目录中</li>\n<li>执行<code>npm install</code>安装所需组件</li>\n<li>使用<code>hexo g &amp;&amp; hexo s -p 8080</code> 在本地打开浏览器输入<code>localhost:8080</code> 查看与在线的博客是否一致。</li>\n<li>使用<code>hexo new &quot;page name&quot;</code>新建一片博客，写完一篇博客，然后部署<code>hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</code>,再执行以下命令来完成同步<ol>\n<li><code>git add .</code></li>\n<li><code>git commit -m &#39;add a new page&#39;</code></li>\n<li><code>git push origin hexo</code></li>\n</ol>\n</li>\n<li>此时就可以在你原先电脑上执行<code>git pull origin hexo</code>来完成同步了。 </li>\n</ol>\n<h1 id=\"留言\"><a href=\"#留言\" class=\"headerlink\" title=\"留言\"></a>留言</h1><p>如果还有不懂请在下面留言，我会及时回复。</p>"},{"title":"Mnist手写数字体识别(tensorflow)","date":"2018-03-20T13:35:05.000Z","_content":"# Tensorflow #\n\n\n> 首先，简单的说下，tensorflow的基本架构。\n>使用 TensorFlow, 你必须明白 TensorFlow:\n\n- 使用图 (graph) 来表示计算任务.\n- 在被称之为 会话 (Session) 的上下文 (context) 中执行图.\n- 使用 tensor 表示数据.\n- 通过 变量 (Variable) 维护状态.\n- 使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.\n\n<!--more -->\n\n# Tensor #\n\n> TensorFlow 是一个编程系统, 使用图来表示计算任务. 图中的节点被称之为 op (operation 的缩写). 一个 op 获得 0 个或多个 Tensor, 执行计算, 产生 0 个或多个 Tensor. 每个 Tensor 是一个类型化的多维数组. 例如, 你可以将一小组图像集表示为一个四维浮点数数组, 这四个维度分别是 [batch, height, width, channels].\n\n> 一个 TensorFlow 图描述了计算的过程. 为了进行计算, 图必须在 会话 里被启动. 会话 将图的 op 分发到诸如 CPU 或 GPU 之类的 设备 上, 同时提供执行 op 的方法. 这些方法执行后, 将产生的 tensor 返回. 在 Python 语言中, 返回的 tensor 是 numpy ndarray 对象; 在 C 和 C++ 语言中, 返回的 tensor 是tensorflow::Tensor 实例.\n\n> Tensor是tensorflow中非常重要且非常基础的概念，可以说数据的呈现形式都是用tensor表示的。输入输出都是tensor，tensor的中文含义，就是张量，可以简单的理解为线性代数里面的向量或者矩阵。\n\n# Graph #\n\n\n> TensorFlow 程序通常被组织成一个构建阶段和一个执行阶段. 在构建阶段, op 的执行步骤 被描述成一个图. 在执行阶段, 使用会话执行执行图中的 op.\n\n\n\n> 例如, 通常在构建阶段创建一个图来表示和训练神经网络, 然后在执行阶段反复执行图中的训练 op. 下面这个图，就是一个比较形象的说明，图中的每一个节点，就是一个op，各个op透过tensor数据流向形成边的连接，构成了一个图。\n\n![](https://images2015.cnblogs.com/blog/844237/201703/844237-20170330093311608-2056024255.gif)\n> 构建图的第一步, 是创建源 op (source op). 源 op 不需要任何输入, 例如 常量 (Constant). 源 op 的输出被传递给其它 op 做运算. Python 库中, op 构造器的返回值代表被构造出的 op 的输出, 这些返回值可以传递给其它 op 构造器作为输入.\n\n\n> TensorFlow Python 库有一个默认图 (default graph), op 构造器可以为其增加节点. 这个默认图对 许多程序来说已经足够用了.\n\n# Session #\n> 当图构建好后，需要创建一个Session来运行构建好的图，来实现逻辑，创建session的时候，若无任何参数，tensorflow将启用默认的session。session.run(xxx)是比较典型的使用方案, session运行结束后，返回值是一个tensor。\n\n\n\n> tensorflow中的session，有两大类，一种就是普通的session，即tensorflow.Session(),还有一种是交互式session，即tensorflow.InteractiveSession(). 使用Tensor.eval() 和Operation.run()方法代替Session.run(). 这样可以避免使用一个变量来持有会话, 为程序架构的设计添加了灵活性.\n\n\n# 数据载体 #\n> Tensorflow体系下，变量（Variable）是用来维护图计算过程中的中间状态信息，是一种常见高频使用的数据载体，还有一种特殊的数据载体，那就是常量（Constant），主要是用作图处理过程的输入量。这些数据载体，也都是以Tensor的形式体现。变量定义和常量定义上，比较好理解：\n   \n\t# 创建一个变量, 初始化为标量0.没有指定数据类型（dtype）\n\tstate = tf.Variable(0, name=\"counter\")\n\n\t# 创建一个常量，其值为1，没有指定数据类型（dtype）\n\tone = tf.constant(1)\n\n\n\n> 针对上面的变量和常量，看看Tensorflow里面的函数定义：\n>\n    class Variable(object):　\n\tdef __init__(self,\n\t\tinitial_value=None,\n\t\ttrainable=True,\n\t\tcollections=None,\n\t\tvalidate_shape=True,\n\t\tcaching_device=None,\n\t\tname=None,\n\t\tvariable_def=None,\n\t\tdtype=None,\n\t\texpected_shape=None,\n\t\timport_scope=None)：\n\n>\n\tdef constant(value, dtype=None, shape=None, name=\"Const\", verify_shape=False)：\n\n> 从上面的源码可以看出，定义变量，其实就是定义了一个Variable的实例，而定义常量，其实就是调用了一下常量函数，创建了一个常量Tensor。\n\n> 还有一个很重要的概念，那就是占位符placeholder，这个在Tensorflow中进行Feed数据灌入时，很有用。所谓的数据灌入，指的是在创建Tensorflow的图时，节点的输入部分，就是一个placeholder，后续在执行session操作的前，将实际数据Feed到图中，进行执行即可。\n>\n\tinput1 = tf.placeholder(tf.types.float32)\n\tinput2 = tf.placeholder(tf.types.float32)\n\toutput = tf.mul(input1, input2)\n>\t\n\twith tf.Session() as sess:\n\t  print sess.run([output], feed_dict={input1:[7.], input2:[2.]})\n>\t\n\t# 输出:\n\t# [array([ 14.], dtype=float32)]\n\n> 占位符的定义原型，也是一个函数：\n>\n\tdef placeholder(dtype, shape=None, name=None)：\n\n\n\n> 到此，Tensorflow的入门级的基本知识介绍完了。下面，将结合一个MNIST的手写识别的例子，从代码上简单分析一下，源代码分成4个文件：\n\n\n----------\n\n> main.py驱动程序\n \n    #!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2018/2/21 20:41\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : main.py\n\t# @ToDo    : 驱动程序\n\t\n\timport _thread\n\t\n\tfrom neural_network_learning.hand_writting_refactor import mnist_train, mnist_eval\n\t\n\t\n\tif __name__ == '__main__':\n\t    _thread.start_new_thread(mnist_train.main, (None,))\n\t    _thread.start_new_thread(mnist_eval.main, (None,))\n\t\n\t    # 这个不能删除，当做主线程\n\t    while 1:\n\t        pass\n\n> mnist_inference.py计算前向传播的过程及定义了神经网络的参数\n \n\t#!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2018/2/20 19:43\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : mnist_inference.py\n\t# @ToDo    : 定义了前向传播的过程及神经网络的参数\n\t\n\t\n\timport tensorflow as tf\n\t\n\t# 定义神经网络结构相关的参数\n\tINPUT_NODE = 784\n\tOUTPUT_NODE = 10\n\tLAYER1_NODE = 500\n\t\n\t\n\t# 训练时会创建这些变量，测试时会通过保存的模型加载这些变量的取值\n\tdef get_weight_variable(shape, regularizer):\n\t    weights = tf.get_variable(\"weights\", shape, initializer=tf.truncated_normal_initializer(stddev=0.1))\n\t\n\t    # 当使用正则化生成函数时,当前变量的正则化损失加入名字为losses的集合.\n\t    # 自定义集合\n\t    if regularizer:\n\t        tf.add_to_collection(\"losses\", regularizer(weights))\n\t    return weights\n\t\n\t\n\t# 前向传播过程\n\tdef inference(input_tensor, regularizer):\n\t    # 声明第一层神经网络的变量并完成前向传播过程\n\t    with tf.variable_scope(\"layer1\"):\n\t        weights = get_weight_variable([INPUT_NODE, LAYER1_NODE], regularizer)\n\t        biases = tf.get_variable(\"biases\", [LAYER1_NODE], initializer=tf.constant_initializer(0.0))\n\t        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights) + biases)\n\t\n\t    # 声明第二层圣经网络变量并完成前向传播过程\n\t    with tf.variable_scope(\"layer2\"):\n\t        weights = get_weight_variable([LAYER1_NODE, OUTPUT_NODE], regularizer)\n\t        biases = tf.get_variable(\"biases\", [OUTPUT_NODE], initializer=tf.constant_initializer(0.0))\n\t        layer2 = tf.matmul(layer1, weights) + biases\n\t    # 返回最后前向传播的结果\n\t    return layer2\n\n> mnist_train.py定义了神经网络的训练过程\n\n\t#!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2018/2/21 16:08\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : mnist_train.py\n\t# @ToDo    : 定义了神经网络的训练过程\n\t\n\timport os\n\t\n\timport tensorflow as tf\n\tfrom tensorflow.examples.tutorials.mnist import input_data\n\t\n\timport neural_network_learning.hand_writting_refactor.mnist_inference as mnist_inference\n\t\n\t# 配置神经网络的参数\n\tBATCH_SIZE = 100\n\tLEARNING_REATE_BASE = 0.8\n\tLEARNING_RATE_DECAY = 0.99\n\tREGULARAZTION_RATE = 0.0001\n\tTRAING_STEPS = 2000\n\tMOVING_AVERAGE_DECAY = 0.99\n\t# 模型保存的路径和文件名\n\tMODEL_SAVE_PATH = \"./model/\"\n\tMODEL_NAME = \"model.ckpt\"\n\t\n\t\n\tdef train(mnist):\n\t    # 定义输入输出placeholder\n\t    x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name=\"input-x\")\n\t    y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name=\"input-y\")\n\t\n\t    regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)\n\t    y = mnist_inference.inference(x, regularizer)\n\t    global_step = tf.Variable(0, trainable=False)\n\t\n\t    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n\t    variables_average_op = variable_averages.apply(tf.trainable_variables())\n\t    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.argmax(y_, 1), logits=y)\n\t    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n\t    loss = cross_entropy_mean + tf.add_n(tf.get_collection(\"losses\"))\n\t    learing_rate = tf.train.exponential_decay(LEARNING_REATE_BASE,\n\t                                              global_step,\n\t                                              mnist.train.num_examples / BATCH_SIZE,\n\t                                              LEARNING_RATE_DECAY)\n\t    train_step = tf.train.GradientDescentOptimizer(learing_rate).minimize(loss, global_step)\n\t\n\t    with tf.control_dependencies([train_step, variables_average_op]):\n\t        train_op = tf.no_op(name=\"train\")\n\t\n\t    # 初始化持久化类\n\t    saver = tf.train.Saver()\n\t    with tf.Session() as sess:\n\t        tf.global_variables_initializer().run()\n\t\n\t        for i in range(TRAING_STEPS):\n\t            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n\t            _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict={x: xs, y_: ys})\n\t\n\t            if i % 1000 == 0:\n\t                print(\"After %d training step(s), loss on training batch is %g.\" % (i, loss_value))\n\t\n\t                saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)\n\t\n\t\n\tdef main(argv=None):\n\t    mnist = input_data.read_data_sets(\"../MNIST_data\", one_hot=True)\n\t    train(mnist)\n\t\n\t\n\tif __name__ == '__main__':\n\t    tf.app.run()\n\n> mnist_eval.py测试过程\n \n\t#!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2018/2/21 16:32\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : mnist_eval.py\n\t# @ToDo    : 测试过程\n\t\n\t\n\timport time\n\timport tensorflow as tf\n\tfrom tensorflow.examples.tutorials.mnist import input_data\n\t\n\timport neural_network_learning.hand_writting_refactor.mnist_inference as mnist_inference\n\timport neural_network_learning.hand_writting_refactor.mnist_train as mnist_train\n\t\n\t# 每10s加载一次最新模型，并在测试数据上测试最新模型的正确率\n\tEVAL_INTERVAL_SECS = 10\n\t\n\t\n\tdef evaluate(mnist):\n\t    x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name=\"input-x\")\n\t    y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name=\"input-y\")\n\t\n\t    validate_feed = {x: mnist.validation.images,\n\t                     y_: mnist.validation.labels}\n\t\n\t    y = mnist_inference.inference(x, None)\n\t\n\t    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n\t    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\t\n\t    variable_averages = tf.train.ExponentialMovingAverage(mnist_train.MOVING_AVERAGE_DECAY)\n\t    variables_to_restore = variable_averages.variables_to_restore()\n\t    saver = tf.train.Saver(variables_to_restore)\n\t\n\t    # 每隔EVAL_INTERVAL_SECS秒调用一次计算正确率的过程以检测训练过程中正确率的变化\n\t    stop_count = 0\n\t    while True:\n\t        with tf.Session() as sess:\n\t            ckpt = tf.train.get_checkpoint_state(mnist_train.MODEL_SAVE_PATH)\n\t            # 停止条件 #\n\t            stop_count += EVAL_INTERVAL_SECS\n\t            if stop_count == mnist_train.TRAING_STEPS:\n\t                return\n\t            # 停止条件 #\n\t            if ckpt and ckpt.model_checkpoint_path:\n\t                saver.restore(sess, ckpt.model_checkpoint_path)\n\t                # 通过文件名得到模型保存时迭代的轮数\n\t                # 输出./model/model.ckpt-29001\n\t                print(ckpt.model_checkpoint_path)\n\t                global_step = ckpt.model_checkpoint_path.split(\"/\")[-1].split(\"-\")[-1]\n\t                accuracy_score = sess.run(accuracy, feed_dict=validate_feed)\n\t                print(\"After %s training step(s), validation accuracy is %g\" % (global_step, accuracy_score))\n\t            else:\n\t                print(\"No checkpoint file found\")\n\t                return\n\t        time.sleep(EVAL_INTERVAL_SECS)\n\t\n\t\n\tdef main(argv=None):\n\t    mnist = input_data.read_data_sets(\"../MNIST_data\", one_hot=True)\n\t    evaluate(mnist)\n\t\n\t\n\tif __name__ == '__main__':\n\t    tf.app.run()\n\n# 参考文章 #\n[https://www.cnblogs.com/shihuc/p/6648130.html](https://www.cnblogs.com/shihuc/p/6648130.html \"Tensorflow之基于MNIST手写识别的入门介绍\")\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/Mnist手写数字体识别-tensorflow.md","raw":"---\ntitle: Mnist手写数字体识别(tensorflow)\ndate: 2018-03-20 21:35:05\ncategories:\n- tensorflow学习\n- tensorflow-Demo\ntags: \n- Mnist\n- tensorflow\n---\n# Tensorflow #\n\n\n> 首先，简单的说下，tensorflow的基本架构。\n>使用 TensorFlow, 你必须明白 TensorFlow:\n\n- 使用图 (graph) 来表示计算任务.\n- 在被称之为 会话 (Session) 的上下文 (context) 中执行图.\n- 使用 tensor 表示数据.\n- 通过 变量 (Variable) 维护状态.\n- 使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.\n\n<!--more -->\n\n# Tensor #\n\n> TensorFlow 是一个编程系统, 使用图来表示计算任务. 图中的节点被称之为 op (operation 的缩写). 一个 op 获得 0 个或多个 Tensor, 执行计算, 产生 0 个或多个 Tensor. 每个 Tensor 是一个类型化的多维数组. 例如, 你可以将一小组图像集表示为一个四维浮点数数组, 这四个维度分别是 [batch, height, width, channels].\n\n> 一个 TensorFlow 图描述了计算的过程. 为了进行计算, 图必须在 会话 里被启动. 会话 将图的 op 分发到诸如 CPU 或 GPU 之类的 设备 上, 同时提供执行 op 的方法. 这些方法执行后, 将产生的 tensor 返回. 在 Python 语言中, 返回的 tensor 是 numpy ndarray 对象; 在 C 和 C++ 语言中, 返回的 tensor 是tensorflow::Tensor 实例.\n\n> Tensor是tensorflow中非常重要且非常基础的概念，可以说数据的呈现形式都是用tensor表示的。输入输出都是tensor，tensor的中文含义，就是张量，可以简单的理解为线性代数里面的向量或者矩阵。\n\n# Graph #\n\n\n> TensorFlow 程序通常被组织成一个构建阶段和一个执行阶段. 在构建阶段, op 的执行步骤 被描述成一个图. 在执行阶段, 使用会话执行执行图中的 op.\n\n\n\n> 例如, 通常在构建阶段创建一个图来表示和训练神经网络, 然后在执行阶段反复执行图中的训练 op. 下面这个图，就是一个比较形象的说明，图中的每一个节点，就是一个op，各个op透过tensor数据流向形成边的连接，构成了一个图。\n\n![](https://images2015.cnblogs.com/blog/844237/201703/844237-20170330093311608-2056024255.gif)\n> 构建图的第一步, 是创建源 op (source op). 源 op 不需要任何输入, 例如 常量 (Constant). 源 op 的输出被传递给其它 op 做运算. Python 库中, op 构造器的返回值代表被构造出的 op 的输出, 这些返回值可以传递给其它 op 构造器作为输入.\n\n\n> TensorFlow Python 库有一个默认图 (default graph), op 构造器可以为其增加节点. 这个默认图对 许多程序来说已经足够用了.\n\n# Session #\n> 当图构建好后，需要创建一个Session来运行构建好的图，来实现逻辑，创建session的时候，若无任何参数，tensorflow将启用默认的session。session.run(xxx)是比较典型的使用方案, session运行结束后，返回值是一个tensor。\n\n\n\n> tensorflow中的session，有两大类，一种就是普通的session，即tensorflow.Session(),还有一种是交互式session，即tensorflow.InteractiveSession(). 使用Tensor.eval() 和Operation.run()方法代替Session.run(). 这样可以避免使用一个变量来持有会话, 为程序架构的设计添加了灵活性.\n\n\n# 数据载体 #\n> Tensorflow体系下，变量（Variable）是用来维护图计算过程中的中间状态信息，是一种常见高频使用的数据载体，还有一种特殊的数据载体，那就是常量（Constant），主要是用作图处理过程的输入量。这些数据载体，也都是以Tensor的形式体现。变量定义和常量定义上，比较好理解：\n   \n\t# 创建一个变量, 初始化为标量0.没有指定数据类型（dtype）\n\tstate = tf.Variable(0, name=\"counter\")\n\n\t# 创建一个常量，其值为1，没有指定数据类型（dtype）\n\tone = tf.constant(1)\n\n\n\n> 针对上面的变量和常量，看看Tensorflow里面的函数定义：\n>\n    class Variable(object):　\n\tdef __init__(self,\n\t\tinitial_value=None,\n\t\ttrainable=True,\n\t\tcollections=None,\n\t\tvalidate_shape=True,\n\t\tcaching_device=None,\n\t\tname=None,\n\t\tvariable_def=None,\n\t\tdtype=None,\n\t\texpected_shape=None,\n\t\timport_scope=None)：\n\n>\n\tdef constant(value, dtype=None, shape=None, name=\"Const\", verify_shape=False)：\n\n> 从上面的源码可以看出，定义变量，其实就是定义了一个Variable的实例，而定义常量，其实就是调用了一下常量函数，创建了一个常量Tensor。\n\n> 还有一个很重要的概念，那就是占位符placeholder，这个在Tensorflow中进行Feed数据灌入时，很有用。所谓的数据灌入，指的是在创建Tensorflow的图时，节点的输入部分，就是一个placeholder，后续在执行session操作的前，将实际数据Feed到图中，进行执行即可。\n>\n\tinput1 = tf.placeholder(tf.types.float32)\n\tinput2 = tf.placeholder(tf.types.float32)\n\toutput = tf.mul(input1, input2)\n>\t\n\twith tf.Session() as sess:\n\t  print sess.run([output], feed_dict={input1:[7.], input2:[2.]})\n>\t\n\t# 输出:\n\t# [array([ 14.], dtype=float32)]\n\n> 占位符的定义原型，也是一个函数：\n>\n\tdef placeholder(dtype, shape=None, name=None)：\n\n\n\n> 到此，Tensorflow的入门级的基本知识介绍完了。下面，将结合一个MNIST的手写识别的例子，从代码上简单分析一下，源代码分成4个文件：\n\n\n----------\n\n> main.py驱动程序\n \n    #!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2018/2/21 20:41\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : main.py\n\t# @ToDo    : 驱动程序\n\t\n\timport _thread\n\t\n\tfrom neural_network_learning.hand_writting_refactor import mnist_train, mnist_eval\n\t\n\t\n\tif __name__ == '__main__':\n\t    _thread.start_new_thread(mnist_train.main, (None,))\n\t    _thread.start_new_thread(mnist_eval.main, (None,))\n\t\n\t    # 这个不能删除，当做主线程\n\t    while 1:\n\t        pass\n\n> mnist_inference.py计算前向传播的过程及定义了神经网络的参数\n \n\t#!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2018/2/20 19:43\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : mnist_inference.py\n\t# @ToDo    : 定义了前向传播的过程及神经网络的参数\n\t\n\t\n\timport tensorflow as tf\n\t\n\t# 定义神经网络结构相关的参数\n\tINPUT_NODE = 784\n\tOUTPUT_NODE = 10\n\tLAYER1_NODE = 500\n\t\n\t\n\t# 训练时会创建这些变量，测试时会通过保存的模型加载这些变量的取值\n\tdef get_weight_variable(shape, regularizer):\n\t    weights = tf.get_variable(\"weights\", shape, initializer=tf.truncated_normal_initializer(stddev=0.1))\n\t\n\t    # 当使用正则化生成函数时,当前变量的正则化损失加入名字为losses的集合.\n\t    # 自定义集合\n\t    if regularizer:\n\t        tf.add_to_collection(\"losses\", regularizer(weights))\n\t    return weights\n\t\n\t\n\t# 前向传播过程\n\tdef inference(input_tensor, regularizer):\n\t    # 声明第一层神经网络的变量并完成前向传播过程\n\t    with tf.variable_scope(\"layer1\"):\n\t        weights = get_weight_variable([INPUT_NODE, LAYER1_NODE], regularizer)\n\t        biases = tf.get_variable(\"biases\", [LAYER1_NODE], initializer=tf.constant_initializer(0.0))\n\t        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights) + biases)\n\t\n\t    # 声明第二层圣经网络变量并完成前向传播过程\n\t    with tf.variable_scope(\"layer2\"):\n\t        weights = get_weight_variable([LAYER1_NODE, OUTPUT_NODE], regularizer)\n\t        biases = tf.get_variable(\"biases\", [OUTPUT_NODE], initializer=tf.constant_initializer(0.0))\n\t        layer2 = tf.matmul(layer1, weights) + biases\n\t    # 返回最后前向传播的结果\n\t    return layer2\n\n> mnist_train.py定义了神经网络的训练过程\n\n\t#!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2018/2/21 16:08\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : mnist_train.py\n\t# @ToDo    : 定义了神经网络的训练过程\n\t\n\timport os\n\t\n\timport tensorflow as tf\n\tfrom tensorflow.examples.tutorials.mnist import input_data\n\t\n\timport neural_network_learning.hand_writting_refactor.mnist_inference as mnist_inference\n\t\n\t# 配置神经网络的参数\n\tBATCH_SIZE = 100\n\tLEARNING_REATE_BASE = 0.8\n\tLEARNING_RATE_DECAY = 0.99\n\tREGULARAZTION_RATE = 0.0001\n\tTRAING_STEPS = 2000\n\tMOVING_AVERAGE_DECAY = 0.99\n\t# 模型保存的路径和文件名\n\tMODEL_SAVE_PATH = \"./model/\"\n\tMODEL_NAME = \"model.ckpt\"\n\t\n\t\n\tdef train(mnist):\n\t    # 定义输入输出placeholder\n\t    x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name=\"input-x\")\n\t    y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name=\"input-y\")\n\t\n\t    regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)\n\t    y = mnist_inference.inference(x, regularizer)\n\t    global_step = tf.Variable(0, trainable=False)\n\t\n\t    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n\t    variables_average_op = variable_averages.apply(tf.trainable_variables())\n\t    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.argmax(y_, 1), logits=y)\n\t    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n\t    loss = cross_entropy_mean + tf.add_n(tf.get_collection(\"losses\"))\n\t    learing_rate = tf.train.exponential_decay(LEARNING_REATE_BASE,\n\t                                              global_step,\n\t                                              mnist.train.num_examples / BATCH_SIZE,\n\t                                              LEARNING_RATE_DECAY)\n\t    train_step = tf.train.GradientDescentOptimizer(learing_rate).minimize(loss, global_step)\n\t\n\t    with tf.control_dependencies([train_step, variables_average_op]):\n\t        train_op = tf.no_op(name=\"train\")\n\t\n\t    # 初始化持久化类\n\t    saver = tf.train.Saver()\n\t    with tf.Session() as sess:\n\t        tf.global_variables_initializer().run()\n\t\n\t        for i in range(TRAING_STEPS):\n\t            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n\t            _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict={x: xs, y_: ys})\n\t\n\t            if i % 1000 == 0:\n\t                print(\"After %d training step(s), loss on training batch is %g.\" % (i, loss_value))\n\t\n\t                saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)\n\t\n\t\n\tdef main(argv=None):\n\t    mnist = input_data.read_data_sets(\"../MNIST_data\", one_hot=True)\n\t    train(mnist)\n\t\n\t\n\tif __name__ == '__main__':\n\t    tf.app.run()\n\n> mnist_eval.py测试过程\n \n\t#!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2018/2/21 16:32\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : mnist_eval.py\n\t# @ToDo    : 测试过程\n\t\n\t\n\timport time\n\timport tensorflow as tf\n\tfrom tensorflow.examples.tutorials.mnist import input_data\n\t\n\timport neural_network_learning.hand_writting_refactor.mnist_inference as mnist_inference\n\timport neural_network_learning.hand_writting_refactor.mnist_train as mnist_train\n\t\n\t# 每10s加载一次最新模型，并在测试数据上测试最新模型的正确率\n\tEVAL_INTERVAL_SECS = 10\n\t\n\t\n\tdef evaluate(mnist):\n\t    x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name=\"input-x\")\n\t    y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name=\"input-y\")\n\t\n\t    validate_feed = {x: mnist.validation.images,\n\t                     y_: mnist.validation.labels}\n\t\n\t    y = mnist_inference.inference(x, None)\n\t\n\t    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n\t    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\t\n\t    variable_averages = tf.train.ExponentialMovingAverage(mnist_train.MOVING_AVERAGE_DECAY)\n\t    variables_to_restore = variable_averages.variables_to_restore()\n\t    saver = tf.train.Saver(variables_to_restore)\n\t\n\t    # 每隔EVAL_INTERVAL_SECS秒调用一次计算正确率的过程以检测训练过程中正确率的变化\n\t    stop_count = 0\n\t    while True:\n\t        with tf.Session() as sess:\n\t            ckpt = tf.train.get_checkpoint_state(mnist_train.MODEL_SAVE_PATH)\n\t            # 停止条件 #\n\t            stop_count += EVAL_INTERVAL_SECS\n\t            if stop_count == mnist_train.TRAING_STEPS:\n\t                return\n\t            # 停止条件 #\n\t            if ckpt and ckpt.model_checkpoint_path:\n\t                saver.restore(sess, ckpt.model_checkpoint_path)\n\t                # 通过文件名得到模型保存时迭代的轮数\n\t                # 输出./model/model.ckpt-29001\n\t                print(ckpt.model_checkpoint_path)\n\t                global_step = ckpt.model_checkpoint_path.split(\"/\")[-1].split(\"-\")[-1]\n\t                accuracy_score = sess.run(accuracy, feed_dict=validate_feed)\n\t                print(\"After %s training step(s), validation accuracy is %g\" % (global_step, accuracy_score))\n\t            else:\n\t                print(\"No checkpoint file found\")\n\t                return\n\t        time.sleep(EVAL_INTERVAL_SECS)\n\t\n\t\n\tdef main(argv=None):\n\t    mnist = input_data.read_data_sets(\"../MNIST_data\", one_hot=True)\n\t    evaluate(mnist)\n\t\n\t\n\tif __name__ == '__main__':\n\t    tf.app.run()\n\n# 参考文章 #\n[https://www.cnblogs.com/shihuc/p/6648130.html](https://www.cnblogs.com/shihuc/p/6648130.html \"Tensorflow之基于MNIST手写识别的入门介绍\")\n\n\n\n\n\n\n\n\n\n\n\n","slug":"Mnist手写数字体识别-tensorflow","published":1,"updated":"2018-03-23T10:21:49.158Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf3srot50002usu8umy7089g","content":"<h1 id=\"Tensorflow\"><a href=\"#Tensorflow\" class=\"headerlink\" title=\"Tensorflow\"></a>Tensorflow</h1><blockquote>\n<p>首先，简单的说下，tensorflow的基本架构。<br>使用 TensorFlow, 你必须明白 TensorFlow:</p>\n</blockquote>\n<ul>\n<li>使用图 (graph) 来表示计算任务.</li>\n<li>在被称之为 会话 (Session) 的上下文 (context) 中执行图.</li>\n<li>使用 tensor 表示数据.</li>\n<li>通过 变量 (Variable) 维护状态.</li>\n<li>使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.</li>\n</ul>\n<a id=\"more\"></a>\n<h1 id=\"Tensor\"><a href=\"#Tensor\" class=\"headerlink\" title=\"Tensor\"></a>Tensor</h1><blockquote>\n<p>TensorFlow 是一个编程系统, 使用图来表示计算任务. 图中的节点被称之为 op (operation 的缩写). 一个 op 获得 0 个或多个 Tensor, 执行计算, 产生 0 个或多个 Tensor. 每个 Tensor 是一个类型化的多维数组. 例如, 你可以将一小组图像集表示为一个四维浮点数数组, 这四个维度分别是 [batch, height, width, channels].</p>\n</blockquote>\n<blockquote>\n<p>一个 TensorFlow 图描述了计算的过程. 为了进行计算, 图必须在 会话 里被启动. 会话 将图的 op 分发到诸如 CPU 或 GPU 之类的 设备 上, 同时提供执行 op 的方法. 这些方法执行后, 将产生的 tensor 返回. 在 Python 语言中, 返回的 tensor 是 numpy ndarray 对象; 在 C 和 C++ 语言中, 返回的 tensor 是tensorflow::Tensor 实例.</p>\n</blockquote>\n<blockquote>\n<p>Tensor是tensorflow中非常重要且非常基础的概念，可以说数据的呈现形式都是用tensor表示的。输入输出都是tensor，tensor的中文含义，就是张量，可以简单的理解为线性代数里面的向量或者矩阵。</p>\n</blockquote>\n<h1 id=\"Graph\"><a href=\"#Graph\" class=\"headerlink\" title=\"Graph\"></a>Graph</h1><blockquote>\n<p>TensorFlow 程序通常被组织成一个构建阶段和一个执行阶段. 在构建阶段, op 的执行步骤 被描述成一个图. 在执行阶段, 使用会话执行执行图中的 op.</p>\n</blockquote>\n<blockquote>\n<p>例如, 通常在构建阶段创建一个图来表示和训练神经网络, 然后在执行阶段反复执行图中的训练 op. 下面这个图，就是一个比较形象的说明，图中的每一个节点，就是一个op，各个op透过tensor数据流向形成边的连接，构成了一个图。</p>\n</blockquote>\n<p><img src=\"https://images2015.cnblogs.com/blog/844237/201703/844237-20170330093311608-2056024255.gif\" alt=\"\"></p>\n<blockquote>\n<p>构建图的第一步, 是创建源 op (source op). 源 op 不需要任何输入, 例如 常量 (Constant). 源 op 的输出被传递给其它 op 做运算. Python 库中, op 构造器的返回值代表被构造出的 op 的输出, 这些返回值可以传递给其它 op 构造器作为输入.</p>\n</blockquote>\n<blockquote>\n<p>TensorFlow Python 库有一个默认图 (default graph), op 构造器可以为其增加节点. 这个默认图对 许多程序来说已经足够用了.</p>\n</blockquote>\n<h1 id=\"Session\"><a href=\"#Session\" class=\"headerlink\" title=\"Session\"></a>Session</h1><blockquote>\n<p>当图构建好后，需要创建一个Session来运行构建好的图，来实现逻辑，创建session的时候，若无任何参数，tensorflow将启用默认的session。session.run(xxx)是比较典型的使用方案, session运行结束后，返回值是一个tensor。</p>\n</blockquote>\n<blockquote>\n<p>tensorflow中的session，有两大类，一种就是普通的session，即tensorflow.Session(),还有一种是交互式session，即tensorflow.InteractiveSession(). 使用Tensor.eval() 和Operation.run()方法代替Session.run(). 这样可以避免使用一个变量来持有会话, 为程序架构的设计添加了灵活性.</p>\n</blockquote>\n<h1 id=\"数据载体\"><a href=\"#数据载体\" class=\"headerlink\" title=\"数据载体\"></a>数据载体</h1><blockquote>\n<p>Tensorflow体系下，变量（Variable）是用来维护图计算过程中的中间状态信息，是一种常见高频使用的数据载体，还有一种特殊的数据载体，那就是常量（Constant），主要是用作图处理过程的输入量。这些数据载体，也都是以Tensor的形式体现。变量定义和常量定义上，比较好理解：</p>\n</blockquote>\n<pre><code># 创建一个变量, 初始化为标量0.没有指定数据类型（dtype）\nstate = tf.Variable(0, name=&quot;counter&quot;)\n\n# 创建一个常量，其值为1，没有指定数据类型（dtype）\none = tf.constant(1)\n</code></pre><blockquote>\n<p>针对上面的变量和常量，看看Tensorflow里面的函数定义：</p>\n</blockquote>\n<pre><code>class Variable(object):　\ndef __init__(self,\n    initial_value=None,\n    trainable=True,\n    collections=None,\n    validate_shape=True,\n    caching_device=None,\n    name=None,\n    variable_def=None,\n    dtype=None,\n    expected_shape=None,\n    import_scope=None)：\n</code></pre><blockquote>\n</blockquote>\n<pre><code>def constant(value, dtype=None, shape=None, name=&quot;Const&quot;, verify_shape=False)：\n</code></pre><blockquote>\n<p>从上面的源码可以看出，定义变量，其实就是定义了一个Variable的实例，而定义常量，其实就是调用了一下常量函数，创建了一个常量Tensor。</p>\n</blockquote>\n<blockquote>\n<p>还有一个很重要的概念，那就是占位符placeholder，这个在Tensorflow中进行Feed数据灌入时，很有用。所谓的数据灌入，指的是在创建Tensorflow的图时，节点的输入部分，就是一个placeholder，后续在执行session操作的前，将实际数据Feed到图中，进行执行即可。</p>\n</blockquote>\n<pre><code>input1 = tf.placeholder(tf.types.float32)\ninput2 = tf.placeholder(tf.types.float32)\noutput = tf.mul(input1, input2)\n</code></pre><blockquote>\n<pre><code>with tf.Session() as sess:\n  print sess.run([output], feed_dict={input1:[7.], input2:[2.]})\n</code></pre></blockquote>\n<pre><code># 输出:\n# [array([ 14.], dtype=float32)]\n</code></pre><blockquote>\n<p>占位符的定义原型，也是一个函数：</p>\n</blockquote>\n<pre><code>def placeholder(dtype, shape=None, name=None)：\n</code></pre><blockquote>\n<p>到此，Tensorflow的入门级的基本知识介绍完了。下面，将结合一个MNIST的手写识别的例子，从代码上简单分析一下，源代码分成4个文件：</p>\n</blockquote>\n<hr>\n<blockquote>\n<p>main.py驱动程序</p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2018/2/21 20:41\n# @Author  : Jasontang\n# @Site    : \n# @File    : main.py\n# @ToDo    : 驱动程序\n\nimport _thread\n\nfrom neural_network_learning.hand_writting_refactor import mnist_train, mnist_eval\n\n\nif __name__ == &apos;__main__&apos;:\n    _thread.start_new_thread(mnist_train.main, (None,))\n    _thread.start_new_thread(mnist_eval.main, (None,))\n\n    # 这个不能删除，当做主线程\n    while 1:\n        pass\n</code></pre><blockquote>\n<p>mnist_inference.py计算前向传播的过程及定义了神经网络的参数</p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2018/2/20 19:43\n# @Author  : Jasontang\n# @Site    : \n# @File    : mnist_inference.py\n# @ToDo    : 定义了前向传播的过程及神经网络的参数\n\n\nimport tensorflow as tf\n\n# 定义神经网络结构相关的参数\nINPUT_NODE = 784\nOUTPUT_NODE = 10\nLAYER1_NODE = 500\n\n\n# 训练时会创建这些变量，测试时会通过保存的模型加载这些变量的取值\ndef get_weight_variable(shape, regularizer):\n    weights = tf.get_variable(&quot;weights&quot;, shape, initializer=tf.truncated_normal_initializer(stddev=0.1))\n\n    # 当使用正则化生成函数时,当前变量的正则化损失加入名字为losses的集合.\n    # 自定义集合\n    if regularizer:\n        tf.add_to_collection(&quot;losses&quot;, regularizer(weights))\n    return weights\n\n\n# 前向传播过程\ndef inference(input_tensor, regularizer):\n    # 声明第一层神经网络的变量并完成前向传播过程\n    with tf.variable_scope(&quot;layer1&quot;):\n        weights = get_weight_variable([INPUT_NODE, LAYER1_NODE], regularizer)\n        biases = tf.get_variable(&quot;biases&quot;, [LAYER1_NODE], initializer=tf.constant_initializer(0.0))\n        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights) + biases)\n\n    # 声明第二层圣经网络变量并完成前向传播过程\n    with tf.variable_scope(&quot;layer2&quot;):\n        weights = get_weight_variable([LAYER1_NODE, OUTPUT_NODE], regularizer)\n        biases = tf.get_variable(&quot;biases&quot;, [OUTPUT_NODE], initializer=tf.constant_initializer(0.0))\n        layer2 = tf.matmul(layer1, weights) + biases\n    # 返回最后前向传播的结果\n    return layer2\n</code></pre><blockquote>\n<p>mnist_train.py定义了神经网络的训练过程</p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2018/2/21 16:08\n# @Author  : Jasontang\n# @Site    : \n# @File    : mnist_train.py\n# @ToDo    : 定义了神经网络的训练过程\n\nimport os\n\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nimport neural_network_learning.hand_writting_refactor.mnist_inference as mnist_inference\n\n# 配置神经网络的参数\nBATCH_SIZE = 100\nLEARNING_REATE_BASE = 0.8\nLEARNING_RATE_DECAY = 0.99\nREGULARAZTION_RATE = 0.0001\nTRAING_STEPS = 2000\nMOVING_AVERAGE_DECAY = 0.99\n# 模型保存的路径和文件名\nMODEL_SAVE_PATH = &quot;./model/&quot;\nMODEL_NAME = &quot;model.ckpt&quot;\n\n\ndef train(mnist):\n    # 定义输入输出placeholder\n    x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name=&quot;input-x&quot;)\n    y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name=&quot;input-y&quot;)\n\n    regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)\n    y = mnist_inference.inference(x, regularizer)\n    global_step = tf.Variable(0, trainable=False)\n\n    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n    variables_average_op = variable_averages.apply(tf.trainable_variables())\n    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.argmax(y_, 1), logits=y)\n    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n    loss = cross_entropy_mean + tf.add_n(tf.get_collection(&quot;losses&quot;))\n    learing_rate = tf.train.exponential_decay(LEARNING_REATE_BASE,\n                                              global_step,\n                                              mnist.train.num_examples / BATCH_SIZE,\n                                              LEARNING_RATE_DECAY)\n    train_step = tf.train.GradientDescentOptimizer(learing_rate).minimize(loss, global_step)\n\n    with tf.control_dependencies([train_step, variables_average_op]):\n        train_op = tf.no_op(name=&quot;train&quot;)\n\n    # 初始化持久化类\n    saver = tf.train.Saver()\n    with tf.Session() as sess:\n        tf.global_variables_initializer().run()\n\n        for i in range(TRAING_STEPS):\n            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n            _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict={x: xs, y_: ys})\n\n            if i % 1000 == 0:\n                print(&quot;After %d training step(s), loss on training batch is %g.&quot; % (i, loss_value))\n\n                saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)\n\n\ndef main(argv=None):\n    mnist = input_data.read_data_sets(&quot;../MNIST_data&quot;, one_hot=True)\n    train(mnist)\n\n\nif __name__ == &apos;__main__&apos;:\n    tf.app.run()\n</code></pre><blockquote>\n<p>mnist_eval.py测试过程</p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2018/2/21 16:32\n# @Author  : Jasontang\n# @Site    : \n# @File    : mnist_eval.py\n# @ToDo    : 测试过程\n\n\nimport time\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nimport neural_network_learning.hand_writting_refactor.mnist_inference as mnist_inference\nimport neural_network_learning.hand_writting_refactor.mnist_train as mnist_train\n\n# 每10s加载一次最新模型，并在测试数据上测试最新模型的正确率\nEVAL_INTERVAL_SECS = 10\n\n\ndef evaluate(mnist):\n    x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name=&quot;input-x&quot;)\n    y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name=&quot;input-y&quot;)\n\n    validate_feed = {x: mnist.validation.images,\n                     y_: mnist.validation.labels}\n\n    y = mnist_inference.inference(x, None)\n\n    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n    variable_averages = tf.train.ExponentialMovingAverage(mnist_train.MOVING_AVERAGE_DECAY)\n    variables_to_restore = variable_averages.variables_to_restore()\n    saver = tf.train.Saver(variables_to_restore)\n\n    # 每隔EVAL_INTERVAL_SECS秒调用一次计算正确率的过程以检测训练过程中正确率的变化\n    stop_count = 0\n    while True:\n        with tf.Session() as sess:\n            ckpt = tf.train.get_checkpoint_state(mnist_train.MODEL_SAVE_PATH)\n            # 停止条件 #\n            stop_count += EVAL_INTERVAL_SECS\n            if stop_count == mnist_train.TRAING_STEPS:\n                return\n            # 停止条件 #\n            if ckpt and ckpt.model_checkpoint_path:\n                saver.restore(sess, ckpt.model_checkpoint_path)\n                # 通过文件名得到模型保存时迭代的轮数\n                # 输出./model/model.ckpt-29001\n                print(ckpt.model_checkpoint_path)\n                global_step = ckpt.model_checkpoint_path.split(&quot;/&quot;)[-1].split(&quot;-&quot;)[-1]\n                accuracy_score = sess.run(accuracy, feed_dict=validate_feed)\n                print(&quot;After %s training step(s), validation accuracy is %g&quot; % (global_step, accuracy_score))\n            else:\n                print(&quot;No checkpoint file found&quot;)\n                return\n        time.sleep(EVAL_INTERVAL_SECS)\n\n\ndef main(argv=None):\n    mnist = input_data.read_data_sets(&quot;../MNIST_data&quot;, one_hot=True)\n    evaluate(mnist)\n\n\nif __name__ == &apos;__main__&apos;:\n    tf.app.run()\n</code></pre><h1 id=\"参考文章\"><a href=\"#参考文章\" class=\"headerlink\" title=\"参考文章\"></a>参考文章</h1><p><a href=\"https://www.cnblogs.com/shihuc/p/6648130.html\" title=\"Tensorflow之基于MNIST手写识别的入门介绍\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/shihuc/p/6648130.html</a></p>\n","site":{"data":{"link":{"social":{"github":"https://github.com/mic-jasontang"},"extern":{"Github地址":"https://github.com/mic-jasontang"}},"reading":{"define":{"readed":"已读","reading":"在读","wanted":"想读"},"contents":{"readed":[{"title":"嫌疑人X的献身","cover":"https://img3.doubanio.com/lpic/s3254244.jpg","review":"百年一遇的数学天才石神，每天唯一的乐趣，便是去固定的便当店买午餐，只为看一眼在便当店做事的邻居靖子。","score":"8.9","doubanLink":"https://book.douban.com/subject/3211779/"},{"title":"Python核心编程（第二版）","cover":"https://img3.doubanio.com/lpic/s3140466.jpg","review":"本书是Python开发者的完全指南——针对 Python 2.5全面升级","score":"7.7","doubanLink":"https://book.douban.com/subject/3112503/"},{"title":"程序员代码面试指南：IT名企算法与数据结构题目最优解","cover":"https://img3.doubanio.com/lpic/s28313721.jpg","review":"这是一本程序员面试宝典！书中对IT名企代码面试各类题目的最优解进行了总结，并提供了相关代码实现。","score":"8.8","doubanLink":"https://book.douban.com/subject/26638586/"},{"title":"机器学习实战","cover":"https://img3.doubanio.com/lpic/s26696371.jpg","review":"全书通过精心编排的实例，切入日常工作任务，摒弃学术化语言，利用高效的可复用Python代码来阐释如何处理统计数据，进行数据分析及可视化。通过各种实例，读者可从中学会机器学习的核心算法，并能将其运用于一些策略性任务中，如分类、预测、推荐。另外，还可用它们来实现一些更高级的功能，如汇总和简化等。","score":"8.2","doubanLink":"https://book.douban.com/subject/24703171/"},{"title":"TensorFlow实战","cover":"https://img3.doubanio.com/lpic/s29343414.jpg","review":"《TensorFlow实战》希望能帮读者快速入门TensorFlow和深度学习，在工业界或者研究中快速地将想法落地为可实践的模型。","score":"7.3","doubanLink":"https://book.douban.com/subject/26974266/"}],"reading":[{"title":"深度学习","cover":"https://img1.doubanio.com/lpic/s29518349.jpg","review":"《深度学习》适合各类读者阅读，包括相关专业的大学生或研究生，以及不具有机器学习或统计背景、但是想要快速补充深度学习知识，以便在实际产品或平台中应用的软件工程师。","score":"8.7","doubanLink":"https://book.douban.com/subject/27087503/"},{"title":"Tensorflow：实战Google深度学习框架","cover":"https://img3.doubanio.com/lpic/s29349250.jpg","review":"《Tensorflow实战》包含了深度学习的入门知识和大量实践经验，是走进这个最新、最火的人工智能领域的首选参考书。","score":"8.2","doubanLink":"https://book.douban.com/subject/26976457/"},{"title":"机器学习","cover":"https://img1.doubanio.com/lpic/s28735609.jpg","review":"本书作为该领域的入门教材，在内容上尽可能涵盖机器学习基础知识的各方面。 为了使尽可能多的读者通过本书对机器学习有所了解, 作者试图尽可能少地使用数学知识. 然而, 少量的概率、统计、代数、优化、逻辑知识似乎不可避免. 因此, 本书更适合大学三年级以上的理工科本科生和研究生, 以及具有类似背景的对机器学 习感兴趣的人士. 为方便读者, 本书附录给出了一些相关数学基础知识简介.","score":"8.7","doubanLink":"https://book.douban.com/subject/26708119/"}],"wanted":[{"title":"OpenCV 3计算机视觉：Python语言实现（原书第2版）","cover":"https://img3.doubanio.com/lpic/s28902360.jpg","review":"本书针对具有一定Python工作经验的程序员以及想要利用OpenCV库研究计算机视觉课题的读者。本书不要求读者具有计算机视觉或OpenCV经验，但要具有编程经验。","score":"7.8","doubanLink":"https://book.douban.com/subject/26816975/"},{"title":"Python计算机视觉编程","cover":"https://img3.doubanio.com/lpic/s27305520.jpg","review":"《python计算机视觉编程》适合的读者是：有一定编程与数学基础，想要了解计算机视觉的基本理论与算法的学生，以及计算机科学、信号处理、物理学、应用数学和统计学、神经生理学、认知科学等领域的研究人员和从业者。","score":"7.5","doubanLink":"https://book.douban.com/subject/25906843/"}]}},"about":{"avatar":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/avatar.jpg","name":"tech.radish","tag":"python/Java/ML/CV","desc":"行走在边缘的coder","skills":{"ptyhon":5,"Java":6,"invisible-split-line-1":-1,"ML":4},"projects":[{"name":"合金战争(Java Swing + MySql + Socket)","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/game.png","tags":["Java","游戏开发"],"description":"合金战争是一款使用JavaSwing作为界面，MySQL作为数据库服务器，使用Socket通信的网络版RPG游戏","link_text":"合金战争","link":null},{"name":"iclass智能课堂助手","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/iclass.png","description":"iclass是一款实用SSM框架开发的轻量级课堂辅助教学系统，旨在加强和方便师生之间的交流合作，提高教学效率。拥有web端和安卓端（本人完成web端和安卓后端的开发）","tags":["毕业设计","SSM框架"],"link_text":"Github地址","link":"https://github.com/Mic-JasonTang/iclass"}],"reward":["https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/alipay-rewardcode.jpg","https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/wetchat-rewardcode.jpg"]},"slider":[{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/coloreggs.jpg","align":"center","title":"computer vision","subtitle":"whole world","link":"/"},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/fantasy.jpg","align":"left","title":"import tensorflow as tf","subtitle":"sess.run(hello)","link":null},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/pythoner.png","align":"right","title":"import __helloworld__","subtitle":">>> Hello World","link":null}],"hint":{"new":{"selector":[".menu-reading"]}}}},"excerpt":"<h1 id=\"Tensorflow\"><a href=\"#Tensorflow\" class=\"headerlink\" title=\"Tensorflow\"></a>Tensorflow</h1><blockquote>\n<p>首先，简单的说下，tensorflow的基本架构。<br>使用 TensorFlow, 你必须明白 TensorFlow:</p>\n</blockquote>\n<ul>\n<li>使用图 (graph) 来表示计算任务.</li>\n<li>在被称之为 会话 (Session) 的上下文 (context) 中执行图.</li>\n<li>使用 tensor 表示数据.</li>\n<li>通过 变量 (Variable) 维护状态.</li>\n<li>使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.</li>\n</ul>","more":"<h1 id=\"Tensor\"><a href=\"#Tensor\" class=\"headerlink\" title=\"Tensor\"></a>Tensor</h1><blockquote>\n<p>TensorFlow 是一个编程系统, 使用图来表示计算任务. 图中的节点被称之为 op (operation 的缩写). 一个 op 获得 0 个或多个 Tensor, 执行计算, 产生 0 个或多个 Tensor. 每个 Tensor 是一个类型化的多维数组. 例如, 你可以将一小组图像集表示为一个四维浮点数数组, 这四个维度分别是 [batch, height, width, channels].</p>\n</blockquote>\n<blockquote>\n<p>一个 TensorFlow 图描述了计算的过程. 为了进行计算, 图必须在 会话 里被启动. 会话 将图的 op 分发到诸如 CPU 或 GPU 之类的 设备 上, 同时提供执行 op 的方法. 这些方法执行后, 将产生的 tensor 返回. 在 Python 语言中, 返回的 tensor 是 numpy ndarray 对象; 在 C 和 C++ 语言中, 返回的 tensor 是tensorflow::Tensor 实例.</p>\n</blockquote>\n<blockquote>\n<p>Tensor是tensorflow中非常重要且非常基础的概念，可以说数据的呈现形式都是用tensor表示的。输入输出都是tensor，tensor的中文含义，就是张量，可以简单的理解为线性代数里面的向量或者矩阵。</p>\n</blockquote>\n<h1 id=\"Graph\"><a href=\"#Graph\" class=\"headerlink\" title=\"Graph\"></a>Graph</h1><blockquote>\n<p>TensorFlow 程序通常被组织成一个构建阶段和一个执行阶段. 在构建阶段, op 的执行步骤 被描述成一个图. 在执行阶段, 使用会话执行执行图中的 op.</p>\n</blockquote>\n<blockquote>\n<p>例如, 通常在构建阶段创建一个图来表示和训练神经网络, 然后在执行阶段反复执行图中的训练 op. 下面这个图，就是一个比较形象的说明，图中的每一个节点，就是一个op，各个op透过tensor数据流向形成边的连接，构成了一个图。</p>\n</blockquote>\n<p><img src=\"https://images2015.cnblogs.com/blog/844237/201703/844237-20170330093311608-2056024255.gif\" alt=\"\"></p>\n<blockquote>\n<p>构建图的第一步, 是创建源 op (source op). 源 op 不需要任何输入, 例如 常量 (Constant). 源 op 的输出被传递给其它 op 做运算. Python 库中, op 构造器的返回值代表被构造出的 op 的输出, 这些返回值可以传递给其它 op 构造器作为输入.</p>\n</blockquote>\n<blockquote>\n<p>TensorFlow Python 库有一个默认图 (default graph), op 构造器可以为其增加节点. 这个默认图对 许多程序来说已经足够用了.</p>\n</blockquote>\n<h1 id=\"Session\"><a href=\"#Session\" class=\"headerlink\" title=\"Session\"></a>Session</h1><blockquote>\n<p>当图构建好后，需要创建一个Session来运行构建好的图，来实现逻辑，创建session的时候，若无任何参数，tensorflow将启用默认的session。session.run(xxx)是比较典型的使用方案, session运行结束后，返回值是一个tensor。</p>\n</blockquote>\n<blockquote>\n<p>tensorflow中的session，有两大类，一种就是普通的session，即tensorflow.Session(),还有一种是交互式session，即tensorflow.InteractiveSession(). 使用Tensor.eval() 和Operation.run()方法代替Session.run(). 这样可以避免使用一个变量来持有会话, 为程序架构的设计添加了灵活性.</p>\n</blockquote>\n<h1 id=\"数据载体\"><a href=\"#数据载体\" class=\"headerlink\" title=\"数据载体\"></a>数据载体</h1><blockquote>\n<p>Tensorflow体系下，变量（Variable）是用来维护图计算过程中的中间状态信息，是一种常见高频使用的数据载体，还有一种特殊的数据载体，那就是常量（Constant），主要是用作图处理过程的输入量。这些数据载体，也都是以Tensor的形式体现。变量定义和常量定义上，比较好理解：</p>\n</blockquote>\n<pre><code># 创建一个变量, 初始化为标量0.没有指定数据类型（dtype）\nstate = tf.Variable(0, name=&quot;counter&quot;)\n\n# 创建一个常量，其值为1，没有指定数据类型（dtype）\none = tf.constant(1)\n</code></pre><blockquote>\n<p>针对上面的变量和常量，看看Tensorflow里面的函数定义：</p>\n</blockquote>\n<pre><code>class Variable(object):　\ndef __init__(self,\n    initial_value=None,\n    trainable=True,\n    collections=None,\n    validate_shape=True,\n    caching_device=None,\n    name=None,\n    variable_def=None,\n    dtype=None,\n    expected_shape=None,\n    import_scope=None)：\n</code></pre><blockquote>\n</blockquote>\n<pre><code>def constant(value, dtype=None, shape=None, name=&quot;Const&quot;, verify_shape=False)：\n</code></pre><blockquote>\n<p>从上面的源码可以看出，定义变量，其实就是定义了一个Variable的实例，而定义常量，其实就是调用了一下常量函数，创建了一个常量Tensor。</p>\n</blockquote>\n<blockquote>\n<p>还有一个很重要的概念，那就是占位符placeholder，这个在Tensorflow中进行Feed数据灌入时，很有用。所谓的数据灌入，指的是在创建Tensorflow的图时，节点的输入部分，就是一个placeholder，后续在执行session操作的前，将实际数据Feed到图中，进行执行即可。</p>\n</blockquote>\n<pre><code>input1 = tf.placeholder(tf.types.float32)\ninput2 = tf.placeholder(tf.types.float32)\noutput = tf.mul(input1, input2)\n</code></pre><blockquote>\n<pre><code>with tf.Session() as sess:\n  print sess.run([output], feed_dict={input1:[7.], input2:[2.]})\n</code></pre></blockquote>\n<pre><code># 输出:\n# [array([ 14.], dtype=float32)]\n</code></pre><blockquote>\n<p>占位符的定义原型，也是一个函数：</p>\n</blockquote>\n<pre><code>def placeholder(dtype, shape=None, name=None)：\n</code></pre><blockquote>\n<p>到此，Tensorflow的入门级的基本知识介绍完了。下面，将结合一个MNIST的手写识别的例子，从代码上简单分析一下，源代码分成4个文件：</p>\n</blockquote>\n<hr>\n<blockquote>\n<p>main.py驱动程序</p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2018/2/21 20:41\n# @Author  : Jasontang\n# @Site    : \n# @File    : main.py\n# @ToDo    : 驱动程序\n\nimport _thread\n\nfrom neural_network_learning.hand_writting_refactor import mnist_train, mnist_eval\n\n\nif __name__ == &apos;__main__&apos;:\n    _thread.start_new_thread(mnist_train.main, (None,))\n    _thread.start_new_thread(mnist_eval.main, (None,))\n\n    # 这个不能删除，当做主线程\n    while 1:\n        pass\n</code></pre><blockquote>\n<p>mnist_inference.py计算前向传播的过程及定义了神经网络的参数</p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2018/2/20 19:43\n# @Author  : Jasontang\n# @Site    : \n# @File    : mnist_inference.py\n# @ToDo    : 定义了前向传播的过程及神经网络的参数\n\n\nimport tensorflow as tf\n\n# 定义神经网络结构相关的参数\nINPUT_NODE = 784\nOUTPUT_NODE = 10\nLAYER1_NODE = 500\n\n\n# 训练时会创建这些变量，测试时会通过保存的模型加载这些变量的取值\ndef get_weight_variable(shape, regularizer):\n    weights = tf.get_variable(&quot;weights&quot;, shape, initializer=tf.truncated_normal_initializer(stddev=0.1))\n\n    # 当使用正则化生成函数时,当前变量的正则化损失加入名字为losses的集合.\n    # 自定义集合\n    if regularizer:\n        tf.add_to_collection(&quot;losses&quot;, regularizer(weights))\n    return weights\n\n\n# 前向传播过程\ndef inference(input_tensor, regularizer):\n    # 声明第一层神经网络的变量并完成前向传播过程\n    with tf.variable_scope(&quot;layer1&quot;):\n        weights = get_weight_variable([INPUT_NODE, LAYER1_NODE], regularizer)\n        biases = tf.get_variable(&quot;biases&quot;, [LAYER1_NODE], initializer=tf.constant_initializer(0.0))\n        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights) + biases)\n\n    # 声明第二层圣经网络变量并完成前向传播过程\n    with tf.variable_scope(&quot;layer2&quot;):\n        weights = get_weight_variable([LAYER1_NODE, OUTPUT_NODE], regularizer)\n        biases = tf.get_variable(&quot;biases&quot;, [OUTPUT_NODE], initializer=tf.constant_initializer(0.0))\n        layer2 = tf.matmul(layer1, weights) + biases\n    # 返回最后前向传播的结果\n    return layer2\n</code></pre><blockquote>\n<p>mnist_train.py定义了神经网络的训练过程</p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2018/2/21 16:08\n# @Author  : Jasontang\n# @Site    : \n# @File    : mnist_train.py\n# @ToDo    : 定义了神经网络的训练过程\n\nimport os\n\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nimport neural_network_learning.hand_writting_refactor.mnist_inference as mnist_inference\n\n# 配置神经网络的参数\nBATCH_SIZE = 100\nLEARNING_REATE_BASE = 0.8\nLEARNING_RATE_DECAY = 0.99\nREGULARAZTION_RATE = 0.0001\nTRAING_STEPS = 2000\nMOVING_AVERAGE_DECAY = 0.99\n# 模型保存的路径和文件名\nMODEL_SAVE_PATH = &quot;./model/&quot;\nMODEL_NAME = &quot;model.ckpt&quot;\n\n\ndef train(mnist):\n    # 定义输入输出placeholder\n    x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name=&quot;input-x&quot;)\n    y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name=&quot;input-y&quot;)\n\n    regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)\n    y = mnist_inference.inference(x, regularizer)\n    global_step = tf.Variable(0, trainable=False)\n\n    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n    variables_average_op = variable_averages.apply(tf.trainable_variables())\n    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.argmax(y_, 1), logits=y)\n    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n    loss = cross_entropy_mean + tf.add_n(tf.get_collection(&quot;losses&quot;))\n    learing_rate = tf.train.exponential_decay(LEARNING_REATE_BASE,\n                                              global_step,\n                                              mnist.train.num_examples / BATCH_SIZE,\n                                              LEARNING_RATE_DECAY)\n    train_step = tf.train.GradientDescentOptimizer(learing_rate).minimize(loss, global_step)\n\n    with tf.control_dependencies([train_step, variables_average_op]):\n        train_op = tf.no_op(name=&quot;train&quot;)\n\n    # 初始化持久化类\n    saver = tf.train.Saver()\n    with tf.Session() as sess:\n        tf.global_variables_initializer().run()\n\n        for i in range(TRAING_STEPS):\n            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n            _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict={x: xs, y_: ys})\n\n            if i % 1000 == 0:\n                print(&quot;After %d training step(s), loss on training batch is %g.&quot; % (i, loss_value))\n\n                saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)\n\n\ndef main(argv=None):\n    mnist = input_data.read_data_sets(&quot;../MNIST_data&quot;, one_hot=True)\n    train(mnist)\n\n\nif __name__ == &apos;__main__&apos;:\n    tf.app.run()\n</code></pre><blockquote>\n<p>mnist_eval.py测试过程</p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2018/2/21 16:32\n# @Author  : Jasontang\n# @Site    : \n# @File    : mnist_eval.py\n# @ToDo    : 测试过程\n\n\nimport time\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nimport neural_network_learning.hand_writting_refactor.mnist_inference as mnist_inference\nimport neural_network_learning.hand_writting_refactor.mnist_train as mnist_train\n\n# 每10s加载一次最新模型，并在测试数据上测试最新模型的正确率\nEVAL_INTERVAL_SECS = 10\n\n\ndef evaluate(mnist):\n    x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name=&quot;input-x&quot;)\n    y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name=&quot;input-y&quot;)\n\n    validate_feed = {x: mnist.validation.images,\n                     y_: mnist.validation.labels}\n\n    y = mnist_inference.inference(x, None)\n\n    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n    variable_averages = tf.train.ExponentialMovingAverage(mnist_train.MOVING_AVERAGE_DECAY)\n    variables_to_restore = variable_averages.variables_to_restore()\n    saver = tf.train.Saver(variables_to_restore)\n\n    # 每隔EVAL_INTERVAL_SECS秒调用一次计算正确率的过程以检测训练过程中正确率的变化\n    stop_count = 0\n    while True:\n        with tf.Session() as sess:\n            ckpt = tf.train.get_checkpoint_state(mnist_train.MODEL_SAVE_PATH)\n            # 停止条件 #\n            stop_count += EVAL_INTERVAL_SECS\n            if stop_count == mnist_train.TRAING_STEPS:\n                return\n            # 停止条件 #\n            if ckpt and ckpt.model_checkpoint_path:\n                saver.restore(sess, ckpt.model_checkpoint_path)\n                # 通过文件名得到模型保存时迭代的轮数\n                # 输出./model/model.ckpt-29001\n                print(ckpt.model_checkpoint_path)\n                global_step = ckpt.model_checkpoint_path.split(&quot;/&quot;)[-1].split(&quot;-&quot;)[-1]\n                accuracy_score = sess.run(accuracy, feed_dict=validate_feed)\n                print(&quot;After %s training step(s), validation accuracy is %g&quot; % (global_step, accuracy_score))\n            else:\n                print(&quot;No checkpoint file found&quot;)\n                return\n        time.sleep(EVAL_INTERVAL_SECS)\n\n\ndef main(argv=None):\n    mnist = input_data.read_data_sets(&quot;../MNIST_data&quot;, one_hot=True)\n    evaluate(mnist)\n\n\nif __name__ == &apos;__main__&apos;:\n    tf.app.run()\n</code></pre><h1 id=\"参考文章\"><a href=\"#参考文章\" class=\"headerlink\" title=\"参考文章\"></a>参考文章</h1><p><a href=\"https://www.cnblogs.com/shihuc/p/6648130.html\" title=\"Tensorflow之基于MNIST手写识别的入门介绍\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/shihuc/p/6648130.html</a></p>"},{"title":"关于k阶矩的理解","date":"2018-03-22T13:44:18.000Z","_content":"\n# k阶原点矩、2阶矩、3阶矩该怎么理解？ #\n\n下面使用语言描述和代码来讲解。\n<!-- more -->\n\n> 阶矩是用来描述随机变量的概率分布的特性.\n\n> 一阶矩指的是随机变量的平均值,即期望值\n> \n> 二阶矩指的是随机变量的方差\n> \n> 三阶矩指的是随机变量的偏度\n> \n> 四阶矩指的是随机变量的峰度\n \n> 因此通过计算矩,则可以得出随机变量的分布形状\n\n# 代码实现 #\n使用Python2.0实现\n\n    import numpy as np\n\tfrom scipy import stats\n\t\n\t\n\tdef calc_statistics(x):\n\tn = x.shape[0]   #样本个数\n\n\t# 手动计算\n\tm = 0\n\tm2 = 0\n\tm3 = 0\n\tm4 = 0\n\tfor t in x:\n\t\tm += t\n\t\tm2 += t*t\n\t\tm3 += t**3\n\t\tm4 += t**4\n\tm /= n\n\tm2 /= n\n\tm3 /= n\n\tm4 /= n\n\n\tmu = m    # 一阶矩\n\tsigma = np.sqrt(m2 - mu*mu)   # 二阶矩\n\tskew = (m3 - 3*mu*m2 + 2*mu**3) / sigma**3    # 三阶矩（偏度）\n\tkurtosis = (m4 - 4*mu*m3 + 6*mu*mu*m2 - 4*mu**3*mu + mu**4) / sigma**4 - 3\t# 四阶矩（峰度）\n\tprint \"手动计算均值、标准差、偏度、峰度：\", mu, sigma, skew, kurtosis\n\n\t# 使用系统函数验证\n\tmu = np.mean(x, axis=0)\n\tsigma = np.std(x, axis=0)\n\tskew = stats.skew(x)\n\tkurtosis = stats.kurtosis(x)\n\treturn mu, sigma, skew, kurtosis\n\n\tif __name__ == '__main__':\n\td = np.random.randn(10000)\n\tprint d\n\tprint d.shape\n\tmu, sigma, skew, kurtosis = calc_statistics(d)\n\tprint \"函数库计算均值、标准差、偏度、峰度：\", mu, sigma, skew, kurtosis\n\t\n执行结果:\n\t\n\t\n> [-0.42751577  0.36230961  0.37899409 ...,  0.09176115 -1.38955563\n -0.57570736]\n\n\n> (10000L,)\n\n\n> 手动计算均值、标准差、偏度、峰度： -0.00189350820374 0.995018151945 -0.00589521484127 -0.0590604043446\n\n\n> 函数库计算均值、标准差、偏度、峰度： -0.00189350820374 0.995018151945 -0.00589521484127 -0.0590604043446\n","source":"_posts/关于k阶矩的理解.md","raw":"---\ntitle: 关于k阶矩的理解\ndate: 2018-03-22 21:44:18\ncategories:\n- 数学基础\n- 随机过程\ntags:\n- k阶矩\n- 随机过程\n- 偏度\n- 峰度\n---\n\n# k阶原点矩、2阶矩、3阶矩该怎么理解？ #\n\n下面使用语言描述和代码来讲解。\n<!-- more -->\n\n> 阶矩是用来描述随机变量的概率分布的特性.\n\n> 一阶矩指的是随机变量的平均值,即期望值\n> \n> 二阶矩指的是随机变量的方差\n> \n> 三阶矩指的是随机变量的偏度\n> \n> 四阶矩指的是随机变量的峰度\n \n> 因此通过计算矩,则可以得出随机变量的分布形状\n\n# 代码实现 #\n使用Python2.0实现\n\n    import numpy as np\n\tfrom scipy import stats\n\t\n\t\n\tdef calc_statistics(x):\n\tn = x.shape[0]   #样本个数\n\n\t# 手动计算\n\tm = 0\n\tm2 = 0\n\tm3 = 0\n\tm4 = 0\n\tfor t in x:\n\t\tm += t\n\t\tm2 += t*t\n\t\tm3 += t**3\n\t\tm4 += t**4\n\tm /= n\n\tm2 /= n\n\tm3 /= n\n\tm4 /= n\n\n\tmu = m    # 一阶矩\n\tsigma = np.sqrt(m2 - mu*mu)   # 二阶矩\n\tskew = (m3 - 3*mu*m2 + 2*mu**3) / sigma**3    # 三阶矩（偏度）\n\tkurtosis = (m4 - 4*mu*m3 + 6*mu*mu*m2 - 4*mu**3*mu + mu**4) / sigma**4 - 3\t# 四阶矩（峰度）\n\tprint \"手动计算均值、标准差、偏度、峰度：\", mu, sigma, skew, kurtosis\n\n\t# 使用系统函数验证\n\tmu = np.mean(x, axis=0)\n\tsigma = np.std(x, axis=0)\n\tskew = stats.skew(x)\n\tkurtosis = stats.kurtosis(x)\n\treturn mu, sigma, skew, kurtosis\n\n\tif __name__ == '__main__':\n\td = np.random.randn(10000)\n\tprint d\n\tprint d.shape\n\tmu, sigma, skew, kurtosis = calc_statistics(d)\n\tprint \"函数库计算均值、标准差、偏度、峰度：\", mu, sigma, skew, kurtosis\n\t\n执行结果:\n\t\n\t\n> [-0.42751577  0.36230961  0.37899409 ...,  0.09176115 -1.38955563\n -0.57570736]\n\n\n> (10000L,)\n\n\n> 手动计算均值、标准差、偏度、峰度： -0.00189350820374 0.995018151945 -0.00589521484127 -0.0590604043446\n\n\n> 函数库计算均值、标准差、偏度、峰度： -0.00189350820374 0.995018151945 -0.00589521484127 -0.0590604043446\n","slug":"关于k阶矩的理解","published":1,"updated":"2018-03-23T10:21:49.158Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf3srot90006usu80w7yrwmd","content":"<h1 id=\"k阶原点矩、2阶矩、3阶矩该怎么理解？\"><a href=\"#k阶原点矩、2阶矩、3阶矩该怎么理解？\" class=\"headerlink\" title=\"k阶原点矩、2阶矩、3阶矩该怎么理解？\"></a>k阶原点矩、2阶矩、3阶矩该怎么理解？</h1><p>下面使用语言描述和代码来讲解。<br><a id=\"more\"></a></p>\n<blockquote>\n<p>阶矩是用来描述随机变量的概率分布的特性.</p>\n</blockquote>\n<blockquote>\n<p>一阶矩指的是随机变量的平均值,即期望值</p>\n<p>二阶矩指的是随机变量的方差</p>\n<p>三阶矩指的是随机变量的偏度</p>\n<p>四阶矩指的是随机变量的峰度</p>\n</blockquote>\n<blockquote>\n<p>因此通过计算矩,则可以得出随机变量的分布形状</p>\n</blockquote>\n<h1 id=\"代码实现\"><a href=\"#代码实现\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h1><p>使用Python2.0实现</p>\n<pre><code>import numpy as np\nfrom scipy import stats\n\n\ndef calc_statistics(x):\nn = x.shape[0]   #样本个数\n\n# 手动计算\nm = 0\nm2 = 0\nm3 = 0\nm4 = 0\nfor t in x:\n    m += t\n    m2 += t*t\n    m3 += t**3\n    m4 += t**4\nm /= n\nm2 /= n\nm3 /= n\nm4 /= n\n\nmu = m    # 一阶矩\nsigma = np.sqrt(m2 - mu*mu)   # 二阶矩\nskew = (m3 - 3*mu*m2 + 2*mu**3) / sigma**3    # 三阶矩（偏度）\nkurtosis = (m4 - 4*mu*m3 + 6*mu*mu*m2 - 4*mu**3*mu + mu**4) / sigma**4 - 3    # 四阶矩（峰度）\nprint &quot;手动计算均值、标准差、偏度、峰度：&quot;, mu, sigma, skew, kurtosis\n\n# 使用系统函数验证\nmu = np.mean(x, axis=0)\nsigma = np.std(x, axis=0)\nskew = stats.skew(x)\nkurtosis = stats.kurtosis(x)\nreturn mu, sigma, skew, kurtosis\n\nif __name__ == &apos;__main__&apos;:\nd = np.random.randn(10000)\nprint d\nprint d.shape\nmu, sigma, skew, kurtosis = calc_statistics(d)\nprint &quot;函数库计算均值、标准差、偏度、峰度：&quot;, mu, sigma, skew, kurtosis\n</code></pre><p>执行结果:</p>\n<blockquote>\n<p>[-0.42751577  0.36230961  0.37899409 …,  0.09176115 -1.38955563<br> -0.57570736]</p>\n</blockquote>\n<blockquote>\n<p>(10000L,)</p>\n</blockquote>\n<blockquote>\n<p>手动计算均值、标准差、偏度、峰度： -0.00189350820374 0.995018151945 -0.00589521484127 -0.0590604043446</p>\n</blockquote>\n<blockquote>\n<p>函数库计算均值、标准差、偏度、峰度： -0.00189350820374 0.995018151945 -0.00589521484127 -0.0590604043446</p>\n</blockquote>\n","site":{"data":{"link":{"social":{"github":"https://github.com/mic-jasontang"},"extern":{"Github地址":"https://github.com/mic-jasontang"}},"reading":{"define":{"readed":"已读","reading":"在读","wanted":"想读"},"contents":{"readed":[{"title":"嫌疑人X的献身","cover":"https://img3.doubanio.com/lpic/s3254244.jpg","review":"百年一遇的数学天才石神，每天唯一的乐趣，便是去固定的便当店买午餐，只为看一眼在便当店做事的邻居靖子。","score":"8.9","doubanLink":"https://book.douban.com/subject/3211779/"},{"title":"Python核心编程（第二版）","cover":"https://img3.doubanio.com/lpic/s3140466.jpg","review":"本书是Python开发者的完全指南——针对 Python 2.5全面升级","score":"7.7","doubanLink":"https://book.douban.com/subject/3112503/"},{"title":"程序员代码面试指南：IT名企算法与数据结构题目最优解","cover":"https://img3.doubanio.com/lpic/s28313721.jpg","review":"这是一本程序员面试宝典！书中对IT名企代码面试各类题目的最优解进行了总结，并提供了相关代码实现。","score":"8.8","doubanLink":"https://book.douban.com/subject/26638586/"},{"title":"机器学习实战","cover":"https://img3.doubanio.com/lpic/s26696371.jpg","review":"全书通过精心编排的实例，切入日常工作任务，摒弃学术化语言，利用高效的可复用Python代码来阐释如何处理统计数据，进行数据分析及可视化。通过各种实例，读者可从中学会机器学习的核心算法，并能将其运用于一些策略性任务中，如分类、预测、推荐。另外，还可用它们来实现一些更高级的功能，如汇总和简化等。","score":"8.2","doubanLink":"https://book.douban.com/subject/24703171/"},{"title":"TensorFlow实战","cover":"https://img3.doubanio.com/lpic/s29343414.jpg","review":"《TensorFlow实战》希望能帮读者快速入门TensorFlow和深度学习，在工业界或者研究中快速地将想法落地为可实践的模型。","score":"7.3","doubanLink":"https://book.douban.com/subject/26974266/"}],"reading":[{"title":"深度学习","cover":"https://img1.doubanio.com/lpic/s29518349.jpg","review":"《深度学习》适合各类读者阅读，包括相关专业的大学生或研究生，以及不具有机器学习或统计背景、但是想要快速补充深度学习知识，以便在实际产品或平台中应用的软件工程师。","score":"8.7","doubanLink":"https://book.douban.com/subject/27087503/"},{"title":"Tensorflow：实战Google深度学习框架","cover":"https://img3.doubanio.com/lpic/s29349250.jpg","review":"《Tensorflow实战》包含了深度学习的入门知识和大量实践经验，是走进这个最新、最火的人工智能领域的首选参考书。","score":"8.2","doubanLink":"https://book.douban.com/subject/26976457/"},{"title":"机器学习","cover":"https://img1.doubanio.com/lpic/s28735609.jpg","review":"本书作为该领域的入门教材，在内容上尽可能涵盖机器学习基础知识的各方面。 为了使尽可能多的读者通过本书对机器学习有所了解, 作者试图尽可能少地使用数学知识. 然而, 少量的概率、统计、代数、优化、逻辑知识似乎不可避免. 因此, 本书更适合大学三年级以上的理工科本科生和研究生, 以及具有类似背景的对机器学 习感兴趣的人士. 为方便读者, 本书附录给出了一些相关数学基础知识简介.","score":"8.7","doubanLink":"https://book.douban.com/subject/26708119/"}],"wanted":[{"title":"OpenCV 3计算机视觉：Python语言实现（原书第2版）","cover":"https://img3.doubanio.com/lpic/s28902360.jpg","review":"本书针对具有一定Python工作经验的程序员以及想要利用OpenCV库研究计算机视觉课题的读者。本书不要求读者具有计算机视觉或OpenCV经验，但要具有编程经验。","score":"7.8","doubanLink":"https://book.douban.com/subject/26816975/"},{"title":"Python计算机视觉编程","cover":"https://img3.doubanio.com/lpic/s27305520.jpg","review":"《python计算机视觉编程》适合的读者是：有一定编程与数学基础，想要了解计算机视觉的基本理论与算法的学生，以及计算机科学、信号处理、物理学、应用数学和统计学、神经生理学、认知科学等领域的研究人员和从业者。","score":"7.5","doubanLink":"https://book.douban.com/subject/25906843/"}]}},"about":{"avatar":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/avatar.jpg","name":"tech.radish","tag":"python/Java/ML/CV","desc":"行走在边缘的coder","skills":{"ptyhon":5,"Java":6,"invisible-split-line-1":-1,"ML":4},"projects":[{"name":"合金战争(Java Swing + MySql + Socket)","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/game.png","tags":["Java","游戏开发"],"description":"合金战争是一款使用JavaSwing作为界面，MySQL作为数据库服务器，使用Socket通信的网络版RPG游戏","link_text":"合金战争","link":null},{"name":"iclass智能课堂助手","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/iclass.png","description":"iclass是一款实用SSM框架开发的轻量级课堂辅助教学系统，旨在加强和方便师生之间的交流合作，提高教学效率。拥有web端和安卓端（本人完成web端和安卓后端的开发）","tags":["毕业设计","SSM框架"],"link_text":"Github地址","link":"https://github.com/Mic-JasonTang/iclass"}],"reward":["https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/alipay-rewardcode.jpg","https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/wetchat-rewardcode.jpg"]},"slider":[{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/coloreggs.jpg","align":"center","title":"computer vision","subtitle":"whole world","link":"/"},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/fantasy.jpg","align":"left","title":"import tensorflow as tf","subtitle":"sess.run(hello)","link":null},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/pythoner.png","align":"right","title":"import __helloworld__","subtitle":">>> Hello World","link":null}],"hint":{"new":{"selector":[".menu-reading"]}}}},"excerpt":"<h1 id=\"k阶原点矩、2阶矩、3阶矩该怎么理解？\"><a href=\"#k阶原点矩、2阶矩、3阶矩该怎么理解？\" class=\"headerlink\" title=\"k阶原点矩、2阶矩、3阶矩该怎么理解？\"></a>k阶原点矩、2阶矩、3阶矩该怎么理解？</h1><p>下面使用语言描述和代码来讲解。<br>","more":"</p>\n<blockquote>\n<p>阶矩是用来描述随机变量的概率分布的特性.</p>\n</blockquote>\n<blockquote>\n<p>一阶矩指的是随机变量的平均值,即期望值</p>\n<p>二阶矩指的是随机变量的方差</p>\n<p>三阶矩指的是随机变量的偏度</p>\n<p>四阶矩指的是随机变量的峰度</p>\n</blockquote>\n<blockquote>\n<p>因此通过计算矩,则可以得出随机变量的分布形状</p>\n</blockquote>\n<h1 id=\"代码实现\"><a href=\"#代码实现\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h1><p>使用Python2.0实现</p>\n<pre><code>import numpy as np\nfrom scipy import stats\n\n\ndef calc_statistics(x):\nn = x.shape[0]   #样本个数\n\n# 手动计算\nm = 0\nm2 = 0\nm3 = 0\nm4 = 0\nfor t in x:\n    m += t\n    m2 += t*t\n    m3 += t**3\n    m4 += t**4\nm /= n\nm2 /= n\nm3 /= n\nm4 /= n\n\nmu = m    # 一阶矩\nsigma = np.sqrt(m2 - mu*mu)   # 二阶矩\nskew = (m3 - 3*mu*m2 + 2*mu**3) / sigma**3    # 三阶矩（偏度）\nkurtosis = (m4 - 4*mu*m3 + 6*mu*mu*m2 - 4*mu**3*mu + mu**4) / sigma**4 - 3    # 四阶矩（峰度）\nprint &quot;手动计算均值、标准差、偏度、峰度：&quot;, mu, sigma, skew, kurtosis\n\n# 使用系统函数验证\nmu = np.mean(x, axis=0)\nsigma = np.std(x, axis=0)\nskew = stats.skew(x)\nkurtosis = stats.kurtosis(x)\nreturn mu, sigma, skew, kurtosis\n\nif __name__ == &apos;__main__&apos;:\nd = np.random.randn(10000)\nprint d\nprint d.shape\nmu, sigma, skew, kurtosis = calc_statistics(d)\nprint &quot;函数库计算均值、标准差、偏度、峰度：&quot;, mu, sigma, skew, kurtosis\n</code></pre><p>执行结果:</p>\n<blockquote>\n<p>[-0.42751577  0.36230961  0.37899409 …,  0.09176115 -1.38955563<br> -0.57570736]</p>\n</blockquote>\n<blockquote>\n<p>(10000L,)</p>\n</blockquote>\n<blockquote>\n<p>手动计算均值、标准差、偏度、峰度： -0.00189350820374 0.995018151945 -0.00589521484127 -0.0590604043446</p>\n</blockquote>\n<blockquote>\n<p>函数库计算均值、标准差、偏度、峰度： -0.00189350820374 0.995018151945 -0.00589521484127 -0.0590604043446</p>\n</blockquote>"},{"title":"直方图均衡化图片","date":"2018-03-20T10:31:55.000Z","_content":"\n# 直方图均衡化 #\n\n\n- 1.实验原理\n> 用直方图变换方法进行图像增强，通过改变图像的直方图来概念图像中像素的灰度，以达到图像增强的目的。\n \n\n\n\n\n- 2.实验步骤\n>\t1、对图像进行灰度统计，求灰度统计直方图。\n>\t\n>\t2、对灰度统计直方图进行归一化。\n>\t\n>\t3、求累积分布函数，求累积分布直方图。\n>\t\n>\t4、对累积直方图各项进行取整扩展tk=int[(L-1)tk + 0.5].\n>\t\n>\t5、确定映射对应关系，根据映射关系计算均衡化直方图。\n\n<!-- more -->\n\n- 3.代码\n\n\n> 代码采用python2.0实现   \n\n\t#!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2017/10/15 18:49\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : histequa.py\n\t# @ToDo    : 直方图均衡化(8bit)\n\t\n\t\n\tfrom PIL import Image\n\timport matplotlib as mpl\n\timport matplotlib.pyplot as plt\n\timport numpy as np\n\t\n\tmpl.rcParams['font.sans-serif'] = \"SimHei\"\n\tmpl.rcParams['axes.unicode_minus'] = False\n\t\n\t\n\tdef image2vector():\n\t    return np.array(Image.open(\"images/lena512.bmp\", \"r\").convert(\"L\"))\n\t\n\t\n\tdef equalization(data):\n\t    # 得到图像的高度、宽度\n\t    h = data.shape[0]\n\t    w = data.shape[1]\n\t    # 灰度数组\n\t    grayArr = np.zeros(255)\n\t    # 进行像素灰度统计\n\t    for i in range(h):\n\t        for j in range(w):\n\t            grayArr[data[i][j]] += 1\n\t    print grayArr.shape, grayArr.max()\n\t    # 归一化\n\t    idx = 0\n\t    for item in grayArr:\n\t        grayArr[idx] = item / (h * w)\n\t        idx += 1\n\t    # print grayArr\n\t    cdf = np.zeros(grayArr.shape)\n\t    sum = 0\n\t    # 计算灰度分布密度\n\t    # print cdf.shape\n\t    for i in range(len(grayArr)):\n\t        sum += grayArr[i]\n\t        cdf[i] = sum\n\t    L = 255\n\t    # print cdf\n\t    # 累计分布取整\n\t    indexArr = ((L - 1) * cdf + 0.5).astype(np.uint8)\n\t    # print indexArr\n\t    # 对灰度值进行映射（均衡化）\n\t    for i in range(h):\n\t        for j in range(w):\n\t            data[i, j] = indexArr[data[i, j]]\n\t    return grayArr, cdf, data\n\t\n\t\n\tif __name__ == '__main__':\n\t    data = image2vector()\n\t    # print data.shape\n\t    plt.figure(figsize=(7, 9))\n\t    plt.subplot(321)\n\t    plt.title(u\"原始图像\")\n\t    plt.imshow(data, cmap='gray')\n\t    plt.subplot(322)\n\t    plt.title(u\"原始灰度\")\n\t    plt.hist(data.flatten(), normed=True, bins=256)\n\t    srcGray, cdf, equlArr = equalization(data)\n\t    plt.subplot(323)\n\t    plt.title(u\"归一化直方图\")\n\t    plt.hist(srcGray, 255)\n\t    plt.subplot(324)\n\t    plt.title(u\"累积直方图\")\n\t    plt.hist(cdf, 255)\n\t    plt.subplot(325)\n\t    plt.title(u\"均衡化图像\")\n\t    plt.imshow(equlArr, cmap='gray')\n\t    plt.subplot(326)\n\t    plt.title(u\"均衡化的直方图\")\n\t    plt.hist(equlArr.flatten(), normed=True, bins=256)\n\t    # print equlArr\n\t    plt.tight_layout(0.3, rect=(0, 0, 1, 0.92))\n\t    plt.show()\n\n- 4.实验结果\n![实验结果](https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/histequa.png)\n\n\n- 5.实验总结\n> 在对数据进行归一化的时候，是用每个灰度值除以像素总数。在最后通过映射关系计算均衡化直方图时，是借助求出的映射关系，直接对原图的像素点进行映射。通过均衡化能增强图像的动态范围偏小的图像的反差，达到增强图像整体对比度的效果。\n","source":"_posts/直方图均衡化图片.md","raw":"---\ntitle: 直方图均衡化图片\ndate: 2018-03-20 18:31:55\ncategories:\n- 图像处理\n- 图像增强\ntags: \n- python \n- 图像处理 \n- 直方图均衡化\n---\n\n# 直方图均衡化 #\n\n\n- 1.实验原理\n> 用直方图变换方法进行图像增强，通过改变图像的直方图来概念图像中像素的灰度，以达到图像增强的目的。\n \n\n\n\n\n- 2.实验步骤\n>\t1、对图像进行灰度统计，求灰度统计直方图。\n>\t\n>\t2、对灰度统计直方图进行归一化。\n>\t\n>\t3、求累积分布函数，求累积分布直方图。\n>\t\n>\t4、对累积直方图各项进行取整扩展tk=int[(L-1)tk + 0.5].\n>\t\n>\t5、确定映射对应关系，根据映射关系计算均衡化直方图。\n\n<!-- more -->\n\n- 3.代码\n\n\n> 代码采用python2.0实现   \n\n\t#!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2017/10/15 18:49\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : histequa.py\n\t# @ToDo    : 直方图均衡化(8bit)\n\t\n\t\n\tfrom PIL import Image\n\timport matplotlib as mpl\n\timport matplotlib.pyplot as plt\n\timport numpy as np\n\t\n\tmpl.rcParams['font.sans-serif'] = \"SimHei\"\n\tmpl.rcParams['axes.unicode_minus'] = False\n\t\n\t\n\tdef image2vector():\n\t    return np.array(Image.open(\"images/lena512.bmp\", \"r\").convert(\"L\"))\n\t\n\t\n\tdef equalization(data):\n\t    # 得到图像的高度、宽度\n\t    h = data.shape[0]\n\t    w = data.shape[1]\n\t    # 灰度数组\n\t    grayArr = np.zeros(255)\n\t    # 进行像素灰度统计\n\t    for i in range(h):\n\t        for j in range(w):\n\t            grayArr[data[i][j]] += 1\n\t    print grayArr.shape, grayArr.max()\n\t    # 归一化\n\t    idx = 0\n\t    for item in grayArr:\n\t        grayArr[idx] = item / (h * w)\n\t        idx += 1\n\t    # print grayArr\n\t    cdf = np.zeros(grayArr.shape)\n\t    sum = 0\n\t    # 计算灰度分布密度\n\t    # print cdf.shape\n\t    for i in range(len(grayArr)):\n\t        sum += grayArr[i]\n\t        cdf[i] = sum\n\t    L = 255\n\t    # print cdf\n\t    # 累计分布取整\n\t    indexArr = ((L - 1) * cdf + 0.5).astype(np.uint8)\n\t    # print indexArr\n\t    # 对灰度值进行映射（均衡化）\n\t    for i in range(h):\n\t        for j in range(w):\n\t            data[i, j] = indexArr[data[i, j]]\n\t    return grayArr, cdf, data\n\t\n\t\n\tif __name__ == '__main__':\n\t    data = image2vector()\n\t    # print data.shape\n\t    plt.figure(figsize=(7, 9))\n\t    plt.subplot(321)\n\t    plt.title(u\"原始图像\")\n\t    plt.imshow(data, cmap='gray')\n\t    plt.subplot(322)\n\t    plt.title(u\"原始灰度\")\n\t    plt.hist(data.flatten(), normed=True, bins=256)\n\t    srcGray, cdf, equlArr = equalization(data)\n\t    plt.subplot(323)\n\t    plt.title(u\"归一化直方图\")\n\t    plt.hist(srcGray, 255)\n\t    plt.subplot(324)\n\t    plt.title(u\"累积直方图\")\n\t    plt.hist(cdf, 255)\n\t    plt.subplot(325)\n\t    plt.title(u\"均衡化图像\")\n\t    plt.imshow(equlArr, cmap='gray')\n\t    plt.subplot(326)\n\t    plt.title(u\"均衡化的直方图\")\n\t    plt.hist(equlArr.flatten(), normed=True, bins=256)\n\t    # print equlArr\n\t    plt.tight_layout(0.3, rect=(0, 0, 1, 0.92))\n\t    plt.show()\n\n- 4.实验结果\n![实验结果](https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/histequa.png)\n\n\n- 5.实验总结\n> 在对数据进行归一化的时候，是用每个灰度值除以像素总数。在最后通过映射关系计算均衡化直方图时，是借助求出的映射关系，直接对原图的像素点进行映射。通过均衡化能增强图像的动态范围偏小的图像的反差，达到增强图像整体对比度的效果。\n","slug":"直方图均衡化图片","published":1,"updated":"2018-03-23T10:21:49.159Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf3srotb0007usu8tul81ovu","content":"<h1 id=\"直方图均衡化\"><a href=\"#直方图均衡化\" class=\"headerlink\" title=\"直方图均衡化\"></a>直方图均衡化</h1><ul>\n<li>1.实验原理<blockquote>\n<p>用直方图变换方法进行图像增强，通过改变图像的直方图来概念图像中像素的灰度，以达到图像增强的目的。</p>\n</blockquote>\n</li>\n</ul>\n<ul>\n<li>2.实验步骤<blockquote>\n<p>   1、对图像进行灰度统计，求灰度统计直方图。</p>\n<p>   2、对灰度统计直方图进行归一化。</p>\n<p>   3、求累积分布函数，求累积分布直方图。</p>\n<p>   4、对累积直方图各项进行取整扩展tk=int[(L-1)tk + 0.5].</p>\n<p>   5、确定映射对应关系，根据映射关系计算均衡化直方图。</p>\n</blockquote>\n</li>\n</ul>\n<a id=\"more\"></a>\n<ul>\n<li>3.代码</li>\n</ul>\n<blockquote>\n<p>代码采用python2.0实现   </p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2017/10/15 18:49\n# @Author  : Jasontang\n# @Site    : \n# @File    : histequa.py\n# @ToDo    : 直方图均衡化(8bit)\n\n\nfrom PIL import Image\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nmpl.rcParams[&apos;font.sans-serif&apos;] = &quot;SimHei&quot;\nmpl.rcParams[&apos;axes.unicode_minus&apos;] = False\n\n\ndef image2vector():\n    return np.array(Image.open(&quot;images/lena512.bmp&quot;, &quot;r&quot;).convert(&quot;L&quot;))\n\n\ndef equalization(data):\n    # 得到图像的高度、宽度\n    h = data.shape[0]\n    w = data.shape[1]\n    # 灰度数组\n    grayArr = np.zeros(255)\n    # 进行像素灰度统计\n    for i in range(h):\n        for j in range(w):\n            grayArr[data[i][j]] += 1\n    print grayArr.shape, grayArr.max()\n    # 归一化\n    idx = 0\n    for item in grayArr:\n        grayArr[idx] = item / (h * w)\n        idx += 1\n    # print grayArr\n    cdf = np.zeros(grayArr.shape)\n    sum = 0\n    # 计算灰度分布密度\n    # print cdf.shape\n    for i in range(len(grayArr)):\n        sum += grayArr[i]\n        cdf[i] = sum\n    L = 255\n    # print cdf\n    # 累计分布取整\n    indexArr = ((L - 1) * cdf + 0.5).astype(np.uint8)\n    # print indexArr\n    # 对灰度值进行映射（均衡化）\n    for i in range(h):\n        for j in range(w):\n            data[i, j] = indexArr[data[i, j]]\n    return grayArr, cdf, data\n\n\nif __name__ == &apos;__main__&apos;:\n    data = image2vector()\n    # print data.shape\n    plt.figure(figsize=(7, 9))\n    plt.subplot(321)\n    plt.title(u&quot;原始图像&quot;)\n    plt.imshow(data, cmap=&apos;gray&apos;)\n    plt.subplot(322)\n    plt.title(u&quot;原始灰度&quot;)\n    plt.hist(data.flatten(), normed=True, bins=256)\n    srcGray, cdf, equlArr = equalization(data)\n    plt.subplot(323)\n    plt.title(u&quot;归一化直方图&quot;)\n    plt.hist(srcGray, 255)\n    plt.subplot(324)\n    plt.title(u&quot;累积直方图&quot;)\n    plt.hist(cdf, 255)\n    plt.subplot(325)\n    plt.title(u&quot;均衡化图像&quot;)\n    plt.imshow(equlArr, cmap=&apos;gray&apos;)\n    plt.subplot(326)\n    plt.title(u&quot;均衡化的直方图&quot;)\n    plt.hist(equlArr.flatten(), normed=True, bins=256)\n    # print equlArr\n    plt.tight_layout(0.3, rect=(0, 0, 1, 0.92))\n    plt.show()\n</code></pre><ul>\n<li>4.实验结果<br><img src=\"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/histequa.png\" alt=\"实验结果\"></li>\n</ul>\n<ul>\n<li>5.实验总结<blockquote>\n<p>在对数据进行归一化的时候，是用每个灰度值除以像素总数。在最后通过映射关系计算均衡化直方图时，是借助求出的映射关系，直接对原图的像素点进行映射。通过均衡化能增强图像的动态范围偏小的图像的反差，达到增强图像整体对比度的效果。</p>\n</blockquote>\n</li>\n</ul>\n","site":{"data":{"link":{"social":{"github":"https://github.com/mic-jasontang"},"extern":{"Github地址":"https://github.com/mic-jasontang"}},"reading":{"define":{"readed":"已读","reading":"在读","wanted":"想读"},"contents":{"readed":[{"title":"嫌疑人X的献身","cover":"https://img3.doubanio.com/lpic/s3254244.jpg","review":"百年一遇的数学天才石神，每天唯一的乐趣，便是去固定的便当店买午餐，只为看一眼在便当店做事的邻居靖子。","score":"8.9","doubanLink":"https://book.douban.com/subject/3211779/"},{"title":"Python核心编程（第二版）","cover":"https://img3.doubanio.com/lpic/s3140466.jpg","review":"本书是Python开发者的完全指南——针对 Python 2.5全面升级","score":"7.7","doubanLink":"https://book.douban.com/subject/3112503/"},{"title":"程序员代码面试指南：IT名企算法与数据结构题目最优解","cover":"https://img3.doubanio.com/lpic/s28313721.jpg","review":"这是一本程序员面试宝典！书中对IT名企代码面试各类题目的最优解进行了总结，并提供了相关代码实现。","score":"8.8","doubanLink":"https://book.douban.com/subject/26638586/"},{"title":"机器学习实战","cover":"https://img3.doubanio.com/lpic/s26696371.jpg","review":"全书通过精心编排的实例，切入日常工作任务，摒弃学术化语言，利用高效的可复用Python代码来阐释如何处理统计数据，进行数据分析及可视化。通过各种实例，读者可从中学会机器学习的核心算法，并能将其运用于一些策略性任务中，如分类、预测、推荐。另外，还可用它们来实现一些更高级的功能，如汇总和简化等。","score":"8.2","doubanLink":"https://book.douban.com/subject/24703171/"},{"title":"TensorFlow实战","cover":"https://img3.doubanio.com/lpic/s29343414.jpg","review":"《TensorFlow实战》希望能帮读者快速入门TensorFlow和深度学习，在工业界或者研究中快速地将想法落地为可实践的模型。","score":"7.3","doubanLink":"https://book.douban.com/subject/26974266/"}],"reading":[{"title":"深度学习","cover":"https://img1.doubanio.com/lpic/s29518349.jpg","review":"《深度学习》适合各类读者阅读，包括相关专业的大学生或研究生，以及不具有机器学习或统计背景、但是想要快速补充深度学习知识，以便在实际产品或平台中应用的软件工程师。","score":"8.7","doubanLink":"https://book.douban.com/subject/27087503/"},{"title":"Tensorflow：实战Google深度学习框架","cover":"https://img3.doubanio.com/lpic/s29349250.jpg","review":"《Tensorflow实战》包含了深度学习的入门知识和大量实践经验，是走进这个最新、最火的人工智能领域的首选参考书。","score":"8.2","doubanLink":"https://book.douban.com/subject/26976457/"},{"title":"机器学习","cover":"https://img1.doubanio.com/lpic/s28735609.jpg","review":"本书作为该领域的入门教材，在内容上尽可能涵盖机器学习基础知识的各方面。 为了使尽可能多的读者通过本书对机器学习有所了解, 作者试图尽可能少地使用数学知识. 然而, 少量的概率、统计、代数、优化、逻辑知识似乎不可避免. 因此, 本书更适合大学三年级以上的理工科本科生和研究生, 以及具有类似背景的对机器学 习感兴趣的人士. 为方便读者, 本书附录给出了一些相关数学基础知识简介.","score":"8.7","doubanLink":"https://book.douban.com/subject/26708119/"}],"wanted":[{"title":"OpenCV 3计算机视觉：Python语言实现（原书第2版）","cover":"https://img3.doubanio.com/lpic/s28902360.jpg","review":"本书针对具有一定Python工作经验的程序员以及想要利用OpenCV库研究计算机视觉课题的读者。本书不要求读者具有计算机视觉或OpenCV经验，但要具有编程经验。","score":"7.8","doubanLink":"https://book.douban.com/subject/26816975/"},{"title":"Python计算机视觉编程","cover":"https://img3.doubanio.com/lpic/s27305520.jpg","review":"《python计算机视觉编程》适合的读者是：有一定编程与数学基础，想要了解计算机视觉的基本理论与算法的学生，以及计算机科学、信号处理、物理学、应用数学和统计学、神经生理学、认知科学等领域的研究人员和从业者。","score":"7.5","doubanLink":"https://book.douban.com/subject/25906843/"}]}},"about":{"avatar":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/avatar.jpg","name":"tech.radish","tag":"python/Java/ML/CV","desc":"行走在边缘的coder","skills":{"ptyhon":5,"Java":6,"invisible-split-line-1":-1,"ML":4},"projects":[{"name":"合金战争(Java Swing + MySql + Socket)","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/game.png","tags":["Java","游戏开发"],"description":"合金战争是一款使用JavaSwing作为界面，MySQL作为数据库服务器，使用Socket通信的网络版RPG游戏","link_text":"合金战争","link":null},{"name":"iclass智能课堂助手","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/iclass.png","description":"iclass是一款实用SSM框架开发的轻量级课堂辅助教学系统，旨在加强和方便师生之间的交流合作，提高教学效率。拥有web端和安卓端（本人完成web端和安卓后端的开发）","tags":["毕业设计","SSM框架"],"link_text":"Github地址","link":"https://github.com/Mic-JasonTang/iclass"}],"reward":["https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/alipay-rewardcode.jpg","https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/wetchat-rewardcode.jpg"]},"slider":[{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/coloreggs.jpg","align":"center","title":"computer vision","subtitle":"whole world","link":"/"},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/fantasy.jpg","align":"left","title":"import tensorflow as tf","subtitle":"sess.run(hello)","link":null},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/pythoner.png","align":"right","title":"import __helloworld__","subtitle":">>> Hello World","link":null}],"hint":{"new":{"selector":[".menu-reading"]}}}},"excerpt":"<h1 id=\"直方图均衡化\"><a href=\"#直方图均衡化\" class=\"headerlink\" title=\"直方图均衡化\"></a>直方图均衡化</h1><ul>\n<li>1.实验原理<blockquote>\n<p>用直方图变换方法进行图像增强，通过改变图像的直方图来概念图像中像素的灰度，以达到图像增强的目的。</p>\n</blockquote>\n</li>\n</ul>\n<ul>\n<li>2.实验步骤<blockquote>\n<p>   1、对图像进行灰度统计，求灰度统计直方图。</p>\n<p>   2、对灰度统计直方图进行归一化。</p>\n<p>   3、求累积分布函数，求累积分布直方图。</p>\n<p>   4、对累积直方图各项进行取整扩展tk=int[(L-1)tk + 0.5].</p>\n<p>   5、确定映射对应关系，根据映射关系计算均衡化直方图。</p>\n</blockquote>\n</li>\n</ul>","more":"<ul>\n<li>3.代码</li>\n</ul>\n<blockquote>\n<p>代码采用python2.0实现   </p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2017/10/15 18:49\n# @Author  : Jasontang\n# @Site    : \n# @File    : histequa.py\n# @ToDo    : 直方图均衡化(8bit)\n\n\nfrom PIL import Image\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nmpl.rcParams[&apos;font.sans-serif&apos;] = &quot;SimHei&quot;\nmpl.rcParams[&apos;axes.unicode_minus&apos;] = False\n\n\ndef image2vector():\n    return np.array(Image.open(&quot;images/lena512.bmp&quot;, &quot;r&quot;).convert(&quot;L&quot;))\n\n\ndef equalization(data):\n    # 得到图像的高度、宽度\n    h = data.shape[0]\n    w = data.shape[1]\n    # 灰度数组\n    grayArr = np.zeros(255)\n    # 进行像素灰度统计\n    for i in range(h):\n        for j in range(w):\n            grayArr[data[i][j]] += 1\n    print grayArr.shape, grayArr.max()\n    # 归一化\n    idx = 0\n    for item in grayArr:\n        grayArr[idx] = item / (h * w)\n        idx += 1\n    # print grayArr\n    cdf = np.zeros(grayArr.shape)\n    sum = 0\n    # 计算灰度分布密度\n    # print cdf.shape\n    for i in range(len(grayArr)):\n        sum += grayArr[i]\n        cdf[i] = sum\n    L = 255\n    # print cdf\n    # 累计分布取整\n    indexArr = ((L - 1) * cdf + 0.5).astype(np.uint8)\n    # print indexArr\n    # 对灰度值进行映射（均衡化）\n    for i in range(h):\n        for j in range(w):\n            data[i, j] = indexArr[data[i, j]]\n    return grayArr, cdf, data\n\n\nif __name__ == &apos;__main__&apos;:\n    data = image2vector()\n    # print data.shape\n    plt.figure(figsize=(7, 9))\n    plt.subplot(321)\n    plt.title(u&quot;原始图像&quot;)\n    plt.imshow(data, cmap=&apos;gray&apos;)\n    plt.subplot(322)\n    plt.title(u&quot;原始灰度&quot;)\n    plt.hist(data.flatten(), normed=True, bins=256)\n    srcGray, cdf, equlArr = equalization(data)\n    plt.subplot(323)\n    plt.title(u&quot;归一化直方图&quot;)\n    plt.hist(srcGray, 255)\n    plt.subplot(324)\n    plt.title(u&quot;累积直方图&quot;)\n    plt.hist(cdf, 255)\n    plt.subplot(325)\n    plt.title(u&quot;均衡化图像&quot;)\n    plt.imshow(equlArr, cmap=&apos;gray&apos;)\n    plt.subplot(326)\n    plt.title(u&quot;均衡化的直方图&quot;)\n    plt.hist(equlArr.flatten(), normed=True, bins=256)\n    # print equlArr\n    plt.tight_layout(0.3, rect=(0, 0, 1, 0.92))\n    plt.show()\n</code></pre><ul>\n<li>4.实验结果<br><img src=\"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/histequa.png\" alt=\"实验结果\"></li>\n</ul>\n<ul>\n<li>5.实验总结<blockquote>\n<p>在对数据进行归一化的时候，是用每个灰度值除以像素总数。在最后通过映射关系计算均衡化直方图时，是借助求出的映射关系，直接对原图的像素点进行映射。通过均衡化能增强图像的动态范围偏小的图像的反差，达到增强图像整体对比度的效果。</p>\n</blockquote>\n</li>\n</ul>"},{"title":"图像与常用算子进行卷积运算","date":"2018-03-19T11:11:57.000Z","_content":"> 图像卷积实验，使用guass、soble、prewitt、 laplacian算子进行图像增强。\n\n<!-- more -->\n\n# 实现代码 #\n\n    #!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2017/9/18 16:57\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : image_convolve.py\n\t# @ToDo    :  图像卷积\n\t\n\timport numpy as np\n\timport os\n\tfrom PIL import Image\n\t\n\t\n\tdef convolve(image, weight):\n\t\theight, width = image.shape\n\t\th, w = weight.shape\n\t\theight_new = height - h + 1\n\t\twidth_new = width - w + 1\n\t\tprint image.shape\n\t\timage_new = np.zeros((height_new, width_new), dtype=np.float)\n\t\tfor i in range(height_new):\n\t\t\tfor j in range(width_new):\n\t\t\t\timage_new[i, j] = np.sum(image[i:i + h, j:j + w] * weight)\n\t\timage_new = image_new.clip(0, 255)\n\t\timage_new = np.rint(image_new).astype(\"uint8\")\n\t\tprint image_new.shape\n\t\treturn image_new\n\t\n\t\n\t# image_new = 255 * (image_new - image_new.min()) / (image_new.max() - image_new.min())\n\t\n\tif __name__ == '__main__':\n\t\timage = Image.open(\"son.png\", \"r\")\n\t\toutput_path = \".\\\\ImageConvolve\\\\\"\n\t\tif not os.path.exists(output_path):\n\t\t\tos.mkdir(output_path)\n\t\ta = np.array(image)\n\t\tavg3 = np.ones((3, 3))\n\t\tavg3 /= avg3.sum()\n\t\tavg5 = np.ones((5, 5))\n\t\tavg5 /= avg5.sum()\n\t\n\t\tgauss = np.array(([0.003, 0.013, 0.022, 0.013, 0.003],\n\t\t\t\t\t\t  [0.013, 0.059, 0.097, 0.059, 0.013],\n\t\t\t\t\t\t  [0.022, 0.097, 0.159, 0.097, 0.022],\n\t\t\t\t\t\t  [0.013, 0.059, 0.097, 0.059, 0.013],\n\t\t\t\t\t\t  [0.003, 0.013, 0.022, 0.013, 0.003]))\n\t\n\t\tsoble_x = np.array(([-1, 0, 1], [-2, 0, 2], [-1, 0, 1]))\n\t\tsoble_y = np.array(([-1, -2, -1], [0, 0, 0], [1, 2, 1]))\n\t\tsoble = np.array(([-1, -1, 0], [-1, 0, 1], [0, 1, 1]))\n\t\n\t\tprewitt_x = np.array(([-1, 0, 1], [-1, 0, 1], [-1, 0, 1]))\n\t\tprewitt_y = np.array(([-1, -1, -1], [0, 0, 0], [1, 1, 1]))\n\t\tprewitt = np.array(([-2, -1, 0], [-1, 0, 1], [0, 1, 2]))\n\t\n\t\tlaplacian4 = np.array(([0, -1, 0], [-1, 4, -1], [0, -1, 0]))\n\t\tlaplacian8 = np.array(([-1, -1, -1], [-1, 8, -1], [-1, -1, -1]))\n\t\tweight_list = (\n\t\t\t'avg3', 'avg5', 'gauss', 'soble_x', 'soble_y', 'soble', 'prewitt_x', 'prewitt_y', 'prewitt', 'laplacian4',\n\t\t\t'laplacian8')\n\t\n\t\tprint \"梯度检测\"\n\t\tfor weight in weight_list:\n\t\t\tprint weight, \"R\",\n\t\t\tR = convolve(a[:, :, 0], eval(weight))\n\t\t\tprint \"G\",\n\t\t\tG = convolve(a[:, :, 1], eval(weight))\n\t\t\tprint \"B\"\n\t\t\tB = convolve(a[:, :, 2], eval(weight))\n\t\t\tI = np.stack((R, G, B), 2)\n\t\t# Image.fromarray(I).save(output_path + weight + \".png\")\n\n# 实验结果 #\n![图像卷积运算实验结果](https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/img-cov.png)","source":"_posts/图像与常用算子进行卷积运算.md","raw":"---\ntitle: 图像与常用算子进行卷积运算\ndate: 2018-03-19 19:11:57\ncategories:\n- 图像处理\n- 图像增强\ntags:\n- 图像处理 \n- 卷积运算 \n- guass \n- soble \n- prewitt \n- laplacian\n---\n> 图像卷积实验，使用guass、soble、prewitt、 laplacian算子进行图像增强。\n\n<!-- more -->\n\n# 实现代码 #\n\n    #!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2017/9/18 16:57\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : image_convolve.py\n\t# @ToDo    :  图像卷积\n\t\n\timport numpy as np\n\timport os\n\tfrom PIL import Image\n\t\n\t\n\tdef convolve(image, weight):\n\t\theight, width = image.shape\n\t\th, w = weight.shape\n\t\theight_new = height - h + 1\n\t\twidth_new = width - w + 1\n\t\tprint image.shape\n\t\timage_new = np.zeros((height_new, width_new), dtype=np.float)\n\t\tfor i in range(height_new):\n\t\t\tfor j in range(width_new):\n\t\t\t\timage_new[i, j] = np.sum(image[i:i + h, j:j + w] * weight)\n\t\timage_new = image_new.clip(0, 255)\n\t\timage_new = np.rint(image_new).astype(\"uint8\")\n\t\tprint image_new.shape\n\t\treturn image_new\n\t\n\t\n\t# image_new = 255 * (image_new - image_new.min()) / (image_new.max() - image_new.min())\n\t\n\tif __name__ == '__main__':\n\t\timage = Image.open(\"son.png\", \"r\")\n\t\toutput_path = \".\\\\ImageConvolve\\\\\"\n\t\tif not os.path.exists(output_path):\n\t\t\tos.mkdir(output_path)\n\t\ta = np.array(image)\n\t\tavg3 = np.ones((3, 3))\n\t\tavg3 /= avg3.sum()\n\t\tavg5 = np.ones((5, 5))\n\t\tavg5 /= avg5.sum()\n\t\n\t\tgauss = np.array(([0.003, 0.013, 0.022, 0.013, 0.003],\n\t\t\t\t\t\t  [0.013, 0.059, 0.097, 0.059, 0.013],\n\t\t\t\t\t\t  [0.022, 0.097, 0.159, 0.097, 0.022],\n\t\t\t\t\t\t  [0.013, 0.059, 0.097, 0.059, 0.013],\n\t\t\t\t\t\t  [0.003, 0.013, 0.022, 0.013, 0.003]))\n\t\n\t\tsoble_x = np.array(([-1, 0, 1], [-2, 0, 2], [-1, 0, 1]))\n\t\tsoble_y = np.array(([-1, -2, -1], [0, 0, 0], [1, 2, 1]))\n\t\tsoble = np.array(([-1, -1, 0], [-1, 0, 1], [0, 1, 1]))\n\t\n\t\tprewitt_x = np.array(([-1, 0, 1], [-1, 0, 1], [-1, 0, 1]))\n\t\tprewitt_y = np.array(([-1, -1, -1], [0, 0, 0], [1, 1, 1]))\n\t\tprewitt = np.array(([-2, -1, 0], [-1, 0, 1], [0, 1, 2]))\n\t\n\t\tlaplacian4 = np.array(([0, -1, 0], [-1, 4, -1], [0, -1, 0]))\n\t\tlaplacian8 = np.array(([-1, -1, -1], [-1, 8, -1], [-1, -1, -1]))\n\t\tweight_list = (\n\t\t\t'avg3', 'avg5', 'gauss', 'soble_x', 'soble_y', 'soble', 'prewitt_x', 'prewitt_y', 'prewitt', 'laplacian4',\n\t\t\t'laplacian8')\n\t\n\t\tprint \"梯度检测\"\n\t\tfor weight in weight_list:\n\t\t\tprint weight, \"R\",\n\t\t\tR = convolve(a[:, :, 0], eval(weight))\n\t\t\tprint \"G\",\n\t\t\tG = convolve(a[:, :, 1], eval(weight))\n\t\t\tprint \"B\"\n\t\t\tB = convolve(a[:, :, 2], eval(weight))\n\t\t\tI = np.stack((R, G, B), 2)\n\t\t# Image.fromarray(I).save(output_path + weight + \".png\")\n\n# 实验结果 #\n![图像卷积运算实验结果](https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/img-cov.png)","slug":"图像与常用算子进行卷积运算","published":1,"updated":"2018-03-23T10:21:49.159Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf3srotc0008usu80xug4bgs","content":"<blockquote>\n<p>图像卷积实验，使用guass、soble、prewitt、 laplacian算子进行图像增强。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h1 id=\"实现代码\"><a href=\"#实现代码\" class=\"headerlink\" title=\"实现代码\"></a>实现代码</h1><pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2017/9/18 16:57\n# @Author  : Jasontang\n# @Site    : \n# @File    : image_convolve.py\n# @ToDo    :  图像卷积\n\nimport numpy as np\nimport os\nfrom PIL import Image\n\n\ndef convolve(image, weight):\n    height, width = image.shape\n    h, w = weight.shape\n    height_new = height - h + 1\n    width_new = width - w + 1\n    print image.shape\n    image_new = np.zeros((height_new, width_new), dtype=np.float)\n    for i in range(height_new):\n        for j in range(width_new):\n            image_new[i, j] = np.sum(image[i:i + h, j:j + w] * weight)\n    image_new = image_new.clip(0, 255)\n    image_new = np.rint(image_new).astype(&quot;uint8&quot;)\n    print image_new.shape\n    return image_new\n\n\n# image_new = 255 * (image_new - image_new.min()) / (image_new.max() - image_new.min())\n\nif __name__ == &apos;__main__&apos;:\n    image = Image.open(&quot;son.png&quot;, &quot;r&quot;)\n    output_path = &quot;.\\\\ImageConvolve\\\\&quot;\n    if not os.path.exists(output_path):\n        os.mkdir(output_path)\n    a = np.array(image)\n    avg3 = np.ones((3, 3))\n    avg3 /= avg3.sum()\n    avg5 = np.ones((5, 5))\n    avg5 /= avg5.sum()\n\n    gauss = np.array(([0.003, 0.013, 0.022, 0.013, 0.003],\n                      [0.013, 0.059, 0.097, 0.059, 0.013],\n                      [0.022, 0.097, 0.159, 0.097, 0.022],\n                      [0.013, 0.059, 0.097, 0.059, 0.013],\n                      [0.003, 0.013, 0.022, 0.013, 0.003]))\n\n    soble_x = np.array(([-1, 0, 1], [-2, 0, 2], [-1, 0, 1]))\n    soble_y = np.array(([-1, -2, -1], [0, 0, 0], [1, 2, 1]))\n    soble = np.array(([-1, -1, 0], [-1, 0, 1], [0, 1, 1]))\n\n    prewitt_x = np.array(([-1, 0, 1], [-1, 0, 1], [-1, 0, 1]))\n    prewitt_y = np.array(([-1, -1, -1], [0, 0, 0], [1, 1, 1]))\n    prewitt = np.array(([-2, -1, 0], [-1, 0, 1], [0, 1, 2]))\n\n    laplacian4 = np.array(([0, -1, 0], [-1, 4, -1], [0, -1, 0]))\n    laplacian8 = np.array(([-1, -1, -1], [-1, 8, -1], [-1, -1, -1]))\n    weight_list = (\n        &apos;avg3&apos;, &apos;avg5&apos;, &apos;gauss&apos;, &apos;soble_x&apos;, &apos;soble_y&apos;, &apos;soble&apos;, &apos;prewitt_x&apos;, &apos;prewitt_y&apos;, &apos;prewitt&apos;, &apos;laplacian4&apos;,\n        &apos;laplacian8&apos;)\n\n    print &quot;梯度检测&quot;\n    for weight in weight_list:\n        print weight, &quot;R&quot;,\n        R = convolve(a[:, :, 0], eval(weight))\n        print &quot;G&quot;,\n        G = convolve(a[:, :, 1], eval(weight))\n        print &quot;B&quot;\n        B = convolve(a[:, :, 2], eval(weight))\n        I = np.stack((R, G, B), 2)\n    # Image.fromarray(I).save(output_path + weight + &quot;.png&quot;)\n</code></pre><h1 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h1><p><img src=\"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/img-cov.png\" alt=\"图像卷积运算实验结果\"></p>\n","site":{"data":{"link":{"social":{"github":"https://github.com/mic-jasontang"},"extern":{"Github地址":"https://github.com/mic-jasontang"}},"reading":{"define":{"readed":"已读","reading":"在读","wanted":"想读"},"contents":{"readed":[{"title":"嫌疑人X的献身","cover":"https://img3.doubanio.com/lpic/s3254244.jpg","review":"百年一遇的数学天才石神，每天唯一的乐趣，便是去固定的便当店买午餐，只为看一眼在便当店做事的邻居靖子。","score":"8.9","doubanLink":"https://book.douban.com/subject/3211779/"},{"title":"Python核心编程（第二版）","cover":"https://img3.doubanio.com/lpic/s3140466.jpg","review":"本书是Python开发者的完全指南——针对 Python 2.5全面升级","score":"7.7","doubanLink":"https://book.douban.com/subject/3112503/"},{"title":"程序员代码面试指南：IT名企算法与数据结构题目最优解","cover":"https://img3.doubanio.com/lpic/s28313721.jpg","review":"这是一本程序员面试宝典！书中对IT名企代码面试各类题目的最优解进行了总结，并提供了相关代码实现。","score":"8.8","doubanLink":"https://book.douban.com/subject/26638586/"},{"title":"机器学习实战","cover":"https://img3.doubanio.com/lpic/s26696371.jpg","review":"全书通过精心编排的实例，切入日常工作任务，摒弃学术化语言，利用高效的可复用Python代码来阐释如何处理统计数据，进行数据分析及可视化。通过各种实例，读者可从中学会机器学习的核心算法，并能将其运用于一些策略性任务中，如分类、预测、推荐。另外，还可用它们来实现一些更高级的功能，如汇总和简化等。","score":"8.2","doubanLink":"https://book.douban.com/subject/24703171/"},{"title":"TensorFlow实战","cover":"https://img3.doubanio.com/lpic/s29343414.jpg","review":"《TensorFlow实战》希望能帮读者快速入门TensorFlow和深度学习，在工业界或者研究中快速地将想法落地为可实践的模型。","score":"7.3","doubanLink":"https://book.douban.com/subject/26974266/"}],"reading":[{"title":"深度学习","cover":"https://img1.doubanio.com/lpic/s29518349.jpg","review":"《深度学习》适合各类读者阅读，包括相关专业的大学生或研究生，以及不具有机器学习或统计背景、但是想要快速补充深度学习知识，以便在实际产品或平台中应用的软件工程师。","score":"8.7","doubanLink":"https://book.douban.com/subject/27087503/"},{"title":"Tensorflow：实战Google深度学习框架","cover":"https://img3.doubanio.com/lpic/s29349250.jpg","review":"《Tensorflow实战》包含了深度学习的入门知识和大量实践经验，是走进这个最新、最火的人工智能领域的首选参考书。","score":"8.2","doubanLink":"https://book.douban.com/subject/26976457/"},{"title":"机器学习","cover":"https://img1.doubanio.com/lpic/s28735609.jpg","review":"本书作为该领域的入门教材，在内容上尽可能涵盖机器学习基础知识的各方面。 为了使尽可能多的读者通过本书对机器学习有所了解, 作者试图尽可能少地使用数学知识. 然而, 少量的概率、统计、代数、优化、逻辑知识似乎不可避免. 因此, 本书更适合大学三年级以上的理工科本科生和研究生, 以及具有类似背景的对机器学 习感兴趣的人士. 为方便读者, 本书附录给出了一些相关数学基础知识简介.","score":"8.7","doubanLink":"https://book.douban.com/subject/26708119/"}],"wanted":[{"title":"OpenCV 3计算机视觉：Python语言实现（原书第2版）","cover":"https://img3.doubanio.com/lpic/s28902360.jpg","review":"本书针对具有一定Python工作经验的程序员以及想要利用OpenCV库研究计算机视觉课题的读者。本书不要求读者具有计算机视觉或OpenCV经验，但要具有编程经验。","score":"7.8","doubanLink":"https://book.douban.com/subject/26816975/"},{"title":"Python计算机视觉编程","cover":"https://img3.doubanio.com/lpic/s27305520.jpg","review":"《python计算机视觉编程》适合的读者是：有一定编程与数学基础，想要了解计算机视觉的基本理论与算法的学生，以及计算机科学、信号处理、物理学、应用数学和统计学、神经生理学、认知科学等领域的研究人员和从业者。","score":"7.5","doubanLink":"https://book.douban.com/subject/25906843/"}]}},"about":{"avatar":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/avatar.jpg","name":"tech.radish","tag":"python/Java/ML/CV","desc":"行走在边缘的coder","skills":{"ptyhon":5,"Java":6,"invisible-split-line-1":-1,"ML":4},"projects":[{"name":"合金战争(Java Swing + MySql + Socket)","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/game.png","tags":["Java","游戏开发"],"description":"合金战争是一款使用JavaSwing作为界面，MySQL作为数据库服务器，使用Socket通信的网络版RPG游戏","link_text":"合金战争","link":null},{"name":"iclass智能课堂助手","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/iclass.png","description":"iclass是一款实用SSM框架开发的轻量级课堂辅助教学系统，旨在加强和方便师生之间的交流合作，提高教学效率。拥有web端和安卓端（本人完成web端和安卓后端的开发）","tags":["毕业设计","SSM框架"],"link_text":"Github地址","link":"https://github.com/Mic-JasonTang/iclass"}],"reward":["https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/alipay-rewardcode.jpg","https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/wetchat-rewardcode.jpg"]},"slider":[{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/coloreggs.jpg","align":"center","title":"computer vision","subtitle":"whole world","link":"/"},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/fantasy.jpg","align":"left","title":"import tensorflow as tf","subtitle":"sess.run(hello)","link":null},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/pythoner.png","align":"right","title":"import __helloworld__","subtitle":">>> Hello World","link":null}],"hint":{"new":{"selector":[".menu-reading"]}}}},"excerpt":"<blockquote>\n<p>图像卷积实验，使用guass、soble、prewitt、 laplacian算子进行图像增强。</p>\n</blockquote>","more":"<h1 id=\"实现代码\"><a href=\"#实现代码\" class=\"headerlink\" title=\"实现代码\"></a>实现代码</h1><pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2017/9/18 16:57\n# @Author  : Jasontang\n# @Site    : \n# @File    : image_convolve.py\n# @ToDo    :  图像卷积\n\nimport numpy as np\nimport os\nfrom PIL import Image\n\n\ndef convolve(image, weight):\n    height, width = image.shape\n    h, w = weight.shape\n    height_new = height - h + 1\n    width_new = width - w + 1\n    print image.shape\n    image_new = np.zeros((height_new, width_new), dtype=np.float)\n    for i in range(height_new):\n        for j in range(width_new):\n            image_new[i, j] = np.sum(image[i:i + h, j:j + w] * weight)\n    image_new = image_new.clip(0, 255)\n    image_new = np.rint(image_new).astype(&quot;uint8&quot;)\n    print image_new.shape\n    return image_new\n\n\n# image_new = 255 * (image_new - image_new.min()) / (image_new.max() - image_new.min())\n\nif __name__ == &apos;__main__&apos;:\n    image = Image.open(&quot;son.png&quot;, &quot;r&quot;)\n    output_path = &quot;.\\\\ImageConvolve\\\\&quot;\n    if not os.path.exists(output_path):\n        os.mkdir(output_path)\n    a = np.array(image)\n    avg3 = np.ones((3, 3))\n    avg3 /= avg3.sum()\n    avg5 = np.ones((5, 5))\n    avg5 /= avg5.sum()\n\n    gauss = np.array(([0.003, 0.013, 0.022, 0.013, 0.003],\n                      [0.013, 0.059, 0.097, 0.059, 0.013],\n                      [0.022, 0.097, 0.159, 0.097, 0.022],\n                      [0.013, 0.059, 0.097, 0.059, 0.013],\n                      [0.003, 0.013, 0.022, 0.013, 0.003]))\n\n    soble_x = np.array(([-1, 0, 1], [-2, 0, 2], [-1, 0, 1]))\n    soble_y = np.array(([-1, -2, -1], [0, 0, 0], [1, 2, 1]))\n    soble = np.array(([-1, -1, 0], [-1, 0, 1], [0, 1, 1]))\n\n    prewitt_x = np.array(([-1, 0, 1], [-1, 0, 1], [-1, 0, 1]))\n    prewitt_y = np.array(([-1, -1, -1], [0, 0, 0], [1, 1, 1]))\n    prewitt = np.array(([-2, -1, 0], [-1, 0, 1], [0, 1, 2]))\n\n    laplacian4 = np.array(([0, -1, 0], [-1, 4, -1], [0, -1, 0]))\n    laplacian8 = np.array(([-1, -1, -1], [-1, 8, -1], [-1, -1, -1]))\n    weight_list = (\n        &apos;avg3&apos;, &apos;avg5&apos;, &apos;gauss&apos;, &apos;soble_x&apos;, &apos;soble_y&apos;, &apos;soble&apos;, &apos;prewitt_x&apos;, &apos;prewitt_y&apos;, &apos;prewitt&apos;, &apos;laplacian4&apos;,\n        &apos;laplacian8&apos;)\n\n    print &quot;梯度检测&quot;\n    for weight in weight_list:\n        print weight, &quot;R&quot;,\n        R = convolve(a[:, :, 0], eval(weight))\n        print &quot;G&quot;,\n        G = convolve(a[:, :, 1], eval(weight))\n        print &quot;B&quot;\n        B = convolve(a[:, :, 2], eval(weight))\n        I = np.stack((R, G, B), 2)\n    # Image.fromarray(I).save(output_path + weight + &quot;.png&quot;)\n</code></pre><h1 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h1><p><img src=\"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/img-cov.png\" alt=\"图像卷积运算实验结果\"></p>"}],"PostAsset":[],"PostCategory":[{"post_id":"cjf3srot00000usu8fjo35wkj","category_id":"cjf3srot70004usu8tr3lo6nc","_id":"cjf3srotl000ousu8zncot5uv"},{"post_id":"cjf3srot00000usu8fjo35wkj","category_id":"cjf3sroti000husu8zqq9x8tz","_id":"cjf3srotm000qusu8sf7tlcqz"},{"post_id":"cjf3srot50002usu8umy7089g","category_id":"cjf3srotd0009usu8lmxd6p18","_id":"cjf3srotn000tusu8fhwresjr"},{"post_id":"cjf3srot50002usu8umy7089g","category_id":"cjf3srotl000nusu8p4e8ewtz","_id":"cjf3sroto000wusu8d4advpks"},{"post_id":"cjf3srot90006usu80w7yrwmd","category_id":"cjf3srotf000busu81tkjy8d2","_id":"cjf3srotp000yusu8tepwadxn"},{"post_id":"cjf3srot90006usu80w7yrwmd","category_id":"cjf3srotm000rusu812spzgb6","_id":"cjf3srotq0012usu8pbicomv5"},{"post_id":"cjf3srotb0007usu8tul81ovu","category_id":"cjf3srotg000fusu8ag0a1sne","_id":"cjf3srotq0015usu87x8o5gdq"},{"post_id":"cjf3srotb0007usu8tul81ovu","category_id":"cjf3srotn000uusu80q81jtuz","_id":"cjf3srotr0017usu8r3u2we2k"},{"post_id":"cjf3srotc0008usu80xug4bgs","category_id":"cjf3srotg000fusu8ag0a1sne","_id":"cjf3srotr0018usu8otgj77mn"},{"post_id":"cjf3srotc0008usu80xug4bgs","category_id":"cjf3srotn000uusu80q81jtuz","_id":"cjf3srotr001ausu804kxh3pw"}],"PostTag":[{"post_id":"cjf3srot00000usu8fjo35wkj","tag_id":"cjf3srot90005usu8fe9pw7gv","_id":"cjf3srotg000dusu8xzv8jrka"},{"post_id":"cjf3srot00000usu8fjo35wkj","tag_id":"cjf3srotd000ausu854n3931g","_id":"cjf3srotg000eusu8wswuo8o6"},{"post_id":"cjf3srot50002usu8umy7089g","tag_id":"cjf3srotf000cusu8a89vg9m2","_id":"cjf3srotj000jusu8pekqfloe"},{"post_id":"cjf3srot50002usu8umy7089g","tag_id":"cjf3sroth000gusu860sx1tcx","_id":"cjf3srotj000kusu8v7whayi7"},{"post_id":"cjf3srot90006usu80w7yrwmd","tag_id":"cjf3sroti000iusu8gtvgudr5","_id":"cjf3sroto000xusu8rt4cpmjz"},{"post_id":"cjf3srot90006usu80w7yrwmd","tag_id":"cjf3srotj000musu86gvcd8lk","_id":"cjf3srotp000zusu8zen0txjg"},{"post_id":"cjf3srot90006usu80w7yrwmd","tag_id":"cjf3srotm000pusu8ox6u0l3d","_id":"cjf3srotq0013usu87atuywmc"},{"post_id":"cjf3srot90006usu80w7yrwmd","tag_id":"cjf3srotn000susu85clgx6y5","_id":"cjf3srotq0014usu8tsis2lhn"},{"post_id":"cjf3srotb0007usu8tul81ovu","tag_id":"cjf3sroto000vusu80ui4ws46","_id":"cjf3srots001busu8kkti894d"},{"post_id":"cjf3srotb0007usu8tul81ovu","tag_id":"cjf3srotp0011usu86cciviuk","_id":"cjf3srots001cusu8psed2uj5"},{"post_id":"cjf3srotb0007usu8tul81ovu","tag_id":"cjf3srotq0016usu8kjndc6yd","_id":"cjf3srots001eusu8ufcfb68j"},{"post_id":"cjf3srotc0008usu80xug4bgs","tag_id":"cjf3srotp0011usu86cciviuk","_id":"cjf3srotu001jusu89lvq43r0"},{"post_id":"cjf3srotc0008usu80xug4bgs","tag_id":"cjf3srots001dusu8dafbu6xt","_id":"cjf3srotu001kusu8gyg2082y"},{"post_id":"cjf3srotc0008usu80xug4bgs","tag_id":"cjf3srott001fusu8l2s55xdb","_id":"cjf3srotu001lusu8mojprj6k"},{"post_id":"cjf3srotc0008usu80xug4bgs","tag_id":"cjf3srott001gusu8t30kysdx","_id":"cjf3srotu001musu8uacv3w6i"},{"post_id":"cjf3srotc0008usu80xug4bgs","tag_id":"cjf3srott001husu8c1kwijri","_id":"cjf3srotu001nusu81yac8nlp"},{"post_id":"cjf3srotc0008usu80xug4bgs","tag_id":"cjf3srott001iusu8qa852n7a","_id":"cjf3srotv001ousu898s62i8x"}],"Tag":[{"name":"hexo","_id":"cjf3srot90005usu8fe9pw7gv"},{"name":"多电脑同步","_id":"cjf3srotd000ausu854n3931g"},{"name":"Mnist","_id":"cjf3srotf000cusu8a89vg9m2"},{"name":"tensorflow","_id":"cjf3sroth000gusu860sx1tcx"},{"name":"k阶矩","_id":"cjf3sroti000iusu8gtvgudr5"},{"name":"随机过程","_id":"cjf3srotj000musu86gvcd8lk"},{"name":"偏度","_id":"cjf3srotm000pusu8ox6u0l3d"},{"name":"峰度","_id":"cjf3srotn000susu85clgx6y5"},{"name":"python","_id":"cjf3sroto000vusu80ui4ws46"},{"name":"图像处理","_id":"cjf3srotp0011usu86cciviuk"},{"name":"直方图均衡化","_id":"cjf3srotq0016usu8kjndc6yd"},{"name":"卷积运算","_id":"cjf3srots001dusu8dafbu6xt"},{"name":"guass","_id":"cjf3srott001fusu8l2s55xdb"},{"name":"soble","_id":"cjf3srott001gusu8t30kysdx"},{"name":"prewitt","_id":"cjf3srott001husu8c1kwijri"},{"name":"laplacian","_id":"cjf3srott001iusu8qa852n7a"}]}}