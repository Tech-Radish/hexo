{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/raytaylorism/source/favicon.png","path":"favicon.png","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/js/prettify.js","path":"js/prettify.js","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/js/jquery.min.js","path":"js/jquery.min.js","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/alipay-rewardcode.jpg","path":"css/images/alipay-rewardcode.jpg","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/avatar.jpg","path":"css/images/avatar.jpg","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/side-user-cover.jpg","path":"css/images/side-user-cover.jpg","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/lib/font-awesome.min.css","path":"css/lib/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/lib/prettify-tomorrow-night-eighties.css","path":"css/lib/prettify-tomorrow-night-eighties.css","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/js/materialize.min.js","path":"js/materialize.min.js","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/iclass.png","path":"css/images/iclass.png","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/pythoner.png","path":"css/images/pythoner.png","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/wetchat-rewardcode.jpg","path":"css/images/wetchat-rewardcode.jpg","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/lib/materialize.min.css","path":"css/lib/materialize.min.css","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Bold.eot","path":"css/font/roboto/Roboto-Bold.eot","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Bold.woff","path":"css/font/roboto/Roboto-Bold.woff","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Bold.woff2","path":"css/font/roboto/Roboto-Bold.woff2","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Light.eot","path":"css/font/roboto/Roboto-Light.eot","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Light.woff","path":"css/font/roboto/Roboto-Light.woff","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Light.woff2","path":"css/font/roboto/Roboto-Light.woff2","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Medium.eot","path":"css/font/roboto/Roboto-Medium.eot","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Medium.woff","path":"css/font/roboto/Roboto-Medium.woff","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Medium.woff2","path":"css/font/roboto/Roboto-Medium.woff2","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Regular.eot","path":"css/font/roboto/Roboto-Regular.eot","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Regular.woff","path":"css/font/roboto/Roboto-Regular.woff","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Regular.woff2","path":"css/font/roboto/Roboto-Regular.woff2","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/font-awesome/FontAwesome.otf","path":"css/font/font-awesome/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.eot","path":"css/font/font-awesome/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.woff","path":"css/font/font-awesome/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.woff2","path":"css/font/font-awesome/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Bold.ttf","path":"css/font/roboto/Roboto-Bold.ttf","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Light.ttf","path":"css/font/roboto/Roboto-Light.ttf","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Medium.ttf","path":"css/font/roboto/Roboto-Medium.ttf","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Regular.ttf","path":"css/font/roboto/Roboto-Regular.ttf","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/histequa.png","path":"css/images/histequa.png","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.ttf","path":"css/font/font-awesome/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/fantasy.jpg","path":"css/images/fantasy.jpg","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.svg","path":"css/font/font-awesome/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/game.png","path":"css/images/game.png","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/img-cov.png","path":"css/images/img-cov.png","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/wall.png","path":"css/images/wall.png","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/coloreggs.jpg","path":"css/images/coloreggs.jpg","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/rain.png","path":"css/images/rain.png","modified":1,"renderable":1},{"_id":"themes/raytaylorism/source/css/images/phone.png","path":"css/images/phone.png","modified":1,"renderable":1}],"Cache":[{"_id":"themes/raytaylorism/.gitignore","hash":"cda50c55bb8864e0d96101140b62f880f690da5e","modified":1521454157654},{"_id":"themes/raytaylorism/Gruntfile.js","hash":"f69b2e716f955c9d5a23ca1b75394098c1494858","modified":1521454157655},{"_id":"themes/raytaylorism/LICENSE","hash":"115cd028ae511ac9e3d30eb4933da38136a68513","modified":1521454157656},{"_id":"themes/raytaylorism/README.md","hash":"a195db5b7c40e99d4da1fdf252e78c496f51f48e","modified":1521454157656},{"_id":"themes/raytaylorism/_config.yml","hash":"c24f24a0b72476b40b6addf0bdb2893fcb8facb9","modified":1521551932225},{"_id":"themes/raytaylorism/log.md","hash":"99d57a50f8f328d1a313b47bb636d0dc5656d813","modified":1521454157691},{"_id":"source/_data/about.json","hash":"488f91afc073615ca76f9c3cbb33271a4655a7cd","modified":1521545018522},{"_id":"source/_data/link.json","hash":"fb7c0deefc9952cf7819234fadb2ea751777e609","modified":1521462435829},{"_id":"source/_data/hint.json","hash":"7433c56bdcc76fab584670a80442200d9b605f5e","modified":1521463238146},{"_id":"source/_data/reading.json","hash":"4b91b2b0d7d06d3cd3bf2fbe59c51884d6304b13","modified":1521537141448},{"_id":"source/_data/slider.json","hash":"4f1c5509b20900aff3e6d69c8f69c6feef2a5ce4","modified":1521537767329},{"_id":"source/_posts/Mnist手写数字体识别-tensorflow.md","hash":"d90284839c27fc57b50ffcaaa30f95f64fe83915","modified":1521554382404},{"_id":"source/_posts/图像与常用算子进行卷积运算.md","hash":"a52728a18908cc9b03b2a0810abc6eab8e074dfd","modified":1521549363965},{"_id":"source/_posts/直方图均衡化图片.md","hash":"7d7b22059c86ff6dab67be152dfc9f335db4606d","modified":1521549297362},{"_id":"source/about/index.md","hash":"fa416d307e7d2e4f0162c58a0d6ffe8a40e28ee8","modified":1521534773890},{"_id":"source/reading/index.md","hash":"8f8179d7dac09b88bfc085465350a753e9eebded","modified":1521535699883},{"_id":"themes/raytaylorism/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1521454157630},{"_id":"themes/raytaylorism/.git/config","hash":"72eb1bbc72a0a062157f32a71bb8e838d1a4d073","modified":1521454157637},{"_id":"themes/raytaylorism/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1521454142853},{"_id":"themes/raytaylorism/.git/index","hash":"e9fcd8a9cf757688537888f50725e06a56edd77d","modified":1521454157742},{"_id":"themes/raytaylorism/.git/packed-refs","hash":"7586593639e036e68c8685187f371fa348402b9b","modified":1521454157622},{"_id":"themes/raytaylorism/_data/about.json","hash":"488f91afc073615ca76f9c3cbb33271a4655a7cd","modified":1521545018522},{"_id":"themes/raytaylorism/_data/hint.json","hash":"7433c56bdcc76fab584670a80442200d9b605f5e","modified":1521463238146},{"_id":"themes/raytaylorism/_data/link.json","hash":"fb7c0deefc9952cf7819234fadb2ea751777e609","modified":1521552401790},{"_id":"themes/raytaylorism/_data/slider.json","hash":"4f1c5509b20900aff3e6d69c8f69c6feef2a5ce4","modified":1521537767329},{"_id":"themes/raytaylorism/_data/reading.json","hash":"4b91b2b0d7d06d3cd3bf2fbe59c51884d6304b13","modified":1521537141448},{"_id":"themes/raytaylorism/languages/en.yml","hash":"ac672903f9c45f244db56e9408b4546d026fee8f","modified":1521454157662},{"_id":"themes/raytaylorism/languages/zh-CN.yml","hash":"b2211c4d88a3f319316f6ecbad748a0ae4b4b91b","modified":1521454157663},{"_id":"themes/raytaylorism/languages/zh-TW.yml","hash":"ae281c898cea81f4c897c0a69c45e2ce6a4314a6","modified":1521454157664},{"_id":"themes/raytaylorism/layout/about.ejs","hash":"599b3bb334b3f88b918e67f7a709287b8effee6d","modified":1521454157687},{"_id":"themes/raytaylorism/layout/archive.ejs","hash":"0a21af8903e95c6d8bb7554b089ac219e8708ad7","modified":1521454157687},{"_id":"themes/raytaylorism/layout/index.ejs","hash":"50c1e7dab5a065fd10dd3a28fdffa5e3d342de82","modified":1521454157688},{"_id":"themes/raytaylorism/layout/layout.ejs","hash":"43beb54ac81519cf5e88a3a1494649beeb856066","modified":1521454157688},{"_id":"themes/raytaylorism/layout/page.ejs","hash":"90441f114859ce63ef7c7d93d668dbe5939995c2","modified":1521454157689},{"_id":"themes/raytaylorism/layout/post.ejs","hash":"8e550fd95ef761909294ed3a4aa428ff0509fbf0","modified":1521454157689},{"_id":"themes/raytaylorism/layout/reading.ejs","hash":"3b2f77f0a154d2f6966b684eee69f26709968936","modified":1521454157690},{"_id":"themes/raytaylorism/layout/tag.ejs","hash":"42ecab14917abd40c0a38e6ab629f089352a24b1","modified":1521454157690},{"_id":"themes/raytaylorism/source/favicon.png","hash":"f28180f9a5026132b36b4a786c0577e68ea1fe55","modified":1483075692707},{"_id":"themes/raytaylorism/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1521454142854},{"_id":"themes/raytaylorism/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1521454142855},{"_id":"themes/raytaylorism/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1521454142857},{"_id":"themes/raytaylorism/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1521454142856},{"_id":"themes/raytaylorism/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1521454142858},{"_id":"themes/raytaylorism/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1521454142858},{"_id":"themes/raytaylorism/.git/hooks/pre-rebase.sample","hash":"5885a56ab4fca8075a05a562d005e922cde9853b","modified":1521454142859},{"_id":"themes/raytaylorism/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1521454142861},{"_id":"themes/raytaylorism/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1521454142860},{"_id":"themes/raytaylorism/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1521454142862},{"_id":"themes/raytaylorism/.git/logs/HEAD","hash":"45c7b7d530027dddca09a17418a699a6caa0a7b2","modified":1521454157634},{"_id":"themes/raytaylorism/_md/about/index.md","hash":"fa416d307e7d2e4f0162c58a0d6ffe8a40e28ee8","modified":1521534773890},{"_id":"themes/raytaylorism/_md/reading/index.md","hash":"ab4ae4fad36f371f60b49973797a115423a784d4","modified":1521537311990},{"_id":"themes/raytaylorism/layout/_partial/after_footer.ejs","hash":"9fafc2cb14cbca89e48335d64ab058b5f256a36e","modified":1521458731608},{"_id":"themes/raytaylorism/layout/_partial/archive.ejs","hash":"68c7db951ffb5323d49d4de74e3b0de7f70fb4c3","modified":1521454157666},{"_id":"themes/raytaylorism/layout/_partial/archive_title.ejs","hash":"dfc6c670702e64abce5fd87e3e2ea43c966ace32","modified":1521454157667},{"_id":"themes/raytaylorism/layout/_partial/article.ejs","hash":"8269f333b405412510454a2a2dd4ef75a19d7465","modified":1521551986359},{"_id":"themes/raytaylorism/layout/_partial/construction.ejs","hash":"21190b5a0d567ed4ea5d5289459690b72c1452f0","modified":1521454157668},{"_id":"themes/raytaylorism/layout/_partial/feature_guide.ejs","hash":"7aefb6bdc65d1e6113cb83190fcd2f29af2c9125","modified":1521454157669},{"_id":"themes/raytaylorism/layout/_partial/float.ejs","hash":"a5594e23bff2047156b647fbdd0ef8247ee4ec65","modified":1521454157669},{"_id":"themes/raytaylorism/layout/_partial/footer.ejs","hash":"7d8ade0e17012bf0006d234a8e8efd633d2658f2","modified":1521548320882},{"_id":"themes/raytaylorism/layout/_partial/head.ejs","hash":"7ceea72401426588cd7778f92585ab9487b463da","modified":1521454157670},{"_id":"themes/raytaylorism/layout/_partial/header.ejs","hash":"0616dd744262dd4cc98cd1cabe959643c845141f","modified":1521454157671},{"_id":"themes/raytaylorism/layout/_partial/menu_drawer.ejs","hash":"028ecbf59089cc4d1907a2d91d8da937f92d321c","modified":1521454157671},{"_id":"themes/raytaylorism/layout/_partial/pagenav.ejs","hash":"e7ada8faaee878ea4dde267d1b420bb45421670d","modified":1521454157671},{"_id":"themes/raytaylorism/layout/_partial/pagination.ejs","hash":"00de7746cf4ef8c4b67a72e825e5ff236f9d5814","modified":1521454157672},{"_id":"themes/raytaylorism/layout/_partial/search.ejs","hash":"0eca40de0d39c1ae52040fcb8c9d7f79afce35dc","modified":1521454157681},{"_id":"themes/raytaylorism/layout/_partial/side_nav.ejs","hash":"c69c45de069c348bf3906f1bd941920887a85c98","modified":1521454157682},{"_id":"themes/raytaylorism/layout/_partial/simple_article.ejs","hash":"6480e101b2f29dddd661410c56516c767d88b79f","modified":1521454157683},{"_id":"themes/raytaylorism/layout/_partial/slider.ejs","hash":"bb7b53f6ca9c852808d955fb074f88112e51ea59","modified":1521454157683},{"_id":"themes/raytaylorism/layout/_widget/blogroll.ejs","hash":"1a6808fa62906e7fb1fac3e16208fa6b1fc8d0ea","modified":1521454157684},{"_id":"themes/raytaylorism/layout/_widget/category.ejs","hash":"95292eb643be63d98f08e28f759c9b01bbfcb9b8","modified":1521454157685},{"_id":"themes/raytaylorism/layout/_widget/recent_posts.ejs","hash":"935bfacce10a726eed6cd82fe39d2c6f9cce9e2a","modified":1521454157685},{"_id":"themes/raytaylorism/layout/_widget/tag.ejs","hash":"90e0ba4412285903420ee3b43125a56743edf0c6","modified":1521454157685},{"_id":"themes/raytaylorism/layout/_widget/tagcloud.ejs","hash":"f256f028c247bdcb7927351df89f2284c64b7b6c","modified":1521454157686},{"_id":"themes/raytaylorism/source/css/style.styl","hash":"a05bcd2543b7bdcd3f725db6d053cd76ccf154be","modified":1521454157736},{"_id":"themes/raytaylorism/source/js/prettify.js","hash":"d592e6f771c2955cea3764d819221b91bc343961","modified":1521454157741},{"_id":"themes/raytaylorism/source/js/jquery.min.js","hash":"f694238d616f579a0690001f37984af430c19963","modified":1521454157738},{"_id":"themes/raytaylorism/.git/refs/heads/master","hash":"5f25a85bb7c9583415dd9d84ce2dbbe6189bfa86","modified":1521454157632},{"_id":"themes/raytaylorism/layout/_partial/plugin/analytics.ejs","hash":"b7dbd8342866929e683e9b013caa7324547ff704","modified":1521454157673},{"_id":"themes/raytaylorism/layout/_partial/plugin/comment.ejs","hash":"9d8e3cda9e11cfcb199da90e79baf11e71c2cfec","modified":1521551984318},{"_id":"themes/raytaylorism/layout/_partial/plugin/google_code_prettify.ejs","hash":"336f01048440f0c9f7b75f24aafcc3a1ffefd9a0","modified":1521454157674},{"_id":"themes/raytaylorism/layout/_partial/plugin/main_javascript.ejs","hash":"6629eec982aa789767b83e80af12fa40189ac344","modified":1521454157675},{"_id":"themes/raytaylorism/layout/_partial/plugin/mathjax.ejs","hash":"6f6b85a5876ae150d3e5f08e384aff68652c0335","modified":1521454157675},{"_id":"themes/raytaylorism/layout/_partial/plugin/noscript.ejs","hash":"182650c8be93b093997ac4d5fe14af2f835b98d9","modified":1521454157676},{"_id":"themes/raytaylorism/layout/_partial/plugin/page_stat.ejs","hash":"9b667cbe0e8031997da065b667d12b0c944a9dad","modified":1521454157676},{"_id":"themes/raytaylorism/layout/_partial/plugin/reward.ejs","hash":"284ab1d5cb4f43eb23b6d7a8aba2477b34abdc00","modified":1521454157677},{"_id":"themes/raytaylorism/layout/_partial/post/category.ejs","hash":"e17f452079201bd2a5a37bc76b51b132afd04faa","modified":1521454157677},{"_id":"themes/raytaylorism/layout/_partial/post/gallery.ejs","hash":"bd2285802766572736663e61852eb49f6acc744f","modified":1521454157678},{"_id":"themes/raytaylorism/layout/_partial/post/livere.ejs","hash":"bfad3e53acffd56b950017ed1754c7fdb8ec1486","modified":1521550256555},{"_id":"themes/raytaylorism/layout/_partial/post/prevnext.ejs","hash":"6556eea4fb351639006c16e9831fd72ab46076ba","modified":1521454157678},{"_id":"themes/raytaylorism/layout/_partial/post/readtimes.ejs","hash":"c829d0598f9906f663a8ace1c86f2aa6024d642c","modified":1521454157679},{"_id":"themes/raytaylorism/layout/_partial/post/tablecontents.ejs","hash":"a851061909d4e27321d1792a262f55385529fb2d","modified":1521454157680},{"_id":"themes/raytaylorism/layout/_partial/post/tag.ejs","hash":"0f84c1aded9ba1887566d34e7f0d696c015295f0","modified":1521454157680},{"_id":"themes/raytaylorism/layout/_partial/post/time.ejs","hash":"42210d6b5a132f5c18352dcff2983d3fdbe26956","modified":1521454157680},{"_id":"themes/raytaylorism/layout/_partial/post/title.ejs","hash":"f0733a134b375172a2cec830d7d09bdba33891fe","modified":1521454157681},{"_id":"themes/raytaylorism/source/css/_base/icons.css","hash":"ab167f1694ffe10c3c51d18a633efd41be121555","modified":1521459198606},{"_id":"themes/raytaylorism/source/css/_base/layout.styl","hash":"b2f718418de61946504a3f8bf28b75be165913a7","modified":1521454157693},{"_id":"themes/raytaylorism/source/css/_base/lib_customize.styl","hash":"5f25b295a3ad99991952f864573c0f1ccc6a1591","modified":1521454157693},{"_id":"themes/raytaylorism/source/css/_base/variable.styl","hash":"ce4e056d1bbfb80734d98a6898950e7c0136edf4","modified":1521454157694},{"_id":"themes/raytaylorism/source/css/_partial/about.styl","hash":"def183d6908ebcbd59341b09e9f7e06dc277b9ca","modified":1521454157695},{"_id":"themes/raytaylorism/source/css/_partial/archive.styl","hash":"4d48566e9f72b8eac8875b6985885418f56fbafa","modified":1521454157695},{"_id":"themes/raytaylorism/source/css/_partial/article.styl","hash":"293e38a8ab9aee346cc8e52421f1519c5a46a667","modified":1521454157696},{"_id":"themes/raytaylorism/source/css/_partial/comment.styl","hash":"590f1386581181ab588be06e4189861f5a209467","modified":1521454157697},{"_id":"themes/raytaylorism/source/css/_partial/footer.styl","hash":"7f2c22ebc3fe551496625e9453017e512d670aea","modified":1521454157697},{"_id":"themes/raytaylorism/source/css/_partial/header.styl","hash":"ebfd0155cda8a0876c36595708f02c294a7c82a0","modified":1521454157697},{"_id":"themes/raytaylorism/source/css/_partial/index.styl","hash":"ac83523dd14a1fc1fe55f98c84ed84cb03be864b","modified":1521454157698},{"_id":"themes/raytaylorism/source/css/_partial/link_context.styl","hash":"5b23db4dee53cbbe9eef257f4a542823100fde72","modified":1521454157698},{"_id":"themes/raytaylorism/source/css/_partial/other.styl","hash":"32bf499037a45ad2e0007a9ab3054067adc02506","modified":1521454157699},{"_id":"themes/raytaylorism/source/css/_partial/search.styl","hash":"f9ca6f5626c795ae73ff7412ff58207b62fd64ac","modified":1521454157700},{"_id":"themes/raytaylorism/source/css/_partial/reading.styl","hash":"f81929fa12212465b02456d0bb3b8263355e3281","modified":1521454157700},{"_id":"themes/raytaylorism/source/css/_partial/side_nav.styl","hash":"b239b6b55e87e86d038d6aa821beeb66a9cbaf39","modified":1521454157701},{"_id":"themes/raytaylorism/source/css/_partial/slider.styl","hash":"ad757e74b3500aa774636ebbe5bdcee7e52e5ad7","modified":1521454157701},{"_id":"themes/raytaylorism/source/css/_partial/syntax.styl","hash":"f39e7bb08abcc220f7c57fb413e76f4043ab9c35","modified":1521454157702},{"_id":"themes/raytaylorism/source/css/_partial/tablecontents.styl","hash":"e04fa0e7664065077750a7223ae3390cc84a4c56","modified":1521458211456},{"_id":"themes/raytaylorism/source/css/images/alipay-rewardcode.jpg","hash":"7093a60c54438b347cb13d79b7a34c99b0d6a4e3","modified":1521536428323},{"_id":"themes/raytaylorism/source/css/images/avatar.jpg","hash":"ad4c9872fa0b5c143a8778d95437452e2186a2e6","modified":1521536589981},{"_id":"themes/raytaylorism/source/css/images/side-user-cover.jpg","hash":"d8d73a64d6d5af83a27e6af1d4fedef808955ba0","modified":1521546910624},{"_id":"themes/raytaylorism/source/css/lib/font-awesome.min.css","hash":"14be7d7ae1894d2cc7c1a8e847df4db42a310b2f","modified":1521454157733},{"_id":"themes/raytaylorism/source/css/lib/prettify-tomorrow-night-eighties.css","hash":"e320b2be926124d30998af0e149b7f06303b8f8b","modified":1521454157736},{"_id":"themes/raytaylorism/source/js/materialize.min.js","hash":"04fe8bbc9a3165eb7bfb13b7166306ed671268d8","modified":1521454157740},{"_id":"themes/raytaylorism/.git/objects/pack/pack-c98d7cb24a60c9f10c63c0f359c183aaf8e51485.idx","hash":"4a9d69ad69329e507a4999ad7e6c86731e376c79","modified":1521454157293},{"_id":"themes/raytaylorism/source/css/images/iclass.png","hash":"ee48ed2068acfcd8f3bbc1101134a9a68043ff4b","modified":1521544198346},{"_id":"themes/raytaylorism/source/css/images/pythoner.png","hash":"926f3e215b9b527227303e2a6ec13f3cf0612d5c","modified":1521459852731},{"_id":"themes/raytaylorism/source/css/images/wetchat-rewardcode.jpg","hash":"37f65c6d09fca7a09dd10da6987268daa42203b4","modified":1521545476523},{"_id":"themes/raytaylorism/source/css/lib/materialize.min.css","hash":"2cdb74e6b61dc8f08352ba61979d3de314fe2af7","modified":1521547677195},{"_id":"themes/raytaylorism/.git/logs/refs/heads/master","hash":"45c7b7d530027dddca09a17418a699a6caa0a7b2","modified":1521454157633},{"_id":"themes/raytaylorism/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1521454157628},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Bold.eot","hash":"a76cd602f5188b9fbd4ba7443dcb9c064e3dbf10","modified":1521454157714},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Bold.woff","hash":"ee99cd87a59a9a5d4092c83232bb3eec67547425","modified":1521454157716},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Bold.woff2","hash":"933b866d09c2b087707a98dab64b3888865eeb96","modified":1521454157717},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Light.eot","hash":"42fe156996197e5eb0c0264c5d1bb3b4681f4595","modified":1521454157718},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Light.woff","hash":"6300f659be9e834ab263efe2fb3c581d48b1e7b2","modified":1521454157720},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Light.woff2","hash":"bbdc28b887400fcb340b504ec2904993af42a5d7","modified":1521454157721},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Medium.eot","hash":"1517f4b6e1c5d0e5198f937557253aac8fab0416","modified":1521454157722},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Medium.woff","hash":"d45f84922131364989ad6578c7a06b6b4fc22c34","modified":1521454157724},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Medium.woff2","hash":"6cc1b73571af9e827c4e7e91418f476703cd4c4b","modified":1521454157725},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Regular.eot","hash":"77ae3e980ec03863ebe2587a8ef9ddfd06941db0","modified":1521454157726},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Regular.woff","hash":"74734dde8d94e7268170f9b994dedfbdcb5b3a15","modified":1521454157729},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Regular.woff2","hash":"ed1558b0541f5e01ce48c7db1588371b990eec19","modified":1521454157730},{"_id":"themes/raytaylorism/source/css/font/font-awesome/FontAwesome.otf","hash":"42c179eef588854b5ec151bcf6a3f58aa8b79b11","modified":1521454157705},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.eot","hash":"986eed8dca049714e43eeebcb3932741a4bec76d","modified":1521454157706},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.woff","hash":"4a313eb93b959cc4154c684b915b0a31ddb68d84","modified":1521454157712},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.woff2","hash":"638c652d623280a58144f93e7b552c66d1667a11","modified":1521454157713},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Bold.ttf","hash":"47327df0f35e7cd7c8645874897a7449697544ae","modified":1521454157715},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Light.ttf","hash":"e321c183e2b75ee19813892b7bac8d7c411cb88a","modified":1521454157719},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Medium.ttf","hash":"6060ca726b9760b76f7c347dce9d2fa1fe42ec92","modified":1521454157723},{"_id":"themes/raytaylorism/source/css/font/roboto/Roboto-Regular.ttf","hash":"824b5480c977a8166e177e5357d13164ccc45f47","modified":1521454157728},{"_id":"themes/raytaylorism/source/css/images/histequa.png","hash":"89eb9d30577401536f20ab07ae8e5647ce79e867","modified":1521542354065},{"_id":"themes/raytaylorism/.git/logs/refs/remotes/origin/HEAD","hash":"45c7b7d530027dddca09a17418a699a6caa0a7b2","modified":1521454157628},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.ttf","hash":"6484f1af6b485d5096b71b344e67f4164c33dd1f","modified":1521454157711},{"_id":"themes/raytaylorism/source/css/images/fantasy.jpg","hash":"b4c6b8b34259e01bc78909be257ec2a4230a6684","modified":1521537474420},{"_id":"themes/raytaylorism/source/css/font/font-awesome/fontawesome-webfont.svg","hash":"550ef5c1253c8376f2ead32b654eb58d3c106ca3","modified":1521454157708},{"_id":"themes/raytaylorism/source/css/images/game.png","hash":"ca05a21991384b3fe0eaf3f529b1fbfb09439e10","modified":1521543178845},{"_id":"themes/raytaylorism/source/css/images/img-cov.png","hash":"71f7616a6e54befc3d7019b6e0b85e1bfb7cc784","modified":1521542924401},{"_id":"themes/raytaylorism/source/css/images/wall.png","hash":"d47ce4e9c164c9563cd230767bbc29f29a738981","modified":1521538245235},{"_id":"themes/raytaylorism/source/css/images/coloreggs.jpg","hash":"518341c5e974a98f8bc00b9e5972954071bf645a","modified":1501746622303},{"_id":"themes/raytaylorism/source/css/images/rain.png","hash":"5d382d60591561923d178dd24d89cb1189b193f6","modified":1521538270521},{"_id":"themes/raytaylorism/source/css/images/phone.png","hash":"91a48999c2a264233bc46f209aba35bd9d65ad38","modified":1521538203623},{"_id":"themes/raytaylorism/.git/objects/pack/pack-c98d7cb24a60c9f10c63c0f359c183aaf8e51485.pack","hash":"90dbb705905a1ce6c6c875ac53f3d326a85209eb","modified":1521454157315}],"Category":[{"name":"tensorflow学习","_id":"cjezqafid0004f4ht3mav2azz"},{"name":"图像处理","_id":"cjezqafii0007f4ht7ewqga7t"},{"name":"tensorflow-Demo","parent":"cjezqafid0004f4ht3mav2azz","_id":"cjezqafio000df4htku5c30eb"},{"name":"图像增强","parent":"cjezqafii0007f4ht7ewqga7t","_id":"cjezqafir000ff4htthco9egz"}],"Data":[{"_id":"about","data":{"avatar":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/avatar.jpg","name":"tech.radish","tag":"python/Java/ML/CV","desc":"行走在边缘的coder","skills":{"ptyhon":5,"Java":6,"invisible-split-line-1":-1,"ML":4},"projects":[{"name":"合金战争(Java Swing + MySql + Socket)","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/game.png","tags":["Java","游戏开发"],"description":"合金战争是一款使用JavaSwing作为界面，MySQL作为数据库服务器，使用Socket通信的网络版RPG游戏","link_text":"合金战争","link":null},{"name":"iclass智能课堂助手","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/iclass.png","description":"iclass是一款实用SSM框架开发的轻量级课堂辅助教学系统，旨在加强和方便师生之间的交流合作，提高教学效率。拥有web端和安卓端（本人完成web端和安卓后端的开发）","tags":["毕业设计","SSM框架"],"link_text":"Github地址","link":"https://github.com/Mic-JasonTang/iclass"}],"reward":["https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/alipay-rewardcode.jpg","https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/wetchat-rewardcode.jpg"]}},{"_id":"link","data":{"social":{"github":"https://github.com/mic-jasontang"},"extern":{"Github地址":"https://github.com/mic-jasontang"}}},{"_id":"slider","data":[{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/coloreggs.jpg","align":"center","title":"computer vision","subtitle":"whole world","link":"/"},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/fantasy.jpg","align":"left","title":"import tensorflow as tf","subtitle":"sess.run(hello)","link":null},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/pythoner.png","align":"right","title":"import __helloworld__","subtitle":">>> Hello World","link":null}]},{"_id":"hint","data":{"new":{"selector":[".menu-reading"]}}},{"_id":"reading","data":{"define":{"readed":"已读","reading":"在读","wanted":"想读"},"contents":{"readed":[{"title":"嫌疑人X的献身","cover":"https://img3.doubanio.com/lpic/s3254244.jpg","review":"百年一遇的数学天才石神，每天唯一的乐趣，便是去固定的便当店买午餐，只为看一眼在便当店做事的邻居靖子。","score":"8.9","doubanLink":"https://book.douban.com/subject/3211779/"},{"title":"Python核心编程（第二版）","cover":"https://img3.doubanio.com/lpic/s3140466.jpg","review":"本书是Python开发者的完全指南——针对 Python 2.5全面升级","score":"7.7","doubanLink":"https://book.douban.com/subject/3112503/"},{"title":"程序员代码面试指南：IT名企算法与数据结构题目最优解","cover":"https://img3.doubanio.com/lpic/s28313721.jpg","review":"这是一本程序员面试宝典！书中对IT名企代码面试各类题目的最优解进行了总结，并提供了相关代码实现。","score":"8.8","doubanLink":"https://book.douban.com/subject/26638586/"},{"title":"机器学习实战","cover":"https://img3.doubanio.com/lpic/s26696371.jpg","review":"全书通过精心编排的实例，切入日常工作任务，摒弃学术化语言，利用高效的可复用Python代码来阐释如何处理统计数据，进行数据分析及可视化。通过各种实例，读者可从中学会机器学习的核心算法，并能将其运用于一些策略性任务中，如分类、预测、推荐。另外，还可用它们来实现一些更高级的功能，如汇总和简化等。","score":"8.2","doubanLink":"https://book.douban.com/subject/24703171/"},{"title":"TensorFlow实战","cover":"https://img3.doubanio.com/lpic/s29343414.jpg","review":"《TensorFlow实战》希望能帮读者快速入门TensorFlow和深度学习，在工业界或者研究中快速地将想法落地为可实践的模型。","score":"7.3","doubanLink":"https://book.douban.com/subject/26974266/"}],"reading":[{"title":"深度学习","cover":"https://img1.doubanio.com/lpic/s29518349.jpg","review":"《深度学习》适合各类读者阅读，包括相关专业的大学生或研究生，以及不具有机器学习或统计背景、但是想要快速补充深度学习知识，以便在实际产品或平台中应用的软件工程师。","score":"8.7","doubanLink":"https://book.douban.com/subject/27087503/"},{"title":"Tensorflow：实战Google深度学习框架","cover":"https://img3.doubanio.com/lpic/s29349250.jpg","review":"《Tensorflow实战》包含了深度学习的入门知识和大量实践经验，是走进这个最新、最火的人工智能领域的首选参考书。","score":"8.2","doubanLink":"https://book.douban.com/subject/26976457/"},{"title":"机器学习","cover":"https://img1.doubanio.com/lpic/s28735609.jpg","review":"本书作为该领域的入门教材，在内容上尽可能涵盖机器学习基础知识的各方面。 为了使尽可能多的读者通过本书对机器学习有所了解, 作者试图尽可能少地使用数学知识. 然而, 少量的概率、统计、代数、优化、逻辑知识似乎不可避免. 因此, 本书更适合大学三年级以上的理工科本科生和研究生, 以及具有类似背景的对机器学 习感兴趣的人士. 为方便读者, 本书附录给出了一些相关数学基础知识简介.","score":"8.7","doubanLink":"https://book.douban.com/subject/26708119/"}],"wanted":[{"title":"OpenCV 3计算机视觉：Python语言实现（原书第2版）","cover":"https://img3.doubanio.com/lpic/s28902360.jpg","review":"本书针对具有一定Python工作经验的程序员以及想要利用OpenCV库研究计算机视觉课题的读者。本书不要求读者具有计算机视觉或OpenCV经验，但要具有编程经验。","score":"7.8","doubanLink":"https://book.douban.com/subject/26816975/"},{"title":"Python计算机视觉编程","cover":"https://img3.doubanio.com/lpic/s27305520.jpg","review":"《python计算机视觉编程》适合的读者是：有一定编程与数学基础，想要了解计算机视觉的基本理论与算法的学生，以及计算机科学、信号处理、物理学、应用数学和统计学、神经生理学、认知科学等领域的研究人员和从业者。","score":"7.5","doubanLink":"https://book.douban.com/subject/25906843/"}]}}}],"Page":[{"title":"关于","layout":"about","_content":"大家好，我是tech.radish。欢迎来到我的个人技术博客。\n","source":"about/index.md","raw":"title: 关于\nlayout: about\n---\n大家好，我是tech.radish。欢迎来到我的个人技术博客。\n","date":"2018-03-20T08:32:53.890Z","updated":"2018-03-20T08:32:53.890Z","path":"about/index.html","comments":1,"_id":"cjezqafi70001f4htl4666nih","content":"<p>大家好，我是tech.radish。欢迎来到我的个人技术博客。</p>\n","site":{"data":{"about":{"avatar":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/avatar.jpg","name":"tech.radish","tag":"python/Java/ML/CV","desc":"行走在边缘的coder","skills":{"ptyhon":5,"Java":6,"invisible-split-line-1":-1,"ML":4},"projects":[{"name":"合金战争(Java Swing + MySql + Socket)","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/game.png","tags":["Java","游戏开发"],"description":"合金战争是一款使用JavaSwing作为界面，MySQL作为数据库服务器，使用Socket通信的网络版RPG游戏","link_text":"合金战争","link":null},{"name":"iclass智能课堂助手","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/iclass.png","description":"iclass是一款实用SSM框架开发的轻量级课堂辅助教学系统，旨在加强和方便师生之间的交流合作，提高教学效率。拥有web端和安卓端（本人完成web端和安卓后端的开发）","tags":["毕业设计","SSM框架"],"link_text":"Github地址","link":"https://github.com/Mic-JasonTang/iclass"}],"reward":["https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/alipay-rewardcode.jpg","https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/wetchat-rewardcode.jpg"]},"link":{"social":{"github":"https://github.com/mic-jasontang"},"extern":{"Github地址":"https://github.com/mic-jasontang"}},"slider":[{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/coloreggs.jpg","align":"center","title":"computer vision","subtitle":"whole world","link":"/"},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/fantasy.jpg","align":"left","title":"import tensorflow as tf","subtitle":"sess.run(hello)","link":null},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/pythoner.png","align":"right","title":"import __helloworld__","subtitle":">>> Hello World","link":null}],"hint":{"new":{"selector":[".menu-reading"]}},"reading":{"define":{"readed":"已读","reading":"在读","wanted":"想读"},"contents":{"readed":[{"title":"嫌疑人X的献身","cover":"https://img3.doubanio.com/lpic/s3254244.jpg","review":"百年一遇的数学天才石神，每天唯一的乐趣，便是去固定的便当店买午餐，只为看一眼在便当店做事的邻居靖子。","score":"8.9","doubanLink":"https://book.douban.com/subject/3211779/"},{"title":"Python核心编程（第二版）","cover":"https://img3.doubanio.com/lpic/s3140466.jpg","review":"本书是Python开发者的完全指南——针对 Python 2.5全面升级","score":"7.7","doubanLink":"https://book.douban.com/subject/3112503/"},{"title":"程序员代码面试指南：IT名企算法与数据结构题目最优解","cover":"https://img3.doubanio.com/lpic/s28313721.jpg","review":"这是一本程序员面试宝典！书中对IT名企代码面试各类题目的最优解进行了总结，并提供了相关代码实现。","score":"8.8","doubanLink":"https://book.douban.com/subject/26638586/"},{"title":"机器学习实战","cover":"https://img3.doubanio.com/lpic/s26696371.jpg","review":"全书通过精心编排的实例，切入日常工作任务，摒弃学术化语言，利用高效的可复用Python代码来阐释如何处理统计数据，进行数据分析及可视化。通过各种实例，读者可从中学会机器学习的核心算法，并能将其运用于一些策略性任务中，如分类、预测、推荐。另外，还可用它们来实现一些更高级的功能，如汇总和简化等。","score":"8.2","doubanLink":"https://book.douban.com/subject/24703171/"},{"title":"TensorFlow实战","cover":"https://img3.doubanio.com/lpic/s29343414.jpg","review":"《TensorFlow实战》希望能帮读者快速入门TensorFlow和深度学习，在工业界或者研究中快速地将想法落地为可实践的模型。","score":"7.3","doubanLink":"https://book.douban.com/subject/26974266/"}],"reading":[{"title":"深度学习","cover":"https://img1.doubanio.com/lpic/s29518349.jpg","review":"《深度学习》适合各类读者阅读，包括相关专业的大学生或研究生，以及不具有机器学习或统计背景、但是想要快速补充深度学习知识，以便在实际产品或平台中应用的软件工程师。","score":"8.7","doubanLink":"https://book.douban.com/subject/27087503/"},{"title":"Tensorflow：实战Google深度学习框架","cover":"https://img3.doubanio.com/lpic/s29349250.jpg","review":"《Tensorflow实战》包含了深度学习的入门知识和大量实践经验，是走进这个最新、最火的人工智能领域的首选参考书。","score":"8.2","doubanLink":"https://book.douban.com/subject/26976457/"},{"title":"机器学习","cover":"https://img1.doubanio.com/lpic/s28735609.jpg","review":"本书作为该领域的入门教材，在内容上尽可能涵盖机器学习基础知识的各方面。 为了使尽可能多的读者通过本书对机器学习有所了解, 作者试图尽可能少地使用数学知识. 然而, 少量的概率、统计、代数、优化、逻辑知识似乎不可避免. 因此, 本书更适合大学三年级以上的理工科本科生和研究生, 以及具有类似背景的对机器学 习感兴趣的人士. 为方便读者, 本书附录给出了一些相关数学基础知识简介.","score":"8.7","doubanLink":"https://book.douban.com/subject/26708119/"}],"wanted":[{"title":"OpenCV 3计算机视觉：Python语言实现（原书第2版）","cover":"https://img3.doubanio.com/lpic/s28902360.jpg","review":"本书针对具有一定Python工作经验的程序员以及想要利用OpenCV库研究计算机视觉课题的读者。本书不要求读者具有计算机视觉或OpenCV经验，但要具有编程经验。","score":"7.8","doubanLink":"https://book.douban.com/subject/26816975/"},{"title":"Python计算机视觉编程","cover":"https://img3.doubanio.com/lpic/s27305520.jpg","review":"《python计算机视觉编程》适合的读者是：有一定编程与数学基础，想要了解计算机视觉的基本理论与算法的学生，以及计算机科学、信号处理、物理学、应用数学和统计学、神经生理学、认知科学等领域的研究人员和从业者。","score":"7.5","doubanLink":"https://book.douban.com/subject/25906843/"}]}}}},"excerpt":"","more":"<p>大家好，我是tech.radish。欢迎来到我的个人技术博客。</p>\n"},{"title":"读书","layout":"reading","_content":"# 我想读 #\n\n书籍1\n\n----------\n\n书籍2\n","source":"reading/index.md","raw":"title: 读书\nlayout: reading\n---\n# 我想读 #\n\n书籍1\n\n----------\n\n书籍2\n","date":"2018-03-20T08:48:19.883Z","updated":"2018-03-20T08:48:19.883Z","path":"reading/index.html","comments":1,"_id":"cjezqafib0003f4ht6hz0ky4b","content":"<h1 id=\"我想读\"><a href=\"#我想读\" class=\"headerlink\" title=\"我想读\"></a>我想读</h1><p>书籍1</p>\n<hr>\n<p>书籍2</p>\n","site":{"data":{"about":{"avatar":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/avatar.jpg","name":"tech.radish","tag":"python/Java/ML/CV","desc":"行走在边缘的coder","skills":{"ptyhon":5,"Java":6,"invisible-split-line-1":-1,"ML":4},"projects":[{"name":"合金战争(Java Swing + MySql + Socket)","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/game.png","tags":["Java","游戏开发"],"description":"合金战争是一款使用JavaSwing作为界面，MySQL作为数据库服务器，使用Socket通信的网络版RPG游戏","link_text":"合金战争","link":null},{"name":"iclass智能课堂助手","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/iclass.png","description":"iclass是一款实用SSM框架开发的轻量级课堂辅助教学系统，旨在加强和方便师生之间的交流合作，提高教学效率。拥有web端和安卓端（本人完成web端和安卓后端的开发）","tags":["毕业设计","SSM框架"],"link_text":"Github地址","link":"https://github.com/Mic-JasonTang/iclass"}],"reward":["https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/alipay-rewardcode.jpg","https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/wetchat-rewardcode.jpg"]},"link":{"social":{"github":"https://github.com/mic-jasontang"},"extern":{"Github地址":"https://github.com/mic-jasontang"}},"slider":[{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/coloreggs.jpg","align":"center","title":"computer vision","subtitle":"whole world","link":"/"},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/fantasy.jpg","align":"left","title":"import tensorflow as tf","subtitle":"sess.run(hello)","link":null},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/pythoner.png","align":"right","title":"import __helloworld__","subtitle":">>> Hello World","link":null}],"hint":{"new":{"selector":[".menu-reading"]}},"reading":{"define":{"readed":"已读","reading":"在读","wanted":"想读"},"contents":{"readed":[{"title":"嫌疑人X的献身","cover":"https://img3.doubanio.com/lpic/s3254244.jpg","review":"百年一遇的数学天才石神，每天唯一的乐趣，便是去固定的便当店买午餐，只为看一眼在便当店做事的邻居靖子。","score":"8.9","doubanLink":"https://book.douban.com/subject/3211779/"},{"title":"Python核心编程（第二版）","cover":"https://img3.doubanio.com/lpic/s3140466.jpg","review":"本书是Python开发者的完全指南——针对 Python 2.5全面升级","score":"7.7","doubanLink":"https://book.douban.com/subject/3112503/"},{"title":"程序员代码面试指南：IT名企算法与数据结构题目最优解","cover":"https://img3.doubanio.com/lpic/s28313721.jpg","review":"这是一本程序员面试宝典！书中对IT名企代码面试各类题目的最优解进行了总结，并提供了相关代码实现。","score":"8.8","doubanLink":"https://book.douban.com/subject/26638586/"},{"title":"机器学习实战","cover":"https://img3.doubanio.com/lpic/s26696371.jpg","review":"全书通过精心编排的实例，切入日常工作任务，摒弃学术化语言，利用高效的可复用Python代码来阐释如何处理统计数据，进行数据分析及可视化。通过各种实例，读者可从中学会机器学习的核心算法，并能将其运用于一些策略性任务中，如分类、预测、推荐。另外，还可用它们来实现一些更高级的功能，如汇总和简化等。","score":"8.2","doubanLink":"https://book.douban.com/subject/24703171/"},{"title":"TensorFlow实战","cover":"https://img3.doubanio.com/lpic/s29343414.jpg","review":"《TensorFlow实战》希望能帮读者快速入门TensorFlow和深度学习，在工业界或者研究中快速地将想法落地为可实践的模型。","score":"7.3","doubanLink":"https://book.douban.com/subject/26974266/"}],"reading":[{"title":"深度学习","cover":"https://img1.doubanio.com/lpic/s29518349.jpg","review":"《深度学习》适合各类读者阅读，包括相关专业的大学生或研究生，以及不具有机器学习或统计背景、但是想要快速补充深度学习知识，以便在实际产品或平台中应用的软件工程师。","score":"8.7","doubanLink":"https://book.douban.com/subject/27087503/"},{"title":"Tensorflow：实战Google深度学习框架","cover":"https://img3.doubanio.com/lpic/s29349250.jpg","review":"《Tensorflow实战》包含了深度学习的入门知识和大量实践经验，是走进这个最新、最火的人工智能领域的首选参考书。","score":"8.2","doubanLink":"https://book.douban.com/subject/26976457/"},{"title":"机器学习","cover":"https://img1.doubanio.com/lpic/s28735609.jpg","review":"本书作为该领域的入门教材，在内容上尽可能涵盖机器学习基础知识的各方面。 为了使尽可能多的读者通过本书对机器学习有所了解, 作者试图尽可能少地使用数学知识. 然而, 少量的概率、统计、代数、优化、逻辑知识似乎不可避免. 因此, 本书更适合大学三年级以上的理工科本科生和研究生, 以及具有类似背景的对机器学 习感兴趣的人士. 为方便读者, 本书附录给出了一些相关数学基础知识简介.","score":"8.7","doubanLink":"https://book.douban.com/subject/26708119/"}],"wanted":[{"title":"OpenCV 3计算机视觉：Python语言实现（原书第2版）","cover":"https://img3.doubanio.com/lpic/s28902360.jpg","review":"本书针对具有一定Python工作经验的程序员以及想要利用OpenCV库研究计算机视觉课题的读者。本书不要求读者具有计算机视觉或OpenCV经验，但要具有编程经验。","score":"7.8","doubanLink":"https://book.douban.com/subject/26816975/"},{"title":"Python计算机视觉编程","cover":"https://img3.doubanio.com/lpic/s27305520.jpg","review":"《python计算机视觉编程》适合的读者是：有一定编程与数学基础，想要了解计算机视觉的基本理论与算法的学生，以及计算机科学、信号处理、物理学、应用数学和统计学、神经生理学、认知科学等领域的研究人员和从业者。","score":"7.5","doubanLink":"https://book.douban.com/subject/25906843/"}]}}}},"excerpt":"","more":"<h1 id=\"我想读\"><a href=\"#我想读\" class=\"headerlink\" title=\"我想读\"></a>我想读</h1><p>书籍1</p>\n<hr>\n<p>书籍2</p>\n"}],"Post":[{"title":"Mnist手写数字体识别(tensorflow)","date":"2018-03-20T13:35:05.000Z","_content":"# Tensorflow #\n\n\n> 首先，简单的说下，tensorflow的基本架构。\n>使用 TensorFlow, 你必须明白 TensorFlow:\n\n- 使用图 (graph) 来表示计算任务.\n- 在被称之为 会话 (Session) 的上下文 (context) 中执行图.\n- 使用 tensor 表示数据.\n- 通过 变量 (Variable) 维护状态.\n- 使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.\n\n<!--more -->\n\n# Tensor #\n\n> TensorFlow 是一个编程系统, 使用图来表示计算任务. 图中的节点被称之为 op (operation 的缩写). 一个 op 获得 0 个或多个 Tensor, 执行计算, 产生 0 个或多个 Tensor. 每个 Tensor 是一个类型化的多维数组. 例如, 你可以将一小组图像集表示为一个四维浮点数数组, 这四个维度分别是 [batch, height, width, channels].\n\n> 一个 TensorFlow 图描述了计算的过程. 为了进行计算, 图必须在 会话 里被启动. 会话 将图的 op 分发到诸如 CPU 或 GPU 之类的 设备 上, 同时提供执行 op 的方法. 这些方法执行后, 将产生的 tensor 返回. 在 Python 语言中, 返回的 tensor 是 numpy ndarray 对象; 在 C 和 C++ 语言中, 返回的 tensor 是tensorflow::Tensor 实例.\n\n> Tensor是tensorflow中非常重要且非常基础的概念，可以说数据的呈现形式都是用tensor表示的。输入输出都是tensor，tensor的中文含义，就是张量，可以简单的理解为线性代数里面的向量或者矩阵。\n\n# Graph #\n\n\n> TensorFlow 程序通常被组织成一个构建阶段和一个执行阶段. 在构建阶段, op 的执行步骤 被描述成一个图. 在执行阶段, 使用会话执行执行图中的 op.\n\n\n\n> 例如, 通常在构建阶段创建一个图来表示和训练神经网络, 然后在执行阶段反复执行图中的训练 op. 下面这个图，就是一个比较形象的说明，图中的每一个节点，就是一个op，各个op透过tensor数据流向形成边的连接，构成了一个图。\n\n![](https://images2015.cnblogs.com/blog/844237/201703/844237-20170330093311608-2056024255.gif)\n> 构建图的第一步, 是创建源 op (source op). 源 op 不需要任何输入, 例如 常量 (Constant). 源 op 的输出被传递给其它 op 做运算. Python 库中, op 构造器的返回值代表被构造出的 op 的输出, 这些返回值可以传递给其它 op 构造器作为输入.\n\n\n> TensorFlow Python 库有一个默认图 (default graph), op 构造器可以为其增加节点. 这个默认图对 许多程序来说已经足够用了.\n\n# Session #\n> 当图构建好后，需要创建一个Session来运行构建好的图，来实现逻辑，创建session的时候，若无任何参数，tensorflow将启用默认的session。session.run(xxx)是比较典型的使用方案, session运行结束后，返回值是一个tensor。\n\n\n\n> tensorflow中的session，有两大类，一种就是普通的session，即tensorflow.Session(),还有一种是交互式session，即tensorflow.InteractiveSession(). 使用Tensor.eval() 和Operation.run()方法代替Session.run(). 这样可以避免使用一个变量来持有会话, 为程序架构的设计添加了灵活性.\n\n\n# 数据载体 #\n> Tensorflow体系下，变量（Variable）是用来维护图计算过程中的中间状态信息，是一种常见高频使用的数据载体，还有一种特殊的数据载体，那就是常量（Constant），主要是用作图处理过程的输入量。这些数据载体，也都是以Tensor的形式体现。变量定义和常量定义上，比较好理解：\n   \n\t# 创建一个变量, 初始化为标量0.没有指定数据类型（dtype）\n\tstate = tf.Variable(0, name=\"counter\")\n\n\t# 创建一个常量，其值为1，没有指定数据类型（dtype）\n\tone = tf.constant(1)\n\n\n\n> 针对上面的变量和常量，看看Tensorflow里面的函数定义：\n>\n    class Variable(object):　\n\tdef __init__(self,\n\t\tinitial_value=None,\n\t\ttrainable=True,\n\t\tcollections=None,\n\t\tvalidate_shape=True,\n\t\tcaching_device=None,\n\t\tname=None,\n\t\tvariable_def=None,\n\t\tdtype=None,\n\t\texpected_shape=None,\n\t\timport_scope=None)：\n\n>\n\tdef constant(value, dtype=None, shape=None, name=\"Const\", verify_shape=False)：\n\n> 从上面的源码可以看出，定义变量，其实就是定义了一个Variable的实例，而定义常量，其实就是调用了一下常量函数，创建了一个常量Tensor。\n\n> 还有一个很重要的概念，那就是占位符placeholder，这个在Tensorflow中进行Feed数据灌入时，很有用。所谓的数据灌入，指的是在创建Tensorflow的图时，节点的输入部分，就是一个placeholder，后续在执行session操作的前，将实际数据Feed到图中，进行执行即可。\n>\n\tinput1 = tf.placeholder(tf.types.float32)\n\tinput2 = tf.placeholder(tf.types.float32)\n\toutput = tf.mul(input1, input2)\n>\t\n\twith tf.Session() as sess:\n\t  print sess.run([output], feed_dict={input1:[7.], input2:[2.]})\n>\t\n\t# 输出:\n\t# [array([ 14.], dtype=float32)]\n\n> 占位符的定义原型，也是一个函数：\n>\n\tdef placeholder(dtype, shape=None, name=None)：\n\n\n\n> 到此，Tensorflow的入门级的基本知识介绍完了。下面，将结合一个MNIST的手写识别的例子，从代码上简单分析一下，源代码分成4个文件：\n\n\n----------\n\n> main.py驱动程序\n \n    #!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2018/2/21 20:41\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : main.py\n\t# @ToDo    : 驱动程序\n\t\n\timport _thread\n\t\n\tfrom neural_network_learning.hand_writting_refactor import mnist_train, mnist_eval\n\t\n\t\n\tif __name__ == '__main__':\n\t    _thread.start_new_thread(mnist_train.main, (None,))\n\t    _thread.start_new_thread(mnist_eval.main, (None,))\n\t\n\t    # 这个不能删除，当做主线程\n\t    while 1:\n\t        pass\n\n> mnist_inference.py计算前向传播的过程及定义了神经网络的参数\n \n\t#!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2018/2/20 19:43\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : mnist_inference.py\n\t# @ToDo    : 定义了前向传播的过程及神经网络的参数\n\t\n\t\n\timport tensorflow as tf\n\t\n\t# 定义神经网络结构相关的参数\n\tINPUT_NODE = 784\n\tOUTPUT_NODE = 10\n\tLAYER1_NODE = 500\n\t\n\t\n\t# 训练时会创建这些变量，测试时会通过保存的模型加载这些变量的取值\n\tdef get_weight_variable(shape, regularizer):\n\t    weights = tf.get_variable(\"weights\", shape, initializer=tf.truncated_normal_initializer(stddev=0.1))\n\t\n\t    # 当使用正则化生成函数时,当前变量的正则化损失加入名字为losses的集合.\n\t    # 自定义集合\n\t    if regularizer:\n\t        tf.add_to_collection(\"losses\", regularizer(weights))\n\t    return weights\n\t\n\t\n\t# 前向传播过程\n\tdef inference(input_tensor, regularizer):\n\t    # 声明第一层神经网络的变量并完成前向传播过程\n\t    with tf.variable_scope(\"layer1\"):\n\t        weights = get_weight_variable([INPUT_NODE, LAYER1_NODE], regularizer)\n\t        biases = tf.get_variable(\"biases\", [LAYER1_NODE], initializer=tf.constant_initializer(0.0))\n\t        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights) + biases)\n\t\n\t    # 声明第二层圣经网络变量并完成前向传播过程\n\t    with tf.variable_scope(\"layer2\"):\n\t        weights = get_weight_variable([LAYER1_NODE, OUTPUT_NODE], regularizer)\n\t        biases = tf.get_variable(\"biases\", [OUTPUT_NODE], initializer=tf.constant_initializer(0.0))\n\t        layer2 = tf.matmul(layer1, weights) + biases\n\t    # 返回最后前向传播的结果\n\t    return layer2\n\n> mnist_train.py定义了神经网络的训练过程\n\n\t#!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2018/2/21 16:08\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : mnist_train.py\n\t# @ToDo    : 定义了神经网络的训练过程\n\t\n\timport os\n\t\n\timport tensorflow as tf\n\tfrom tensorflow.examples.tutorials.mnist import input_data\n\t\n\timport neural_network_learning.hand_writting_refactor.mnist_inference as mnist_inference\n\t\n\t# 配置神经网络的参数\n\tBATCH_SIZE = 100\n\tLEARNING_REATE_BASE = 0.8\n\tLEARNING_RATE_DECAY = 0.99\n\tREGULARAZTION_RATE = 0.0001\n\tTRAING_STEPS = 2000\n\tMOVING_AVERAGE_DECAY = 0.99\n\t# 模型保存的路径和文件名\n\tMODEL_SAVE_PATH = \"./model/\"\n\tMODEL_NAME = \"model.ckpt\"\n\t\n\t\n\tdef train(mnist):\n\t    # 定义输入输出placeholder\n\t    x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name=\"input-x\")\n\t    y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name=\"input-y\")\n\t\n\t    regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)\n\t    y = mnist_inference.inference(x, regularizer)\n\t    global_step = tf.Variable(0, trainable=False)\n\t\n\t    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n\t    variables_average_op = variable_averages.apply(tf.trainable_variables())\n\t    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.argmax(y_, 1), logits=y)\n\t    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n\t    loss = cross_entropy_mean + tf.add_n(tf.get_collection(\"losses\"))\n\t    learing_rate = tf.train.exponential_decay(LEARNING_REATE_BASE,\n\t                                              global_step,\n\t                                              mnist.train.num_examples / BATCH_SIZE,\n\t                                              LEARNING_RATE_DECAY)\n\t    train_step = tf.train.GradientDescentOptimizer(learing_rate).minimize(loss, global_step)\n\t\n\t    with tf.control_dependencies([train_step, variables_average_op]):\n\t        train_op = tf.no_op(name=\"train\")\n\t\n\t    # 初始化持久化类\n\t    saver = tf.train.Saver()\n\t    with tf.Session() as sess:\n\t        tf.global_variables_initializer().run()\n\t\n\t        for i in range(TRAING_STEPS):\n\t            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n\t            _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict={x: xs, y_: ys})\n\t\n\t            if i % 1000 == 0:\n\t                print(\"After %d training step(s), loss on training batch is %g.\" % (i, loss_value))\n\t\n\t                saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)\n\t\n\t\n\tdef main(argv=None):\n\t    mnist = input_data.read_data_sets(\"../MNIST_data\", one_hot=True)\n\t    train(mnist)\n\t\n\t\n\tif __name__ == '__main__':\n\t    tf.app.run()\n\n> mnist_eval.py测试过程\n \n\t#!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2018/2/21 16:32\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : mnist_eval.py\n\t# @ToDo    : 测试过程\n\t\n\t\n\timport time\n\timport tensorflow as tf\n\tfrom tensorflow.examples.tutorials.mnist import input_data\n\t\n\timport neural_network_learning.hand_writting_refactor.mnist_inference as mnist_inference\n\timport neural_network_learning.hand_writting_refactor.mnist_train as mnist_train\n\t\n\t# 每10s加载一次最新模型，并在测试数据上测试最新模型的正确率\n\tEVAL_INTERVAL_SECS = 10\n\t\n\t\n\tdef evaluate(mnist):\n\t    x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name=\"input-x\")\n\t    y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name=\"input-y\")\n\t\n\t    validate_feed = {x: mnist.validation.images,\n\t                     y_: mnist.validation.labels}\n\t\n\t    y = mnist_inference.inference(x, None)\n\t\n\t    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n\t    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\t\n\t    variable_averages = tf.train.ExponentialMovingAverage(mnist_train.MOVING_AVERAGE_DECAY)\n\t    variables_to_restore = variable_averages.variables_to_restore()\n\t    saver = tf.train.Saver(variables_to_restore)\n\t\n\t    # 每隔EVAL_INTERVAL_SECS秒调用一次计算正确率的过程以检测训练过程中正确率的变化\n\t    stop_count = 0\n\t    while True:\n\t        with tf.Session() as sess:\n\t            ckpt = tf.train.get_checkpoint_state(mnist_train.MODEL_SAVE_PATH)\n\t            # 停止条件 #\n\t            stop_count += EVAL_INTERVAL_SECS\n\t            if stop_count == mnist_train.TRAING_STEPS:\n\t                return\n\t            # 停止条件 #\n\t            if ckpt and ckpt.model_checkpoint_path:\n\t                saver.restore(sess, ckpt.model_checkpoint_path)\n\t                # 通过文件名得到模型保存时迭代的轮数\n\t                # 输出./model/model.ckpt-29001\n\t                print(ckpt.model_checkpoint_path)\n\t                global_step = ckpt.model_checkpoint_path.split(\"/\")[-1].split(\"-\")[-1]\n\t                accuracy_score = sess.run(accuracy, feed_dict=validate_feed)\n\t                print(\"After %s training step(s), validation accuracy is %g\" % (global_step, accuracy_score))\n\t            else:\n\t                print(\"No checkpoint file found\")\n\t                return\n\t        time.sleep(EVAL_INTERVAL_SECS)\n\t\n\t\n\tdef main(argv=None):\n\t    mnist = input_data.read_data_sets(\"../MNIST_data\", one_hot=True)\n\t    evaluate(mnist)\n\t\n\t\n\tif __name__ == '__main__':\n\t    tf.app.run()\n\n# 参考文章 #\n[https://www.cnblogs.com/shihuc/p/6648130.html](https://www.cnblogs.com/shihuc/p/6648130.html \"Tensorflow之基于MNIST手写识别的入门介绍\")\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/Mnist手写数字体识别-tensorflow.md","raw":"---\ntitle: Mnist手写数字体识别(tensorflow)\ndate: 2018-03-20 21:35:05\ncategories:\n- tensorflow学习\n- tensorflow-Demo\ntags: \n- Mnist\n- tensorflow\n---\n# Tensorflow #\n\n\n> 首先，简单的说下，tensorflow的基本架构。\n>使用 TensorFlow, 你必须明白 TensorFlow:\n\n- 使用图 (graph) 来表示计算任务.\n- 在被称之为 会话 (Session) 的上下文 (context) 中执行图.\n- 使用 tensor 表示数据.\n- 通过 变量 (Variable) 维护状态.\n- 使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.\n\n<!--more -->\n\n# Tensor #\n\n> TensorFlow 是一个编程系统, 使用图来表示计算任务. 图中的节点被称之为 op (operation 的缩写). 一个 op 获得 0 个或多个 Tensor, 执行计算, 产生 0 个或多个 Tensor. 每个 Tensor 是一个类型化的多维数组. 例如, 你可以将一小组图像集表示为一个四维浮点数数组, 这四个维度分别是 [batch, height, width, channels].\n\n> 一个 TensorFlow 图描述了计算的过程. 为了进行计算, 图必须在 会话 里被启动. 会话 将图的 op 分发到诸如 CPU 或 GPU 之类的 设备 上, 同时提供执行 op 的方法. 这些方法执行后, 将产生的 tensor 返回. 在 Python 语言中, 返回的 tensor 是 numpy ndarray 对象; 在 C 和 C++ 语言中, 返回的 tensor 是tensorflow::Tensor 实例.\n\n> Tensor是tensorflow中非常重要且非常基础的概念，可以说数据的呈现形式都是用tensor表示的。输入输出都是tensor，tensor的中文含义，就是张量，可以简单的理解为线性代数里面的向量或者矩阵。\n\n# Graph #\n\n\n> TensorFlow 程序通常被组织成一个构建阶段和一个执行阶段. 在构建阶段, op 的执行步骤 被描述成一个图. 在执行阶段, 使用会话执行执行图中的 op.\n\n\n\n> 例如, 通常在构建阶段创建一个图来表示和训练神经网络, 然后在执行阶段反复执行图中的训练 op. 下面这个图，就是一个比较形象的说明，图中的每一个节点，就是一个op，各个op透过tensor数据流向形成边的连接，构成了一个图。\n\n![](https://images2015.cnblogs.com/blog/844237/201703/844237-20170330093311608-2056024255.gif)\n> 构建图的第一步, 是创建源 op (source op). 源 op 不需要任何输入, 例如 常量 (Constant). 源 op 的输出被传递给其它 op 做运算. Python 库中, op 构造器的返回值代表被构造出的 op 的输出, 这些返回值可以传递给其它 op 构造器作为输入.\n\n\n> TensorFlow Python 库有一个默认图 (default graph), op 构造器可以为其增加节点. 这个默认图对 许多程序来说已经足够用了.\n\n# Session #\n> 当图构建好后，需要创建一个Session来运行构建好的图，来实现逻辑，创建session的时候，若无任何参数，tensorflow将启用默认的session。session.run(xxx)是比较典型的使用方案, session运行结束后，返回值是一个tensor。\n\n\n\n> tensorflow中的session，有两大类，一种就是普通的session，即tensorflow.Session(),还有一种是交互式session，即tensorflow.InteractiveSession(). 使用Tensor.eval() 和Operation.run()方法代替Session.run(). 这样可以避免使用一个变量来持有会话, 为程序架构的设计添加了灵活性.\n\n\n# 数据载体 #\n> Tensorflow体系下，变量（Variable）是用来维护图计算过程中的中间状态信息，是一种常见高频使用的数据载体，还有一种特殊的数据载体，那就是常量（Constant），主要是用作图处理过程的输入量。这些数据载体，也都是以Tensor的形式体现。变量定义和常量定义上，比较好理解：\n   \n\t# 创建一个变量, 初始化为标量0.没有指定数据类型（dtype）\n\tstate = tf.Variable(0, name=\"counter\")\n\n\t# 创建一个常量，其值为1，没有指定数据类型（dtype）\n\tone = tf.constant(1)\n\n\n\n> 针对上面的变量和常量，看看Tensorflow里面的函数定义：\n>\n    class Variable(object):　\n\tdef __init__(self,\n\t\tinitial_value=None,\n\t\ttrainable=True,\n\t\tcollections=None,\n\t\tvalidate_shape=True,\n\t\tcaching_device=None,\n\t\tname=None,\n\t\tvariable_def=None,\n\t\tdtype=None,\n\t\texpected_shape=None,\n\t\timport_scope=None)：\n\n>\n\tdef constant(value, dtype=None, shape=None, name=\"Const\", verify_shape=False)：\n\n> 从上面的源码可以看出，定义变量，其实就是定义了一个Variable的实例，而定义常量，其实就是调用了一下常量函数，创建了一个常量Tensor。\n\n> 还有一个很重要的概念，那就是占位符placeholder，这个在Tensorflow中进行Feed数据灌入时，很有用。所谓的数据灌入，指的是在创建Tensorflow的图时，节点的输入部分，就是一个placeholder，后续在执行session操作的前，将实际数据Feed到图中，进行执行即可。\n>\n\tinput1 = tf.placeholder(tf.types.float32)\n\tinput2 = tf.placeholder(tf.types.float32)\n\toutput = tf.mul(input1, input2)\n>\t\n\twith tf.Session() as sess:\n\t  print sess.run([output], feed_dict={input1:[7.], input2:[2.]})\n>\t\n\t# 输出:\n\t# [array([ 14.], dtype=float32)]\n\n> 占位符的定义原型，也是一个函数：\n>\n\tdef placeholder(dtype, shape=None, name=None)：\n\n\n\n> 到此，Tensorflow的入门级的基本知识介绍完了。下面，将结合一个MNIST的手写识别的例子，从代码上简单分析一下，源代码分成4个文件：\n\n\n----------\n\n> main.py驱动程序\n \n    #!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2018/2/21 20:41\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : main.py\n\t# @ToDo    : 驱动程序\n\t\n\timport _thread\n\t\n\tfrom neural_network_learning.hand_writting_refactor import mnist_train, mnist_eval\n\t\n\t\n\tif __name__ == '__main__':\n\t    _thread.start_new_thread(mnist_train.main, (None,))\n\t    _thread.start_new_thread(mnist_eval.main, (None,))\n\t\n\t    # 这个不能删除，当做主线程\n\t    while 1:\n\t        pass\n\n> mnist_inference.py计算前向传播的过程及定义了神经网络的参数\n \n\t#!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2018/2/20 19:43\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : mnist_inference.py\n\t# @ToDo    : 定义了前向传播的过程及神经网络的参数\n\t\n\t\n\timport tensorflow as tf\n\t\n\t# 定义神经网络结构相关的参数\n\tINPUT_NODE = 784\n\tOUTPUT_NODE = 10\n\tLAYER1_NODE = 500\n\t\n\t\n\t# 训练时会创建这些变量，测试时会通过保存的模型加载这些变量的取值\n\tdef get_weight_variable(shape, regularizer):\n\t    weights = tf.get_variable(\"weights\", shape, initializer=tf.truncated_normal_initializer(stddev=0.1))\n\t\n\t    # 当使用正则化生成函数时,当前变量的正则化损失加入名字为losses的集合.\n\t    # 自定义集合\n\t    if regularizer:\n\t        tf.add_to_collection(\"losses\", regularizer(weights))\n\t    return weights\n\t\n\t\n\t# 前向传播过程\n\tdef inference(input_tensor, regularizer):\n\t    # 声明第一层神经网络的变量并完成前向传播过程\n\t    with tf.variable_scope(\"layer1\"):\n\t        weights = get_weight_variable([INPUT_NODE, LAYER1_NODE], regularizer)\n\t        biases = tf.get_variable(\"biases\", [LAYER1_NODE], initializer=tf.constant_initializer(0.0))\n\t        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights) + biases)\n\t\n\t    # 声明第二层圣经网络变量并完成前向传播过程\n\t    with tf.variable_scope(\"layer2\"):\n\t        weights = get_weight_variable([LAYER1_NODE, OUTPUT_NODE], regularizer)\n\t        biases = tf.get_variable(\"biases\", [OUTPUT_NODE], initializer=tf.constant_initializer(0.0))\n\t        layer2 = tf.matmul(layer1, weights) + biases\n\t    # 返回最后前向传播的结果\n\t    return layer2\n\n> mnist_train.py定义了神经网络的训练过程\n\n\t#!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2018/2/21 16:08\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : mnist_train.py\n\t# @ToDo    : 定义了神经网络的训练过程\n\t\n\timport os\n\t\n\timport tensorflow as tf\n\tfrom tensorflow.examples.tutorials.mnist import input_data\n\t\n\timport neural_network_learning.hand_writting_refactor.mnist_inference as mnist_inference\n\t\n\t# 配置神经网络的参数\n\tBATCH_SIZE = 100\n\tLEARNING_REATE_BASE = 0.8\n\tLEARNING_RATE_DECAY = 0.99\n\tREGULARAZTION_RATE = 0.0001\n\tTRAING_STEPS = 2000\n\tMOVING_AVERAGE_DECAY = 0.99\n\t# 模型保存的路径和文件名\n\tMODEL_SAVE_PATH = \"./model/\"\n\tMODEL_NAME = \"model.ckpt\"\n\t\n\t\n\tdef train(mnist):\n\t    # 定义输入输出placeholder\n\t    x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name=\"input-x\")\n\t    y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name=\"input-y\")\n\t\n\t    regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)\n\t    y = mnist_inference.inference(x, regularizer)\n\t    global_step = tf.Variable(0, trainable=False)\n\t\n\t    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n\t    variables_average_op = variable_averages.apply(tf.trainable_variables())\n\t    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.argmax(y_, 1), logits=y)\n\t    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n\t    loss = cross_entropy_mean + tf.add_n(tf.get_collection(\"losses\"))\n\t    learing_rate = tf.train.exponential_decay(LEARNING_REATE_BASE,\n\t                                              global_step,\n\t                                              mnist.train.num_examples / BATCH_SIZE,\n\t                                              LEARNING_RATE_DECAY)\n\t    train_step = tf.train.GradientDescentOptimizer(learing_rate).minimize(loss, global_step)\n\t\n\t    with tf.control_dependencies([train_step, variables_average_op]):\n\t        train_op = tf.no_op(name=\"train\")\n\t\n\t    # 初始化持久化类\n\t    saver = tf.train.Saver()\n\t    with tf.Session() as sess:\n\t        tf.global_variables_initializer().run()\n\t\n\t        for i in range(TRAING_STEPS):\n\t            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n\t            _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict={x: xs, y_: ys})\n\t\n\t            if i % 1000 == 0:\n\t                print(\"After %d training step(s), loss on training batch is %g.\" % (i, loss_value))\n\t\n\t                saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)\n\t\n\t\n\tdef main(argv=None):\n\t    mnist = input_data.read_data_sets(\"../MNIST_data\", one_hot=True)\n\t    train(mnist)\n\t\n\t\n\tif __name__ == '__main__':\n\t    tf.app.run()\n\n> mnist_eval.py测试过程\n \n\t#!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2018/2/21 16:32\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : mnist_eval.py\n\t# @ToDo    : 测试过程\n\t\n\t\n\timport time\n\timport tensorflow as tf\n\tfrom tensorflow.examples.tutorials.mnist import input_data\n\t\n\timport neural_network_learning.hand_writting_refactor.mnist_inference as mnist_inference\n\timport neural_network_learning.hand_writting_refactor.mnist_train as mnist_train\n\t\n\t# 每10s加载一次最新模型，并在测试数据上测试最新模型的正确率\n\tEVAL_INTERVAL_SECS = 10\n\t\n\t\n\tdef evaluate(mnist):\n\t    x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name=\"input-x\")\n\t    y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name=\"input-y\")\n\t\n\t    validate_feed = {x: mnist.validation.images,\n\t                     y_: mnist.validation.labels}\n\t\n\t    y = mnist_inference.inference(x, None)\n\t\n\t    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n\t    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\t\n\t    variable_averages = tf.train.ExponentialMovingAverage(mnist_train.MOVING_AVERAGE_DECAY)\n\t    variables_to_restore = variable_averages.variables_to_restore()\n\t    saver = tf.train.Saver(variables_to_restore)\n\t\n\t    # 每隔EVAL_INTERVAL_SECS秒调用一次计算正确率的过程以检测训练过程中正确率的变化\n\t    stop_count = 0\n\t    while True:\n\t        with tf.Session() as sess:\n\t            ckpt = tf.train.get_checkpoint_state(mnist_train.MODEL_SAVE_PATH)\n\t            # 停止条件 #\n\t            stop_count += EVAL_INTERVAL_SECS\n\t            if stop_count == mnist_train.TRAING_STEPS:\n\t                return\n\t            # 停止条件 #\n\t            if ckpt and ckpt.model_checkpoint_path:\n\t                saver.restore(sess, ckpt.model_checkpoint_path)\n\t                # 通过文件名得到模型保存时迭代的轮数\n\t                # 输出./model/model.ckpt-29001\n\t                print(ckpt.model_checkpoint_path)\n\t                global_step = ckpt.model_checkpoint_path.split(\"/\")[-1].split(\"-\")[-1]\n\t                accuracy_score = sess.run(accuracy, feed_dict=validate_feed)\n\t                print(\"After %s training step(s), validation accuracy is %g\" % (global_step, accuracy_score))\n\t            else:\n\t                print(\"No checkpoint file found\")\n\t                return\n\t        time.sleep(EVAL_INTERVAL_SECS)\n\t\n\t\n\tdef main(argv=None):\n\t    mnist = input_data.read_data_sets(\"../MNIST_data\", one_hot=True)\n\t    evaluate(mnist)\n\t\n\t\n\tif __name__ == '__main__':\n\t    tf.app.run()\n\n# 参考文章 #\n[https://www.cnblogs.com/shihuc/p/6648130.html](https://www.cnblogs.com/shihuc/p/6648130.html \"Tensorflow之基于MNIST手写识别的入门介绍\")\n\n\n\n\n\n\n\n\n\n\n\n","slug":"Mnist手写数字体识别-tensorflow","published":1,"updated":"2018-03-20T13:59:42.404Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjezqafi10000f4htmvkkdxmr","content":"<h1 id=\"Tensorflow\"><a href=\"#Tensorflow\" class=\"headerlink\" title=\"Tensorflow\"></a>Tensorflow</h1><blockquote>\n<p>首先，简单的说下，tensorflow的基本架构。<br>使用 TensorFlow, 你必须明白 TensorFlow:</p>\n</blockquote>\n<ul>\n<li>使用图 (graph) 来表示计算任务.</li>\n<li>在被称之为 会话 (Session) 的上下文 (context) 中执行图.</li>\n<li>使用 tensor 表示数据.</li>\n<li>通过 变量 (Variable) 维护状态.</li>\n<li>使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.</li>\n</ul>\n<a id=\"more\"></a>\n<h1 id=\"Tensor\"><a href=\"#Tensor\" class=\"headerlink\" title=\"Tensor\"></a>Tensor</h1><blockquote>\n<p>TensorFlow 是一个编程系统, 使用图来表示计算任务. 图中的节点被称之为 op (operation 的缩写). 一个 op 获得 0 个或多个 Tensor, 执行计算, 产生 0 个或多个 Tensor. 每个 Tensor 是一个类型化的多维数组. 例如, 你可以将一小组图像集表示为一个四维浮点数数组, 这四个维度分别是 [batch, height, width, channels].</p>\n</blockquote>\n<blockquote>\n<p>一个 TensorFlow 图描述了计算的过程. 为了进行计算, 图必须在 会话 里被启动. 会话 将图的 op 分发到诸如 CPU 或 GPU 之类的 设备 上, 同时提供执行 op 的方法. 这些方法执行后, 将产生的 tensor 返回. 在 Python 语言中, 返回的 tensor 是 numpy ndarray 对象; 在 C 和 C++ 语言中, 返回的 tensor 是tensorflow::Tensor 实例.</p>\n</blockquote>\n<blockquote>\n<p>Tensor是tensorflow中非常重要且非常基础的概念，可以说数据的呈现形式都是用tensor表示的。输入输出都是tensor，tensor的中文含义，就是张量，可以简单的理解为线性代数里面的向量或者矩阵。</p>\n</blockquote>\n<h1 id=\"Graph\"><a href=\"#Graph\" class=\"headerlink\" title=\"Graph\"></a>Graph</h1><blockquote>\n<p>TensorFlow 程序通常被组织成一个构建阶段和一个执行阶段. 在构建阶段, op 的执行步骤 被描述成一个图. 在执行阶段, 使用会话执行执行图中的 op.</p>\n</blockquote>\n<blockquote>\n<p>例如, 通常在构建阶段创建一个图来表示和训练神经网络, 然后在执行阶段反复执行图中的训练 op. 下面这个图，就是一个比较形象的说明，图中的每一个节点，就是一个op，各个op透过tensor数据流向形成边的连接，构成了一个图。</p>\n</blockquote>\n<p><img src=\"https://images2015.cnblogs.com/blog/844237/201703/844237-20170330093311608-2056024255.gif\" alt=\"\"></p>\n<blockquote>\n<p>构建图的第一步, 是创建源 op (source op). 源 op 不需要任何输入, 例如 常量 (Constant). 源 op 的输出被传递给其它 op 做运算. Python 库中, op 构造器的返回值代表被构造出的 op 的输出, 这些返回值可以传递给其它 op 构造器作为输入.</p>\n</blockquote>\n<blockquote>\n<p>TensorFlow Python 库有一个默认图 (default graph), op 构造器可以为其增加节点. 这个默认图对 许多程序来说已经足够用了.</p>\n</blockquote>\n<h1 id=\"Session\"><a href=\"#Session\" class=\"headerlink\" title=\"Session\"></a>Session</h1><blockquote>\n<p>当图构建好后，需要创建一个Session来运行构建好的图，来实现逻辑，创建session的时候，若无任何参数，tensorflow将启用默认的session。session.run(xxx)是比较典型的使用方案, session运行结束后，返回值是一个tensor。</p>\n</blockquote>\n<blockquote>\n<p>tensorflow中的session，有两大类，一种就是普通的session，即tensorflow.Session(),还有一种是交互式session，即tensorflow.InteractiveSession(). 使用Tensor.eval() 和Operation.run()方法代替Session.run(). 这样可以避免使用一个变量来持有会话, 为程序架构的设计添加了灵活性.</p>\n</blockquote>\n<h1 id=\"数据载体\"><a href=\"#数据载体\" class=\"headerlink\" title=\"数据载体\"></a>数据载体</h1><blockquote>\n<p>Tensorflow体系下，变量（Variable）是用来维护图计算过程中的中间状态信息，是一种常见高频使用的数据载体，还有一种特殊的数据载体，那就是常量（Constant），主要是用作图处理过程的输入量。这些数据载体，也都是以Tensor的形式体现。变量定义和常量定义上，比较好理解：</p>\n</blockquote>\n<pre><code># 创建一个变量, 初始化为标量0.没有指定数据类型（dtype）\nstate = tf.Variable(0, name=&quot;counter&quot;)\n\n# 创建一个常量，其值为1，没有指定数据类型（dtype）\none = tf.constant(1)\n</code></pre><blockquote>\n<p>针对上面的变量和常量，看看Tensorflow里面的函数定义：</p>\n</blockquote>\n<pre><code>class Variable(object):　\ndef __init__(self,\n    initial_value=None,\n    trainable=True,\n    collections=None,\n    validate_shape=True,\n    caching_device=None,\n    name=None,\n    variable_def=None,\n    dtype=None,\n    expected_shape=None,\n    import_scope=None)：\n</code></pre><blockquote>\n</blockquote>\n<pre><code>def constant(value, dtype=None, shape=None, name=&quot;Const&quot;, verify_shape=False)：\n</code></pre><blockquote>\n<p>从上面的源码可以看出，定义变量，其实就是定义了一个Variable的实例，而定义常量，其实就是调用了一下常量函数，创建了一个常量Tensor。</p>\n</blockquote>\n<blockquote>\n<p>还有一个很重要的概念，那就是占位符placeholder，这个在Tensorflow中进行Feed数据灌入时，很有用。所谓的数据灌入，指的是在创建Tensorflow的图时，节点的输入部分，就是一个placeholder，后续在执行session操作的前，将实际数据Feed到图中，进行执行即可。</p>\n</blockquote>\n<pre><code>input1 = tf.placeholder(tf.types.float32)\ninput2 = tf.placeholder(tf.types.float32)\noutput = tf.mul(input1, input2)\n</code></pre><blockquote>\n<pre><code>with tf.Session() as sess:\n  print sess.run([output], feed_dict={input1:[7.], input2:[2.]})\n</code></pre></blockquote>\n<pre><code># 输出:\n# [array([ 14.], dtype=float32)]\n</code></pre><blockquote>\n<p>占位符的定义原型，也是一个函数：</p>\n</blockquote>\n<pre><code>def placeholder(dtype, shape=None, name=None)：\n</code></pre><blockquote>\n<p>到此，Tensorflow的入门级的基本知识介绍完了。下面，将结合一个MNIST的手写识别的例子，从代码上简单分析一下，源代码分成4个文件：</p>\n</blockquote>\n<hr>\n<blockquote>\n<p>main.py驱动程序</p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2018/2/21 20:41\n# @Author  : Jasontang\n# @Site    : \n# @File    : main.py\n# @ToDo    : 驱动程序\n\nimport _thread\n\nfrom neural_network_learning.hand_writting_refactor import mnist_train, mnist_eval\n\n\nif __name__ == &apos;__main__&apos;:\n    _thread.start_new_thread(mnist_train.main, (None,))\n    _thread.start_new_thread(mnist_eval.main, (None,))\n\n    # 这个不能删除，当做主线程\n    while 1:\n        pass\n</code></pre><blockquote>\n<p>mnist_inference.py计算前向传播的过程及定义了神经网络的参数</p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2018/2/20 19:43\n# @Author  : Jasontang\n# @Site    : \n# @File    : mnist_inference.py\n# @ToDo    : 定义了前向传播的过程及神经网络的参数\n\n\nimport tensorflow as tf\n\n# 定义神经网络结构相关的参数\nINPUT_NODE = 784\nOUTPUT_NODE = 10\nLAYER1_NODE = 500\n\n\n# 训练时会创建这些变量，测试时会通过保存的模型加载这些变量的取值\ndef get_weight_variable(shape, regularizer):\n    weights = tf.get_variable(&quot;weights&quot;, shape, initializer=tf.truncated_normal_initializer(stddev=0.1))\n\n    # 当使用正则化生成函数时,当前变量的正则化损失加入名字为losses的集合.\n    # 自定义集合\n    if regularizer:\n        tf.add_to_collection(&quot;losses&quot;, regularizer(weights))\n    return weights\n\n\n# 前向传播过程\ndef inference(input_tensor, regularizer):\n    # 声明第一层神经网络的变量并完成前向传播过程\n    with tf.variable_scope(&quot;layer1&quot;):\n        weights = get_weight_variable([INPUT_NODE, LAYER1_NODE], regularizer)\n        biases = tf.get_variable(&quot;biases&quot;, [LAYER1_NODE], initializer=tf.constant_initializer(0.0))\n        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights) + biases)\n\n    # 声明第二层圣经网络变量并完成前向传播过程\n    with tf.variable_scope(&quot;layer2&quot;):\n        weights = get_weight_variable([LAYER1_NODE, OUTPUT_NODE], regularizer)\n        biases = tf.get_variable(&quot;biases&quot;, [OUTPUT_NODE], initializer=tf.constant_initializer(0.0))\n        layer2 = tf.matmul(layer1, weights) + biases\n    # 返回最后前向传播的结果\n    return layer2\n</code></pre><blockquote>\n<p>mnist_train.py定义了神经网络的训练过程</p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2018/2/21 16:08\n# @Author  : Jasontang\n# @Site    : \n# @File    : mnist_train.py\n# @ToDo    : 定义了神经网络的训练过程\n\nimport os\n\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nimport neural_network_learning.hand_writting_refactor.mnist_inference as mnist_inference\n\n# 配置神经网络的参数\nBATCH_SIZE = 100\nLEARNING_REATE_BASE = 0.8\nLEARNING_RATE_DECAY = 0.99\nREGULARAZTION_RATE = 0.0001\nTRAING_STEPS = 2000\nMOVING_AVERAGE_DECAY = 0.99\n# 模型保存的路径和文件名\nMODEL_SAVE_PATH = &quot;./model/&quot;\nMODEL_NAME = &quot;model.ckpt&quot;\n\n\ndef train(mnist):\n    # 定义输入输出placeholder\n    x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name=&quot;input-x&quot;)\n    y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name=&quot;input-y&quot;)\n\n    regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)\n    y = mnist_inference.inference(x, regularizer)\n    global_step = tf.Variable(0, trainable=False)\n\n    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n    variables_average_op = variable_averages.apply(tf.trainable_variables())\n    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.argmax(y_, 1), logits=y)\n    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n    loss = cross_entropy_mean + tf.add_n(tf.get_collection(&quot;losses&quot;))\n    learing_rate = tf.train.exponential_decay(LEARNING_REATE_BASE,\n                                              global_step,\n                                              mnist.train.num_examples / BATCH_SIZE,\n                                              LEARNING_RATE_DECAY)\n    train_step = tf.train.GradientDescentOptimizer(learing_rate).minimize(loss, global_step)\n\n    with tf.control_dependencies([train_step, variables_average_op]):\n        train_op = tf.no_op(name=&quot;train&quot;)\n\n    # 初始化持久化类\n    saver = tf.train.Saver()\n    with tf.Session() as sess:\n        tf.global_variables_initializer().run()\n\n        for i in range(TRAING_STEPS):\n            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n            _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict={x: xs, y_: ys})\n\n            if i % 1000 == 0:\n                print(&quot;After %d training step(s), loss on training batch is %g.&quot; % (i, loss_value))\n\n                saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)\n\n\ndef main(argv=None):\n    mnist = input_data.read_data_sets(&quot;../MNIST_data&quot;, one_hot=True)\n    train(mnist)\n\n\nif __name__ == &apos;__main__&apos;:\n    tf.app.run()\n</code></pre><blockquote>\n<p>mnist_eval.py测试过程</p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2018/2/21 16:32\n# @Author  : Jasontang\n# @Site    : \n# @File    : mnist_eval.py\n# @ToDo    : 测试过程\n\n\nimport time\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nimport neural_network_learning.hand_writting_refactor.mnist_inference as mnist_inference\nimport neural_network_learning.hand_writting_refactor.mnist_train as mnist_train\n\n# 每10s加载一次最新模型，并在测试数据上测试最新模型的正确率\nEVAL_INTERVAL_SECS = 10\n\n\ndef evaluate(mnist):\n    x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name=&quot;input-x&quot;)\n    y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name=&quot;input-y&quot;)\n\n    validate_feed = {x: mnist.validation.images,\n                     y_: mnist.validation.labels}\n\n    y = mnist_inference.inference(x, None)\n\n    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n    variable_averages = tf.train.ExponentialMovingAverage(mnist_train.MOVING_AVERAGE_DECAY)\n    variables_to_restore = variable_averages.variables_to_restore()\n    saver = tf.train.Saver(variables_to_restore)\n\n    # 每隔EVAL_INTERVAL_SECS秒调用一次计算正确率的过程以检测训练过程中正确率的变化\n    stop_count = 0\n    while True:\n        with tf.Session() as sess:\n            ckpt = tf.train.get_checkpoint_state(mnist_train.MODEL_SAVE_PATH)\n            # 停止条件 #\n            stop_count += EVAL_INTERVAL_SECS\n            if stop_count == mnist_train.TRAING_STEPS:\n                return\n            # 停止条件 #\n            if ckpt and ckpt.model_checkpoint_path:\n                saver.restore(sess, ckpt.model_checkpoint_path)\n                # 通过文件名得到模型保存时迭代的轮数\n                # 输出./model/model.ckpt-29001\n                print(ckpt.model_checkpoint_path)\n                global_step = ckpt.model_checkpoint_path.split(&quot;/&quot;)[-1].split(&quot;-&quot;)[-1]\n                accuracy_score = sess.run(accuracy, feed_dict=validate_feed)\n                print(&quot;After %s training step(s), validation accuracy is %g&quot; % (global_step, accuracy_score))\n            else:\n                print(&quot;No checkpoint file found&quot;)\n                return\n        time.sleep(EVAL_INTERVAL_SECS)\n\n\ndef main(argv=None):\n    mnist = input_data.read_data_sets(&quot;../MNIST_data&quot;, one_hot=True)\n    evaluate(mnist)\n\n\nif __name__ == &apos;__main__&apos;:\n    tf.app.run()\n</code></pre><h1 id=\"参考文章\"><a href=\"#参考文章\" class=\"headerlink\" title=\"参考文章\"></a>参考文章</h1><p><a href=\"https://www.cnblogs.com/shihuc/p/6648130.html\" title=\"Tensorflow之基于MNIST手写识别的入门介绍\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/shihuc/p/6648130.html</a></p>\n","site":{"data":{"about":{"avatar":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/avatar.jpg","name":"tech.radish","tag":"python/Java/ML/CV","desc":"行走在边缘的coder","skills":{"ptyhon":5,"Java":6,"invisible-split-line-1":-1,"ML":4},"projects":[{"name":"合金战争(Java Swing + MySql + Socket)","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/game.png","tags":["Java","游戏开发"],"description":"合金战争是一款使用JavaSwing作为界面，MySQL作为数据库服务器，使用Socket通信的网络版RPG游戏","link_text":"合金战争","link":null},{"name":"iclass智能课堂助手","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/iclass.png","description":"iclass是一款实用SSM框架开发的轻量级课堂辅助教学系统，旨在加强和方便师生之间的交流合作，提高教学效率。拥有web端和安卓端（本人完成web端和安卓后端的开发）","tags":["毕业设计","SSM框架"],"link_text":"Github地址","link":"https://github.com/Mic-JasonTang/iclass"}],"reward":["https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/alipay-rewardcode.jpg","https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/wetchat-rewardcode.jpg"]},"link":{"social":{"github":"https://github.com/mic-jasontang"},"extern":{"Github地址":"https://github.com/mic-jasontang"}},"slider":[{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/coloreggs.jpg","align":"center","title":"computer vision","subtitle":"whole world","link":"/"},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/fantasy.jpg","align":"left","title":"import tensorflow as tf","subtitle":"sess.run(hello)","link":null},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/pythoner.png","align":"right","title":"import __helloworld__","subtitle":">>> Hello World","link":null}],"hint":{"new":{"selector":[".menu-reading"]}},"reading":{"define":{"readed":"已读","reading":"在读","wanted":"想读"},"contents":{"readed":[{"title":"嫌疑人X的献身","cover":"https://img3.doubanio.com/lpic/s3254244.jpg","review":"百年一遇的数学天才石神，每天唯一的乐趣，便是去固定的便当店买午餐，只为看一眼在便当店做事的邻居靖子。","score":"8.9","doubanLink":"https://book.douban.com/subject/3211779/"},{"title":"Python核心编程（第二版）","cover":"https://img3.doubanio.com/lpic/s3140466.jpg","review":"本书是Python开发者的完全指南——针对 Python 2.5全面升级","score":"7.7","doubanLink":"https://book.douban.com/subject/3112503/"},{"title":"程序员代码面试指南：IT名企算法与数据结构题目最优解","cover":"https://img3.doubanio.com/lpic/s28313721.jpg","review":"这是一本程序员面试宝典！书中对IT名企代码面试各类题目的最优解进行了总结，并提供了相关代码实现。","score":"8.8","doubanLink":"https://book.douban.com/subject/26638586/"},{"title":"机器学习实战","cover":"https://img3.doubanio.com/lpic/s26696371.jpg","review":"全书通过精心编排的实例，切入日常工作任务，摒弃学术化语言，利用高效的可复用Python代码来阐释如何处理统计数据，进行数据分析及可视化。通过各种实例，读者可从中学会机器学习的核心算法，并能将其运用于一些策略性任务中，如分类、预测、推荐。另外，还可用它们来实现一些更高级的功能，如汇总和简化等。","score":"8.2","doubanLink":"https://book.douban.com/subject/24703171/"},{"title":"TensorFlow实战","cover":"https://img3.doubanio.com/lpic/s29343414.jpg","review":"《TensorFlow实战》希望能帮读者快速入门TensorFlow和深度学习，在工业界或者研究中快速地将想法落地为可实践的模型。","score":"7.3","doubanLink":"https://book.douban.com/subject/26974266/"}],"reading":[{"title":"深度学习","cover":"https://img1.doubanio.com/lpic/s29518349.jpg","review":"《深度学习》适合各类读者阅读，包括相关专业的大学生或研究生，以及不具有机器学习或统计背景、但是想要快速补充深度学习知识，以便在实际产品或平台中应用的软件工程师。","score":"8.7","doubanLink":"https://book.douban.com/subject/27087503/"},{"title":"Tensorflow：实战Google深度学习框架","cover":"https://img3.doubanio.com/lpic/s29349250.jpg","review":"《Tensorflow实战》包含了深度学习的入门知识和大量实践经验，是走进这个最新、最火的人工智能领域的首选参考书。","score":"8.2","doubanLink":"https://book.douban.com/subject/26976457/"},{"title":"机器学习","cover":"https://img1.doubanio.com/lpic/s28735609.jpg","review":"本书作为该领域的入门教材，在内容上尽可能涵盖机器学习基础知识的各方面。 为了使尽可能多的读者通过本书对机器学习有所了解, 作者试图尽可能少地使用数学知识. 然而, 少量的概率、统计、代数、优化、逻辑知识似乎不可避免. 因此, 本书更适合大学三年级以上的理工科本科生和研究生, 以及具有类似背景的对机器学 习感兴趣的人士. 为方便读者, 本书附录给出了一些相关数学基础知识简介.","score":"8.7","doubanLink":"https://book.douban.com/subject/26708119/"}],"wanted":[{"title":"OpenCV 3计算机视觉：Python语言实现（原书第2版）","cover":"https://img3.doubanio.com/lpic/s28902360.jpg","review":"本书针对具有一定Python工作经验的程序员以及想要利用OpenCV库研究计算机视觉课题的读者。本书不要求读者具有计算机视觉或OpenCV经验，但要具有编程经验。","score":"7.8","doubanLink":"https://book.douban.com/subject/26816975/"},{"title":"Python计算机视觉编程","cover":"https://img3.doubanio.com/lpic/s27305520.jpg","review":"《python计算机视觉编程》适合的读者是：有一定编程与数学基础，想要了解计算机视觉的基本理论与算法的学生，以及计算机科学、信号处理、物理学、应用数学和统计学、神经生理学、认知科学等领域的研究人员和从业者。","score":"7.5","doubanLink":"https://book.douban.com/subject/25906843/"}]}}}},"excerpt":"<h1 id=\"Tensorflow\"><a href=\"#Tensorflow\" class=\"headerlink\" title=\"Tensorflow\"></a>Tensorflow</h1><blockquote>\n<p>首先，简单的说下，tensorflow的基本架构。<br>使用 TensorFlow, 你必须明白 TensorFlow:</p>\n</blockquote>\n<ul>\n<li>使用图 (graph) 来表示计算任务.</li>\n<li>在被称之为 会话 (Session) 的上下文 (context) 中执行图.</li>\n<li>使用 tensor 表示数据.</li>\n<li>通过 变量 (Variable) 维护状态.</li>\n<li>使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.</li>\n</ul>","more":"<h1 id=\"Tensor\"><a href=\"#Tensor\" class=\"headerlink\" title=\"Tensor\"></a>Tensor</h1><blockquote>\n<p>TensorFlow 是一个编程系统, 使用图来表示计算任务. 图中的节点被称之为 op (operation 的缩写). 一个 op 获得 0 个或多个 Tensor, 执行计算, 产生 0 个或多个 Tensor. 每个 Tensor 是一个类型化的多维数组. 例如, 你可以将一小组图像集表示为一个四维浮点数数组, 这四个维度分别是 [batch, height, width, channels].</p>\n</blockquote>\n<blockquote>\n<p>一个 TensorFlow 图描述了计算的过程. 为了进行计算, 图必须在 会话 里被启动. 会话 将图的 op 分发到诸如 CPU 或 GPU 之类的 设备 上, 同时提供执行 op 的方法. 这些方法执行后, 将产生的 tensor 返回. 在 Python 语言中, 返回的 tensor 是 numpy ndarray 对象; 在 C 和 C++ 语言中, 返回的 tensor 是tensorflow::Tensor 实例.</p>\n</blockquote>\n<blockquote>\n<p>Tensor是tensorflow中非常重要且非常基础的概念，可以说数据的呈现形式都是用tensor表示的。输入输出都是tensor，tensor的中文含义，就是张量，可以简单的理解为线性代数里面的向量或者矩阵。</p>\n</blockquote>\n<h1 id=\"Graph\"><a href=\"#Graph\" class=\"headerlink\" title=\"Graph\"></a>Graph</h1><blockquote>\n<p>TensorFlow 程序通常被组织成一个构建阶段和一个执行阶段. 在构建阶段, op 的执行步骤 被描述成一个图. 在执行阶段, 使用会话执行执行图中的 op.</p>\n</blockquote>\n<blockquote>\n<p>例如, 通常在构建阶段创建一个图来表示和训练神经网络, 然后在执行阶段反复执行图中的训练 op. 下面这个图，就是一个比较形象的说明，图中的每一个节点，就是一个op，各个op透过tensor数据流向形成边的连接，构成了一个图。</p>\n</blockquote>\n<p><img src=\"https://images2015.cnblogs.com/blog/844237/201703/844237-20170330093311608-2056024255.gif\" alt=\"\"></p>\n<blockquote>\n<p>构建图的第一步, 是创建源 op (source op). 源 op 不需要任何输入, 例如 常量 (Constant). 源 op 的输出被传递给其它 op 做运算. Python 库中, op 构造器的返回值代表被构造出的 op 的输出, 这些返回值可以传递给其它 op 构造器作为输入.</p>\n</blockquote>\n<blockquote>\n<p>TensorFlow Python 库有一个默认图 (default graph), op 构造器可以为其增加节点. 这个默认图对 许多程序来说已经足够用了.</p>\n</blockquote>\n<h1 id=\"Session\"><a href=\"#Session\" class=\"headerlink\" title=\"Session\"></a>Session</h1><blockquote>\n<p>当图构建好后，需要创建一个Session来运行构建好的图，来实现逻辑，创建session的时候，若无任何参数，tensorflow将启用默认的session。session.run(xxx)是比较典型的使用方案, session运行结束后，返回值是一个tensor。</p>\n</blockquote>\n<blockquote>\n<p>tensorflow中的session，有两大类，一种就是普通的session，即tensorflow.Session(),还有一种是交互式session，即tensorflow.InteractiveSession(). 使用Tensor.eval() 和Operation.run()方法代替Session.run(). 这样可以避免使用一个变量来持有会话, 为程序架构的设计添加了灵活性.</p>\n</blockquote>\n<h1 id=\"数据载体\"><a href=\"#数据载体\" class=\"headerlink\" title=\"数据载体\"></a>数据载体</h1><blockquote>\n<p>Tensorflow体系下，变量（Variable）是用来维护图计算过程中的中间状态信息，是一种常见高频使用的数据载体，还有一种特殊的数据载体，那就是常量（Constant），主要是用作图处理过程的输入量。这些数据载体，也都是以Tensor的形式体现。变量定义和常量定义上，比较好理解：</p>\n</blockquote>\n<pre><code># 创建一个变量, 初始化为标量0.没有指定数据类型（dtype）\nstate = tf.Variable(0, name=&quot;counter&quot;)\n\n# 创建一个常量，其值为1，没有指定数据类型（dtype）\none = tf.constant(1)\n</code></pre><blockquote>\n<p>针对上面的变量和常量，看看Tensorflow里面的函数定义：</p>\n</blockquote>\n<pre><code>class Variable(object):　\ndef __init__(self,\n    initial_value=None,\n    trainable=True,\n    collections=None,\n    validate_shape=True,\n    caching_device=None,\n    name=None,\n    variable_def=None,\n    dtype=None,\n    expected_shape=None,\n    import_scope=None)：\n</code></pre><blockquote>\n</blockquote>\n<pre><code>def constant(value, dtype=None, shape=None, name=&quot;Const&quot;, verify_shape=False)：\n</code></pre><blockquote>\n<p>从上面的源码可以看出，定义变量，其实就是定义了一个Variable的实例，而定义常量，其实就是调用了一下常量函数，创建了一个常量Tensor。</p>\n</blockquote>\n<blockquote>\n<p>还有一个很重要的概念，那就是占位符placeholder，这个在Tensorflow中进行Feed数据灌入时，很有用。所谓的数据灌入，指的是在创建Tensorflow的图时，节点的输入部分，就是一个placeholder，后续在执行session操作的前，将实际数据Feed到图中，进行执行即可。</p>\n</blockquote>\n<pre><code>input1 = tf.placeholder(tf.types.float32)\ninput2 = tf.placeholder(tf.types.float32)\noutput = tf.mul(input1, input2)\n</code></pre><blockquote>\n<pre><code>with tf.Session() as sess:\n  print sess.run([output], feed_dict={input1:[7.], input2:[2.]})\n</code></pre></blockquote>\n<pre><code># 输出:\n# [array([ 14.], dtype=float32)]\n</code></pre><blockquote>\n<p>占位符的定义原型，也是一个函数：</p>\n</blockquote>\n<pre><code>def placeholder(dtype, shape=None, name=None)：\n</code></pre><blockquote>\n<p>到此，Tensorflow的入门级的基本知识介绍完了。下面，将结合一个MNIST的手写识别的例子，从代码上简单分析一下，源代码分成4个文件：</p>\n</blockquote>\n<hr>\n<blockquote>\n<p>main.py驱动程序</p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2018/2/21 20:41\n# @Author  : Jasontang\n# @Site    : \n# @File    : main.py\n# @ToDo    : 驱动程序\n\nimport _thread\n\nfrom neural_network_learning.hand_writting_refactor import mnist_train, mnist_eval\n\n\nif __name__ == &apos;__main__&apos;:\n    _thread.start_new_thread(mnist_train.main, (None,))\n    _thread.start_new_thread(mnist_eval.main, (None,))\n\n    # 这个不能删除，当做主线程\n    while 1:\n        pass\n</code></pre><blockquote>\n<p>mnist_inference.py计算前向传播的过程及定义了神经网络的参数</p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2018/2/20 19:43\n# @Author  : Jasontang\n# @Site    : \n# @File    : mnist_inference.py\n# @ToDo    : 定义了前向传播的过程及神经网络的参数\n\n\nimport tensorflow as tf\n\n# 定义神经网络结构相关的参数\nINPUT_NODE = 784\nOUTPUT_NODE = 10\nLAYER1_NODE = 500\n\n\n# 训练时会创建这些变量，测试时会通过保存的模型加载这些变量的取值\ndef get_weight_variable(shape, regularizer):\n    weights = tf.get_variable(&quot;weights&quot;, shape, initializer=tf.truncated_normal_initializer(stddev=0.1))\n\n    # 当使用正则化生成函数时,当前变量的正则化损失加入名字为losses的集合.\n    # 自定义集合\n    if regularizer:\n        tf.add_to_collection(&quot;losses&quot;, regularizer(weights))\n    return weights\n\n\n# 前向传播过程\ndef inference(input_tensor, regularizer):\n    # 声明第一层神经网络的变量并完成前向传播过程\n    with tf.variable_scope(&quot;layer1&quot;):\n        weights = get_weight_variable([INPUT_NODE, LAYER1_NODE], regularizer)\n        biases = tf.get_variable(&quot;biases&quot;, [LAYER1_NODE], initializer=tf.constant_initializer(0.0))\n        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights) + biases)\n\n    # 声明第二层圣经网络变量并完成前向传播过程\n    with tf.variable_scope(&quot;layer2&quot;):\n        weights = get_weight_variable([LAYER1_NODE, OUTPUT_NODE], regularizer)\n        biases = tf.get_variable(&quot;biases&quot;, [OUTPUT_NODE], initializer=tf.constant_initializer(0.0))\n        layer2 = tf.matmul(layer1, weights) + biases\n    # 返回最后前向传播的结果\n    return layer2\n</code></pre><blockquote>\n<p>mnist_train.py定义了神经网络的训练过程</p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2018/2/21 16:08\n# @Author  : Jasontang\n# @Site    : \n# @File    : mnist_train.py\n# @ToDo    : 定义了神经网络的训练过程\n\nimport os\n\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nimport neural_network_learning.hand_writting_refactor.mnist_inference as mnist_inference\n\n# 配置神经网络的参数\nBATCH_SIZE = 100\nLEARNING_REATE_BASE = 0.8\nLEARNING_RATE_DECAY = 0.99\nREGULARAZTION_RATE = 0.0001\nTRAING_STEPS = 2000\nMOVING_AVERAGE_DECAY = 0.99\n# 模型保存的路径和文件名\nMODEL_SAVE_PATH = &quot;./model/&quot;\nMODEL_NAME = &quot;model.ckpt&quot;\n\n\ndef train(mnist):\n    # 定义输入输出placeholder\n    x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name=&quot;input-x&quot;)\n    y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name=&quot;input-y&quot;)\n\n    regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)\n    y = mnist_inference.inference(x, regularizer)\n    global_step = tf.Variable(0, trainable=False)\n\n    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n    variables_average_op = variable_averages.apply(tf.trainable_variables())\n    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.argmax(y_, 1), logits=y)\n    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n    loss = cross_entropy_mean + tf.add_n(tf.get_collection(&quot;losses&quot;))\n    learing_rate = tf.train.exponential_decay(LEARNING_REATE_BASE,\n                                              global_step,\n                                              mnist.train.num_examples / BATCH_SIZE,\n                                              LEARNING_RATE_DECAY)\n    train_step = tf.train.GradientDescentOptimizer(learing_rate).minimize(loss, global_step)\n\n    with tf.control_dependencies([train_step, variables_average_op]):\n        train_op = tf.no_op(name=&quot;train&quot;)\n\n    # 初始化持久化类\n    saver = tf.train.Saver()\n    with tf.Session() as sess:\n        tf.global_variables_initializer().run()\n\n        for i in range(TRAING_STEPS):\n            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n            _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict={x: xs, y_: ys})\n\n            if i % 1000 == 0:\n                print(&quot;After %d training step(s), loss on training batch is %g.&quot; % (i, loss_value))\n\n                saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)\n\n\ndef main(argv=None):\n    mnist = input_data.read_data_sets(&quot;../MNIST_data&quot;, one_hot=True)\n    train(mnist)\n\n\nif __name__ == &apos;__main__&apos;:\n    tf.app.run()\n</code></pre><blockquote>\n<p>mnist_eval.py测试过程</p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2018/2/21 16:32\n# @Author  : Jasontang\n# @Site    : \n# @File    : mnist_eval.py\n# @ToDo    : 测试过程\n\n\nimport time\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nimport neural_network_learning.hand_writting_refactor.mnist_inference as mnist_inference\nimport neural_network_learning.hand_writting_refactor.mnist_train as mnist_train\n\n# 每10s加载一次最新模型，并在测试数据上测试最新模型的正确率\nEVAL_INTERVAL_SECS = 10\n\n\ndef evaluate(mnist):\n    x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name=&quot;input-x&quot;)\n    y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name=&quot;input-y&quot;)\n\n    validate_feed = {x: mnist.validation.images,\n                     y_: mnist.validation.labels}\n\n    y = mnist_inference.inference(x, None)\n\n    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n    variable_averages = tf.train.ExponentialMovingAverage(mnist_train.MOVING_AVERAGE_DECAY)\n    variables_to_restore = variable_averages.variables_to_restore()\n    saver = tf.train.Saver(variables_to_restore)\n\n    # 每隔EVAL_INTERVAL_SECS秒调用一次计算正确率的过程以检测训练过程中正确率的变化\n    stop_count = 0\n    while True:\n        with tf.Session() as sess:\n            ckpt = tf.train.get_checkpoint_state(mnist_train.MODEL_SAVE_PATH)\n            # 停止条件 #\n            stop_count += EVAL_INTERVAL_SECS\n            if stop_count == mnist_train.TRAING_STEPS:\n                return\n            # 停止条件 #\n            if ckpt and ckpt.model_checkpoint_path:\n                saver.restore(sess, ckpt.model_checkpoint_path)\n                # 通过文件名得到模型保存时迭代的轮数\n                # 输出./model/model.ckpt-29001\n                print(ckpt.model_checkpoint_path)\n                global_step = ckpt.model_checkpoint_path.split(&quot;/&quot;)[-1].split(&quot;-&quot;)[-1]\n                accuracy_score = sess.run(accuracy, feed_dict=validate_feed)\n                print(&quot;After %s training step(s), validation accuracy is %g&quot; % (global_step, accuracy_score))\n            else:\n                print(&quot;No checkpoint file found&quot;)\n                return\n        time.sleep(EVAL_INTERVAL_SECS)\n\n\ndef main(argv=None):\n    mnist = input_data.read_data_sets(&quot;../MNIST_data&quot;, one_hot=True)\n    evaluate(mnist)\n\n\nif __name__ == &apos;__main__&apos;:\n    tf.app.run()\n</code></pre><h1 id=\"参考文章\"><a href=\"#参考文章\" class=\"headerlink\" title=\"参考文章\"></a>参考文章</h1><p><a href=\"https://www.cnblogs.com/shihuc/p/6648130.html\" title=\"Tensorflow之基于MNIST手写识别的入门介绍\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/shihuc/p/6648130.html</a></p>"},{"title":"图像与常用算子进行卷积运算","date":"2018-03-19T11:11:57.000Z","_content":"> 图像卷积实验，使用guass、soble、prewitt、 laplacian算子进行图像增强。\n\n<!-- more -->\n\n# 实现代码 #\n\n    #!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2017/9/18 16:57\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : image_convolve.py\n\t# @ToDo    :  图像卷积\n\t\n\timport numpy as np\n\timport os\n\tfrom PIL import Image\n\t\n\t\n\tdef convolve(image, weight):\n\t\theight, width = image.shape\n\t\th, w = weight.shape\n\t\theight_new = height - h + 1\n\t\twidth_new = width - w + 1\n\t\tprint image.shape\n\t\timage_new = np.zeros((height_new, width_new), dtype=np.float)\n\t\tfor i in range(height_new):\n\t\t\tfor j in range(width_new):\n\t\t\t\timage_new[i, j] = np.sum(image[i:i + h, j:j + w] * weight)\n\t\timage_new = image_new.clip(0, 255)\n\t\timage_new = np.rint(image_new).astype(\"uint8\")\n\t\tprint image_new.shape\n\t\treturn image_new\n\t\n\t\n\t# image_new = 255 * (image_new - image_new.min()) / (image_new.max() - image_new.min())\n\t\n\tif __name__ == '__main__':\n\t\timage = Image.open(\"son.png\", \"r\")\n\t\toutput_path = \".\\\\ImageConvolve\\\\\"\n\t\tif not os.path.exists(output_path):\n\t\t\tos.mkdir(output_path)\n\t\ta = np.array(image)\n\t\tavg3 = np.ones((3, 3))\n\t\tavg3 /= avg3.sum()\n\t\tavg5 = np.ones((5, 5))\n\t\tavg5 /= avg5.sum()\n\t\n\t\tgauss = np.array(([0.003, 0.013, 0.022, 0.013, 0.003],\n\t\t\t\t\t\t  [0.013, 0.059, 0.097, 0.059, 0.013],\n\t\t\t\t\t\t  [0.022, 0.097, 0.159, 0.097, 0.022],\n\t\t\t\t\t\t  [0.013, 0.059, 0.097, 0.059, 0.013],\n\t\t\t\t\t\t  [0.003, 0.013, 0.022, 0.013, 0.003]))\n\t\n\t\tsoble_x = np.array(([-1, 0, 1], [-2, 0, 2], [-1, 0, 1]))\n\t\tsoble_y = np.array(([-1, -2, -1], [0, 0, 0], [1, 2, 1]))\n\t\tsoble = np.array(([-1, -1, 0], [-1, 0, 1], [0, 1, 1]))\n\t\n\t\tprewitt_x = np.array(([-1, 0, 1], [-1, 0, 1], [-1, 0, 1]))\n\t\tprewitt_y = np.array(([-1, -1, -1], [0, 0, 0], [1, 1, 1]))\n\t\tprewitt = np.array(([-2, -1, 0], [-1, 0, 1], [0, 1, 2]))\n\t\n\t\tlaplacian4 = np.array(([0, -1, 0], [-1, 4, -1], [0, -1, 0]))\n\t\tlaplacian8 = np.array(([-1, -1, -1], [-1, 8, -1], [-1, -1, -1]))\n\t\tweight_list = (\n\t\t\t'avg3', 'avg5', 'gauss', 'soble_x', 'soble_y', 'soble', 'prewitt_x', 'prewitt_y', 'prewitt', 'laplacian4',\n\t\t\t'laplacian8')\n\t\n\t\tprint \"梯度检测\"\n\t\tfor weight in weight_list:\n\t\t\tprint weight, \"R\",\n\t\t\tR = convolve(a[:, :, 0], eval(weight))\n\t\t\tprint \"G\",\n\t\t\tG = convolve(a[:, :, 1], eval(weight))\n\t\t\tprint \"B\"\n\t\t\tB = convolve(a[:, :, 2], eval(weight))\n\t\t\tI = np.stack((R, G, B), 2)\n\t\t# Image.fromarray(I).save(output_path + weight + \".png\")\n\n# 实验结果 #\n![图像卷积运算实验结果](https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/img-cov.png)","source":"_posts/图像与常用算子进行卷积运算.md","raw":"---\ntitle: 图像与常用算子进行卷积运算\ndate: 2018-03-19 19:11:57\ncategories:\n- 图像处理\n- 图像增强\ntags:\n- 图像处理 \n- 卷积运算 \n- guass \n- soble \n- prewitt \n- laplacian\n---\n> 图像卷积实验，使用guass、soble、prewitt、 laplacian算子进行图像增强。\n\n<!-- more -->\n\n# 实现代码 #\n\n    #!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2017/9/18 16:57\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : image_convolve.py\n\t# @ToDo    :  图像卷积\n\t\n\timport numpy as np\n\timport os\n\tfrom PIL import Image\n\t\n\t\n\tdef convolve(image, weight):\n\t\theight, width = image.shape\n\t\th, w = weight.shape\n\t\theight_new = height - h + 1\n\t\twidth_new = width - w + 1\n\t\tprint image.shape\n\t\timage_new = np.zeros((height_new, width_new), dtype=np.float)\n\t\tfor i in range(height_new):\n\t\t\tfor j in range(width_new):\n\t\t\t\timage_new[i, j] = np.sum(image[i:i + h, j:j + w] * weight)\n\t\timage_new = image_new.clip(0, 255)\n\t\timage_new = np.rint(image_new).astype(\"uint8\")\n\t\tprint image_new.shape\n\t\treturn image_new\n\t\n\t\n\t# image_new = 255 * (image_new - image_new.min()) / (image_new.max() - image_new.min())\n\t\n\tif __name__ == '__main__':\n\t\timage = Image.open(\"son.png\", \"r\")\n\t\toutput_path = \".\\\\ImageConvolve\\\\\"\n\t\tif not os.path.exists(output_path):\n\t\t\tos.mkdir(output_path)\n\t\ta = np.array(image)\n\t\tavg3 = np.ones((3, 3))\n\t\tavg3 /= avg3.sum()\n\t\tavg5 = np.ones((5, 5))\n\t\tavg5 /= avg5.sum()\n\t\n\t\tgauss = np.array(([0.003, 0.013, 0.022, 0.013, 0.003],\n\t\t\t\t\t\t  [0.013, 0.059, 0.097, 0.059, 0.013],\n\t\t\t\t\t\t  [0.022, 0.097, 0.159, 0.097, 0.022],\n\t\t\t\t\t\t  [0.013, 0.059, 0.097, 0.059, 0.013],\n\t\t\t\t\t\t  [0.003, 0.013, 0.022, 0.013, 0.003]))\n\t\n\t\tsoble_x = np.array(([-1, 0, 1], [-2, 0, 2], [-1, 0, 1]))\n\t\tsoble_y = np.array(([-1, -2, -1], [0, 0, 0], [1, 2, 1]))\n\t\tsoble = np.array(([-1, -1, 0], [-1, 0, 1], [0, 1, 1]))\n\t\n\t\tprewitt_x = np.array(([-1, 0, 1], [-1, 0, 1], [-1, 0, 1]))\n\t\tprewitt_y = np.array(([-1, -1, -1], [0, 0, 0], [1, 1, 1]))\n\t\tprewitt = np.array(([-2, -1, 0], [-1, 0, 1], [0, 1, 2]))\n\t\n\t\tlaplacian4 = np.array(([0, -1, 0], [-1, 4, -1], [0, -1, 0]))\n\t\tlaplacian8 = np.array(([-1, -1, -1], [-1, 8, -1], [-1, -1, -1]))\n\t\tweight_list = (\n\t\t\t'avg3', 'avg5', 'gauss', 'soble_x', 'soble_y', 'soble', 'prewitt_x', 'prewitt_y', 'prewitt', 'laplacian4',\n\t\t\t'laplacian8')\n\t\n\t\tprint \"梯度检测\"\n\t\tfor weight in weight_list:\n\t\t\tprint weight, \"R\",\n\t\t\tR = convolve(a[:, :, 0], eval(weight))\n\t\t\tprint \"G\",\n\t\t\tG = convolve(a[:, :, 1], eval(weight))\n\t\t\tprint \"B\"\n\t\t\tB = convolve(a[:, :, 2], eval(weight))\n\t\t\tI = np.stack((R, G, B), 2)\n\t\t# Image.fromarray(I).save(output_path + weight + \".png\")\n\n# 实验结果 #\n![图像卷积运算实验结果](https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/img-cov.png)","slug":"图像与常用算子进行卷积运算","published":1,"updated":"2018-03-20T12:36:03.965Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjezqafi90002f4ht0gv5hiu3","content":"<blockquote>\n<p>图像卷积实验，使用guass、soble、prewitt、 laplacian算子进行图像增强。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h1 id=\"实现代码\"><a href=\"#实现代码\" class=\"headerlink\" title=\"实现代码\"></a>实现代码</h1><pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2017/9/18 16:57\n# @Author  : Jasontang\n# @Site    : \n# @File    : image_convolve.py\n# @ToDo    :  图像卷积\n\nimport numpy as np\nimport os\nfrom PIL import Image\n\n\ndef convolve(image, weight):\n    height, width = image.shape\n    h, w = weight.shape\n    height_new = height - h + 1\n    width_new = width - w + 1\n    print image.shape\n    image_new = np.zeros((height_new, width_new), dtype=np.float)\n    for i in range(height_new):\n        for j in range(width_new):\n            image_new[i, j] = np.sum(image[i:i + h, j:j + w] * weight)\n    image_new = image_new.clip(0, 255)\n    image_new = np.rint(image_new).astype(&quot;uint8&quot;)\n    print image_new.shape\n    return image_new\n\n\n# image_new = 255 * (image_new - image_new.min()) / (image_new.max() - image_new.min())\n\nif __name__ == &apos;__main__&apos;:\n    image = Image.open(&quot;son.png&quot;, &quot;r&quot;)\n    output_path = &quot;.\\\\ImageConvolve\\\\&quot;\n    if not os.path.exists(output_path):\n        os.mkdir(output_path)\n    a = np.array(image)\n    avg3 = np.ones((3, 3))\n    avg3 /= avg3.sum()\n    avg5 = np.ones((5, 5))\n    avg5 /= avg5.sum()\n\n    gauss = np.array(([0.003, 0.013, 0.022, 0.013, 0.003],\n                      [0.013, 0.059, 0.097, 0.059, 0.013],\n                      [0.022, 0.097, 0.159, 0.097, 0.022],\n                      [0.013, 0.059, 0.097, 0.059, 0.013],\n                      [0.003, 0.013, 0.022, 0.013, 0.003]))\n\n    soble_x = np.array(([-1, 0, 1], [-2, 0, 2], [-1, 0, 1]))\n    soble_y = np.array(([-1, -2, -1], [0, 0, 0], [1, 2, 1]))\n    soble = np.array(([-1, -1, 0], [-1, 0, 1], [0, 1, 1]))\n\n    prewitt_x = np.array(([-1, 0, 1], [-1, 0, 1], [-1, 0, 1]))\n    prewitt_y = np.array(([-1, -1, -1], [0, 0, 0], [1, 1, 1]))\n    prewitt = np.array(([-2, -1, 0], [-1, 0, 1], [0, 1, 2]))\n\n    laplacian4 = np.array(([0, -1, 0], [-1, 4, -1], [0, -1, 0]))\n    laplacian8 = np.array(([-1, -1, -1], [-1, 8, -1], [-1, -1, -1]))\n    weight_list = (\n        &apos;avg3&apos;, &apos;avg5&apos;, &apos;gauss&apos;, &apos;soble_x&apos;, &apos;soble_y&apos;, &apos;soble&apos;, &apos;prewitt_x&apos;, &apos;prewitt_y&apos;, &apos;prewitt&apos;, &apos;laplacian4&apos;,\n        &apos;laplacian8&apos;)\n\n    print &quot;梯度检测&quot;\n    for weight in weight_list:\n        print weight, &quot;R&quot;,\n        R = convolve(a[:, :, 0], eval(weight))\n        print &quot;G&quot;,\n        G = convolve(a[:, :, 1], eval(weight))\n        print &quot;B&quot;\n        B = convolve(a[:, :, 2], eval(weight))\n        I = np.stack((R, G, B), 2)\n    # Image.fromarray(I).save(output_path + weight + &quot;.png&quot;)\n</code></pre><h1 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h1><p><img src=\"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/img-cov.png\" alt=\"图像卷积运算实验结果\"></p>\n","site":{"data":{"about":{"avatar":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/avatar.jpg","name":"tech.radish","tag":"python/Java/ML/CV","desc":"行走在边缘的coder","skills":{"ptyhon":5,"Java":6,"invisible-split-line-1":-1,"ML":4},"projects":[{"name":"合金战争(Java Swing + MySql + Socket)","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/game.png","tags":["Java","游戏开发"],"description":"合金战争是一款使用JavaSwing作为界面，MySQL作为数据库服务器，使用Socket通信的网络版RPG游戏","link_text":"合金战争","link":null},{"name":"iclass智能课堂助手","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/iclass.png","description":"iclass是一款实用SSM框架开发的轻量级课堂辅助教学系统，旨在加强和方便师生之间的交流合作，提高教学效率。拥有web端和安卓端（本人完成web端和安卓后端的开发）","tags":["毕业设计","SSM框架"],"link_text":"Github地址","link":"https://github.com/Mic-JasonTang/iclass"}],"reward":["https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/alipay-rewardcode.jpg","https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/wetchat-rewardcode.jpg"]},"link":{"social":{"github":"https://github.com/mic-jasontang"},"extern":{"Github地址":"https://github.com/mic-jasontang"}},"slider":[{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/coloreggs.jpg","align":"center","title":"computer vision","subtitle":"whole world","link":"/"},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/fantasy.jpg","align":"left","title":"import tensorflow as tf","subtitle":"sess.run(hello)","link":null},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/pythoner.png","align":"right","title":"import __helloworld__","subtitle":">>> Hello World","link":null}],"hint":{"new":{"selector":[".menu-reading"]}},"reading":{"define":{"readed":"已读","reading":"在读","wanted":"想读"},"contents":{"readed":[{"title":"嫌疑人X的献身","cover":"https://img3.doubanio.com/lpic/s3254244.jpg","review":"百年一遇的数学天才石神，每天唯一的乐趣，便是去固定的便当店买午餐，只为看一眼在便当店做事的邻居靖子。","score":"8.9","doubanLink":"https://book.douban.com/subject/3211779/"},{"title":"Python核心编程（第二版）","cover":"https://img3.doubanio.com/lpic/s3140466.jpg","review":"本书是Python开发者的完全指南——针对 Python 2.5全面升级","score":"7.7","doubanLink":"https://book.douban.com/subject/3112503/"},{"title":"程序员代码面试指南：IT名企算法与数据结构题目最优解","cover":"https://img3.doubanio.com/lpic/s28313721.jpg","review":"这是一本程序员面试宝典！书中对IT名企代码面试各类题目的最优解进行了总结，并提供了相关代码实现。","score":"8.8","doubanLink":"https://book.douban.com/subject/26638586/"},{"title":"机器学习实战","cover":"https://img3.doubanio.com/lpic/s26696371.jpg","review":"全书通过精心编排的实例，切入日常工作任务，摒弃学术化语言，利用高效的可复用Python代码来阐释如何处理统计数据，进行数据分析及可视化。通过各种实例，读者可从中学会机器学习的核心算法，并能将其运用于一些策略性任务中，如分类、预测、推荐。另外，还可用它们来实现一些更高级的功能，如汇总和简化等。","score":"8.2","doubanLink":"https://book.douban.com/subject/24703171/"},{"title":"TensorFlow实战","cover":"https://img3.doubanio.com/lpic/s29343414.jpg","review":"《TensorFlow实战》希望能帮读者快速入门TensorFlow和深度学习，在工业界或者研究中快速地将想法落地为可实践的模型。","score":"7.3","doubanLink":"https://book.douban.com/subject/26974266/"}],"reading":[{"title":"深度学习","cover":"https://img1.doubanio.com/lpic/s29518349.jpg","review":"《深度学习》适合各类读者阅读，包括相关专业的大学生或研究生，以及不具有机器学习或统计背景、但是想要快速补充深度学习知识，以便在实际产品或平台中应用的软件工程师。","score":"8.7","doubanLink":"https://book.douban.com/subject/27087503/"},{"title":"Tensorflow：实战Google深度学习框架","cover":"https://img3.doubanio.com/lpic/s29349250.jpg","review":"《Tensorflow实战》包含了深度学习的入门知识和大量实践经验，是走进这个最新、最火的人工智能领域的首选参考书。","score":"8.2","doubanLink":"https://book.douban.com/subject/26976457/"},{"title":"机器学习","cover":"https://img1.doubanio.com/lpic/s28735609.jpg","review":"本书作为该领域的入门教材，在内容上尽可能涵盖机器学习基础知识的各方面。 为了使尽可能多的读者通过本书对机器学习有所了解, 作者试图尽可能少地使用数学知识. 然而, 少量的概率、统计、代数、优化、逻辑知识似乎不可避免. 因此, 本书更适合大学三年级以上的理工科本科生和研究生, 以及具有类似背景的对机器学 习感兴趣的人士. 为方便读者, 本书附录给出了一些相关数学基础知识简介.","score":"8.7","doubanLink":"https://book.douban.com/subject/26708119/"}],"wanted":[{"title":"OpenCV 3计算机视觉：Python语言实现（原书第2版）","cover":"https://img3.doubanio.com/lpic/s28902360.jpg","review":"本书针对具有一定Python工作经验的程序员以及想要利用OpenCV库研究计算机视觉课题的读者。本书不要求读者具有计算机视觉或OpenCV经验，但要具有编程经验。","score":"7.8","doubanLink":"https://book.douban.com/subject/26816975/"},{"title":"Python计算机视觉编程","cover":"https://img3.doubanio.com/lpic/s27305520.jpg","review":"《python计算机视觉编程》适合的读者是：有一定编程与数学基础，想要了解计算机视觉的基本理论与算法的学生，以及计算机科学、信号处理、物理学、应用数学和统计学、神经生理学、认知科学等领域的研究人员和从业者。","score":"7.5","doubanLink":"https://book.douban.com/subject/25906843/"}]}}}},"excerpt":"<blockquote>\n<p>图像卷积实验，使用guass、soble、prewitt、 laplacian算子进行图像增强。</p>\n</blockquote>","more":"<h1 id=\"实现代码\"><a href=\"#实现代码\" class=\"headerlink\" title=\"实现代码\"></a>实现代码</h1><pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2017/9/18 16:57\n# @Author  : Jasontang\n# @Site    : \n# @File    : image_convolve.py\n# @ToDo    :  图像卷积\n\nimport numpy as np\nimport os\nfrom PIL import Image\n\n\ndef convolve(image, weight):\n    height, width = image.shape\n    h, w = weight.shape\n    height_new = height - h + 1\n    width_new = width - w + 1\n    print image.shape\n    image_new = np.zeros((height_new, width_new), dtype=np.float)\n    for i in range(height_new):\n        for j in range(width_new):\n            image_new[i, j] = np.sum(image[i:i + h, j:j + w] * weight)\n    image_new = image_new.clip(0, 255)\n    image_new = np.rint(image_new).astype(&quot;uint8&quot;)\n    print image_new.shape\n    return image_new\n\n\n# image_new = 255 * (image_new - image_new.min()) / (image_new.max() - image_new.min())\n\nif __name__ == &apos;__main__&apos;:\n    image = Image.open(&quot;son.png&quot;, &quot;r&quot;)\n    output_path = &quot;.\\\\ImageConvolve\\\\&quot;\n    if not os.path.exists(output_path):\n        os.mkdir(output_path)\n    a = np.array(image)\n    avg3 = np.ones((3, 3))\n    avg3 /= avg3.sum()\n    avg5 = np.ones((5, 5))\n    avg5 /= avg5.sum()\n\n    gauss = np.array(([0.003, 0.013, 0.022, 0.013, 0.003],\n                      [0.013, 0.059, 0.097, 0.059, 0.013],\n                      [0.022, 0.097, 0.159, 0.097, 0.022],\n                      [0.013, 0.059, 0.097, 0.059, 0.013],\n                      [0.003, 0.013, 0.022, 0.013, 0.003]))\n\n    soble_x = np.array(([-1, 0, 1], [-2, 0, 2], [-1, 0, 1]))\n    soble_y = np.array(([-1, -2, -1], [0, 0, 0], [1, 2, 1]))\n    soble = np.array(([-1, -1, 0], [-1, 0, 1], [0, 1, 1]))\n\n    prewitt_x = np.array(([-1, 0, 1], [-1, 0, 1], [-1, 0, 1]))\n    prewitt_y = np.array(([-1, -1, -1], [0, 0, 0], [1, 1, 1]))\n    prewitt = np.array(([-2, -1, 0], [-1, 0, 1], [0, 1, 2]))\n\n    laplacian4 = np.array(([0, -1, 0], [-1, 4, -1], [0, -1, 0]))\n    laplacian8 = np.array(([-1, -1, -1], [-1, 8, -1], [-1, -1, -1]))\n    weight_list = (\n        &apos;avg3&apos;, &apos;avg5&apos;, &apos;gauss&apos;, &apos;soble_x&apos;, &apos;soble_y&apos;, &apos;soble&apos;, &apos;prewitt_x&apos;, &apos;prewitt_y&apos;, &apos;prewitt&apos;, &apos;laplacian4&apos;,\n        &apos;laplacian8&apos;)\n\n    print &quot;梯度检测&quot;\n    for weight in weight_list:\n        print weight, &quot;R&quot;,\n        R = convolve(a[:, :, 0], eval(weight))\n        print &quot;G&quot;,\n        G = convolve(a[:, :, 1], eval(weight))\n        print &quot;B&quot;\n        B = convolve(a[:, :, 2], eval(weight))\n        I = np.stack((R, G, B), 2)\n    # Image.fromarray(I).save(output_path + weight + &quot;.png&quot;)\n</code></pre><h1 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h1><p><img src=\"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/img-cov.png\" alt=\"图像卷积运算实验结果\"></p>"},{"title":"直方图均衡化图片","date":"2018-03-20T10:31:55.000Z","_content":"\n# 直方图均衡化 #\n\n\n- 1.实验原理\n> 用直方图变换方法进行图像增强，通过改变图像的直方图来概念图像中像素的灰度，以达到图像增强的目的。\n \n\n\n\n\n- 2.实验步骤\n>\t1、对图像进行灰度统计，求灰度统计直方图。\n>\t\n>\t2、对灰度统计直方图进行归一化。\n>\t\n>\t3、求累积分布函数，求累积分布直方图。\n>\t\n>\t4、对累积直方图各项进行取整扩展tk=int[(L-1)tk + 0.5].\n>\t\n>\t5、确定映射对应关系，根据映射关系计算均衡化直方图。\n\n<!-- more -->\n\n- 3.代码\n\n\n> 代码采用python2.0实现   \n\n\t#!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2017/10/15 18:49\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : histequa.py\n\t# @ToDo    : 直方图均衡化(8bit)\n\t\n\t\n\tfrom PIL import Image\n\timport matplotlib as mpl\n\timport matplotlib.pyplot as plt\n\timport numpy as np\n\t\n\tmpl.rcParams['font.sans-serif'] = \"SimHei\"\n\tmpl.rcParams['axes.unicode_minus'] = False\n\t\n\t\n\tdef image2vector():\n\t    return np.array(Image.open(\"images/lena512.bmp\", \"r\").convert(\"L\"))\n\t\n\t\n\tdef equalization(data):\n\t    # 得到图像的高度、宽度\n\t    h = data.shape[0]\n\t    w = data.shape[1]\n\t    # 灰度数组\n\t    grayArr = np.zeros(255)\n\t    # 进行像素灰度统计\n\t    for i in range(h):\n\t        for j in range(w):\n\t            grayArr[data[i][j]] += 1\n\t    print grayArr.shape, grayArr.max()\n\t    # 归一化\n\t    idx = 0\n\t    for item in grayArr:\n\t        grayArr[idx] = item / (h * w)\n\t        idx += 1\n\t    # print grayArr\n\t    cdf = np.zeros(grayArr.shape)\n\t    sum = 0\n\t    # 计算灰度分布密度\n\t    # print cdf.shape\n\t    for i in range(len(grayArr)):\n\t        sum += grayArr[i]\n\t        cdf[i] = sum\n\t    L = 255\n\t    # print cdf\n\t    # 累计分布取整\n\t    indexArr = ((L - 1) * cdf + 0.5).astype(np.uint8)\n\t    # print indexArr\n\t    # 对灰度值进行映射（均衡化）\n\t    for i in range(h):\n\t        for j in range(w):\n\t            data[i, j] = indexArr[data[i, j]]\n\t    return grayArr, cdf, data\n\t\n\t\n\tif __name__ == '__main__':\n\t    data = image2vector()\n\t    # print data.shape\n\t    plt.figure(figsize=(7, 9))\n\t    plt.subplot(321)\n\t    plt.title(u\"原始图像\")\n\t    plt.imshow(data, cmap='gray')\n\t    plt.subplot(322)\n\t    plt.title(u\"原始灰度\")\n\t    plt.hist(data.flatten(), normed=True, bins=256)\n\t    srcGray, cdf, equlArr = equalization(data)\n\t    plt.subplot(323)\n\t    plt.title(u\"归一化直方图\")\n\t    plt.hist(srcGray, 255)\n\t    plt.subplot(324)\n\t    plt.title(u\"累积直方图\")\n\t    plt.hist(cdf, 255)\n\t    plt.subplot(325)\n\t    plt.title(u\"均衡化图像\")\n\t    plt.imshow(equlArr, cmap='gray')\n\t    plt.subplot(326)\n\t    plt.title(u\"均衡化的直方图\")\n\t    plt.hist(equlArr.flatten(), normed=True, bins=256)\n\t    # print equlArr\n\t    plt.tight_layout(0.3, rect=(0, 0, 1, 0.92))\n\t    plt.show()\n\n- 4.实验结果\n![实验结果](https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/histequa.png)\n\n\n- 5.实验总结\n> 在对数据进行归一化的时候，是用每个灰度值除以像素总数。在最后通过映射关系计算均衡化直方图时，是借助求出的映射关系，直接对原图的像素点进行映射。通过均衡化能增强图像的动态范围偏小的图像的反差，达到增强图像整体对比度的效果。\n","source":"_posts/直方图均衡化图片.md","raw":"---\ntitle: 直方图均衡化图片\ndate: 2018-03-20 18:31:55\ncategories:\n- 图像处理\n- 图像增强\ntags: \n- python \n- 图像处理 \n- 直方图均衡化\n---\n\n# 直方图均衡化 #\n\n\n- 1.实验原理\n> 用直方图变换方法进行图像增强，通过改变图像的直方图来概念图像中像素的灰度，以达到图像增强的目的。\n \n\n\n\n\n- 2.实验步骤\n>\t1、对图像进行灰度统计，求灰度统计直方图。\n>\t\n>\t2、对灰度统计直方图进行归一化。\n>\t\n>\t3、求累积分布函数，求累积分布直方图。\n>\t\n>\t4、对累积直方图各项进行取整扩展tk=int[(L-1)tk + 0.5].\n>\t\n>\t5、确定映射对应关系，根据映射关系计算均衡化直方图。\n\n<!-- more -->\n\n- 3.代码\n\n\n> 代码采用python2.0实现   \n\n\t#!/usr/bin/env python\n\t# -*- coding: utf-8 -*-\n\t# @Time    : 2017/10/15 18:49\n\t# @Author  : Jasontang\n\t# @Site    : \n\t# @File    : histequa.py\n\t# @ToDo    : 直方图均衡化(8bit)\n\t\n\t\n\tfrom PIL import Image\n\timport matplotlib as mpl\n\timport matplotlib.pyplot as plt\n\timport numpy as np\n\t\n\tmpl.rcParams['font.sans-serif'] = \"SimHei\"\n\tmpl.rcParams['axes.unicode_minus'] = False\n\t\n\t\n\tdef image2vector():\n\t    return np.array(Image.open(\"images/lena512.bmp\", \"r\").convert(\"L\"))\n\t\n\t\n\tdef equalization(data):\n\t    # 得到图像的高度、宽度\n\t    h = data.shape[0]\n\t    w = data.shape[1]\n\t    # 灰度数组\n\t    grayArr = np.zeros(255)\n\t    # 进行像素灰度统计\n\t    for i in range(h):\n\t        for j in range(w):\n\t            grayArr[data[i][j]] += 1\n\t    print grayArr.shape, grayArr.max()\n\t    # 归一化\n\t    idx = 0\n\t    for item in grayArr:\n\t        grayArr[idx] = item / (h * w)\n\t        idx += 1\n\t    # print grayArr\n\t    cdf = np.zeros(grayArr.shape)\n\t    sum = 0\n\t    # 计算灰度分布密度\n\t    # print cdf.shape\n\t    for i in range(len(grayArr)):\n\t        sum += grayArr[i]\n\t        cdf[i] = sum\n\t    L = 255\n\t    # print cdf\n\t    # 累计分布取整\n\t    indexArr = ((L - 1) * cdf + 0.5).astype(np.uint8)\n\t    # print indexArr\n\t    # 对灰度值进行映射（均衡化）\n\t    for i in range(h):\n\t        for j in range(w):\n\t            data[i, j] = indexArr[data[i, j]]\n\t    return grayArr, cdf, data\n\t\n\t\n\tif __name__ == '__main__':\n\t    data = image2vector()\n\t    # print data.shape\n\t    plt.figure(figsize=(7, 9))\n\t    plt.subplot(321)\n\t    plt.title(u\"原始图像\")\n\t    plt.imshow(data, cmap='gray')\n\t    plt.subplot(322)\n\t    plt.title(u\"原始灰度\")\n\t    plt.hist(data.flatten(), normed=True, bins=256)\n\t    srcGray, cdf, equlArr = equalization(data)\n\t    plt.subplot(323)\n\t    plt.title(u\"归一化直方图\")\n\t    plt.hist(srcGray, 255)\n\t    plt.subplot(324)\n\t    plt.title(u\"累积直方图\")\n\t    plt.hist(cdf, 255)\n\t    plt.subplot(325)\n\t    plt.title(u\"均衡化图像\")\n\t    plt.imshow(equlArr, cmap='gray')\n\t    plt.subplot(326)\n\t    plt.title(u\"均衡化的直方图\")\n\t    plt.hist(equlArr.flatten(), normed=True, bins=256)\n\t    # print equlArr\n\t    plt.tight_layout(0.3, rect=(0, 0, 1, 0.92))\n\t    plt.show()\n\n- 4.实验结果\n![实验结果](https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/histequa.png)\n\n\n- 5.实验总结\n> 在对数据进行归一化的时候，是用每个灰度值除以像素总数。在最后通过映射关系计算均衡化直方图时，是借助求出的映射关系，直接对原图的像素点进行映射。通过均衡化能增强图像的动态范围偏小的图像的反差，达到增强图像整体对比度的效果。\n","slug":"直方图均衡化图片","published":1,"updated":"2018-03-20T12:34:57.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjezqafig0006f4hticilr7fq","content":"<h1 id=\"直方图均衡化\"><a href=\"#直方图均衡化\" class=\"headerlink\" title=\"直方图均衡化\"></a>直方图均衡化</h1><ul>\n<li>1.实验原理<blockquote>\n<p>用直方图变换方法进行图像增强，通过改变图像的直方图来概念图像中像素的灰度，以达到图像增强的目的。</p>\n</blockquote>\n</li>\n</ul>\n<ul>\n<li>2.实验步骤<blockquote>\n<p>   1、对图像进行灰度统计，求灰度统计直方图。</p>\n<p>   2、对灰度统计直方图进行归一化。</p>\n<p>   3、求累积分布函数，求累积分布直方图。</p>\n<p>   4、对累积直方图各项进行取整扩展tk=int[(L-1)tk + 0.5].</p>\n<p>   5、确定映射对应关系，根据映射关系计算均衡化直方图。</p>\n</blockquote>\n</li>\n</ul>\n<a id=\"more\"></a>\n<ul>\n<li>3.代码</li>\n</ul>\n<blockquote>\n<p>代码采用python2.0实现   </p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2017/10/15 18:49\n# @Author  : Jasontang\n# @Site    : \n# @File    : histequa.py\n# @ToDo    : 直方图均衡化(8bit)\n\n\nfrom PIL import Image\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nmpl.rcParams[&apos;font.sans-serif&apos;] = &quot;SimHei&quot;\nmpl.rcParams[&apos;axes.unicode_minus&apos;] = False\n\n\ndef image2vector():\n    return np.array(Image.open(&quot;images/lena512.bmp&quot;, &quot;r&quot;).convert(&quot;L&quot;))\n\n\ndef equalization(data):\n    # 得到图像的高度、宽度\n    h = data.shape[0]\n    w = data.shape[1]\n    # 灰度数组\n    grayArr = np.zeros(255)\n    # 进行像素灰度统计\n    for i in range(h):\n        for j in range(w):\n            grayArr[data[i][j]] += 1\n    print grayArr.shape, grayArr.max()\n    # 归一化\n    idx = 0\n    for item in grayArr:\n        grayArr[idx] = item / (h * w)\n        idx += 1\n    # print grayArr\n    cdf = np.zeros(grayArr.shape)\n    sum = 0\n    # 计算灰度分布密度\n    # print cdf.shape\n    for i in range(len(grayArr)):\n        sum += grayArr[i]\n        cdf[i] = sum\n    L = 255\n    # print cdf\n    # 累计分布取整\n    indexArr = ((L - 1) * cdf + 0.5).astype(np.uint8)\n    # print indexArr\n    # 对灰度值进行映射（均衡化）\n    for i in range(h):\n        for j in range(w):\n            data[i, j] = indexArr[data[i, j]]\n    return grayArr, cdf, data\n\n\nif __name__ == &apos;__main__&apos;:\n    data = image2vector()\n    # print data.shape\n    plt.figure(figsize=(7, 9))\n    plt.subplot(321)\n    plt.title(u&quot;原始图像&quot;)\n    plt.imshow(data, cmap=&apos;gray&apos;)\n    plt.subplot(322)\n    plt.title(u&quot;原始灰度&quot;)\n    plt.hist(data.flatten(), normed=True, bins=256)\n    srcGray, cdf, equlArr = equalization(data)\n    plt.subplot(323)\n    plt.title(u&quot;归一化直方图&quot;)\n    plt.hist(srcGray, 255)\n    plt.subplot(324)\n    plt.title(u&quot;累积直方图&quot;)\n    plt.hist(cdf, 255)\n    plt.subplot(325)\n    plt.title(u&quot;均衡化图像&quot;)\n    plt.imshow(equlArr, cmap=&apos;gray&apos;)\n    plt.subplot(326)\n    plt.title(u&quot;均衡化的直方图&quot;)\n    plt.hist(equlArr.flatten(), normed=True, bins=256)\n    # print equlArr\n    plt.tight_layout(0.3, rect=(0, 0, 1, 0.92))\n    plt.show()\n</code></pre><ul>\n<li>4.实验结果<br><img src=\"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/histequa.png\" alt=\"实验结果\"></li>\n</ul>\n<ul>\n<li>5.实验总结<blockquote>\n<p>在对数据进行归一化的时候，是用每个灰度值除以像素总数。在最后通过映射关系计算均衡化直方图时，是借助求出的映射关系，直接对原图的像素点进行映射。通过均衡化能增强图像的动态范围偏小的图像的反差，达到增强图像整体对比度的效果。</p>\n</blockquote>\n</li>\n</ul>\n","site":{"data":{"about":{"avatar":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/avatar.jpg","name":"tech.radish","tag":"python/Java/ML/CV","desc":"行走在边缘的coder","skills":{"ptyhon":5,"Java":6,"invisible-split-line-1":-1,"ML":4},"projects":[{"name":"合金战争(Java Swing + MySql + Socket)","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/game.png","tags":["Java","游戏开发"],"description":"合金战争是一款使用JavaSwing作为界面，MySQL作为数据库服务器，使用Socket通信的网络版RPG游戏","link_text":"合金战争","link":null},{"name":"iclass智能课堂助手","image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/iclass.png","description":"iclass是一款实用SSM框架开发的轻量级课堂辅助教学系统，旨在加强和方便师生之间的交流合作，提高教学效率。拥有web端和安卓端（本人完成web端和安卓后端的开发）","tags":["毕业设计","SSM框架"],"link_text":"Github地址","link":"https://github.com/Mic-JasonTang/iclass"}],"reward":["https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/alipay-rewardcode.jpg","https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/wetchat-rewardcode.jpg"]},"link":{"social":{"github":"https://github.com/mic-jasontang"},"extern":{"Github地址":"https://github.com/mic-jasontang"}},"slider":[{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/coloreggs.jpg","align":"center","title":"computer vision","subtitle":"whole world","link":"/"},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/fantasy.jpg","align":"left","title":"import tensorflow as tf","subtitle":"sess.run(hello)","link":null},{"image":"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/pythoner.png","align":"right","title":"import __helloworld__","subtitle":">>> Hello World","link":null}],"hint":{"new":{"selector":[".menu-reading"]}},"reading":{"define":{"readed":"已读","reading":"在读","wanted":"想读"},"contents":{"readed":[{"title":"嫌疑人X的献身","cover":"https://img3.doubanio.com/lpic/s3254244.jpg","review":"百年一遇的数学天才石神，每天唯一的乐趣，便是去固定的便当店买午餐，只为看一眼在便当店做事的邻居靖子。","score":"8.9","doubanLink":"https://book.douban.com/subject/3211779/"},{"title":"Python核心编程（第二版）","cover":"https://img3.doubanio.com/lpic/s3140466.jpg","review":"本书是Python开发者的完全指南——针对 Python 2.5全面升级","score":"7.7","doubanLink":"https://book.douban.com/subject/3112503/"},{"title":"程序员代码面试指南：IT名企算法与数据结构题目最优解","cover":"https://img3.doubanio.com/lpic/s28313721.jpg","review":"这是一本程序员面试宝典！书中对IT名企代码面试各类题目的最优解进行了总结，并提供了相关代码实现。","score":"8.8","doubanLink":"https://book.douban.com/subject/26638586/"},{"title":"机器学习实战","cover":"https://img3.doubanio.com/lpic/s26696371.jpg","review":"全书通过精心编排的实例，切入日常工作任务，摒弃学术化语言，利用高效的可复用Python代码来阐释如何处理统计数据，进行数据分析及可视化。通过各种实例，读者可从中学会机器学习的核心算法，并能将其运用于一些策略性任务中，如分类、预测、推荐。另外，还可用它们来实现一些更高级的功能，如汇总和简化等。","score":"8.2","doubanLink":"https://book.douban.com/subject/24703171/"},{"title":"TensorFlow实战","cover":"https://img3.doubanio.com/lpic/s29343414.jpg","review":"《TensorFlow实战》希望能帮读者快速入门TensorFlow和深度学习，在工业界或者研究中快速地将想法落地为可实践的模型。","score":"7.3","doubanLink":"https://book.douban.com/subject/26974266/"}],"reading":[{"title":"深度学习","cover":"https://img1.doubanio.com/lpic/s29518349.jpg","review":"《深度学习》适合各类读者阅读，包括相关专业的大学生或研究生，以及不具有机器学习或统计背景、但是想要快速补充深度学习知识，以便在实际产品或平台中应用的软件工程师。","score":"8.7","doubanLink":"https://book.douban.com/subject/27087503/"},{"title":"Tensorflow：实战Google深度学习框架","cover":"https://img3.doubanio.com/lpic/s29349250.jpg","review":"《Tensorflow实战》包含了深度学习的入门知识和大量实践经验，是走进这个最新、最火的人工智能领域的首选参考书。","score":"8.2","doubanLink":"https://book.douban.com/subject/26976457/"},{"title":"机器学习","cover":"https://img1.doubanio.com/lpic/s28735609.jpg","review":"本书作为该领域的入门教材，在内容上尽可能涵盖机器学习基础知识的各方面。 为了使尽可能多的读者通过本书对机器学习有所了解, 作者试图尽可能少地使用数学知识. 然而, 少量的概率、统计、代数、优化、逻辑知识似乎不可避免. 因此, 本书更适合大学三年级以上的理工科本科生和研究生, 以及具有类似背景的对机器学 习感兴趣的人士. 为方便读者, 本书附录给出了一些相关数学基础知识简介.","score":"8.7","doubanLink":"https://book.douban.com/subject/26708119/"}],"wanted":[{"title":"OpenCV 3计算机视觉：Python语言实现（原书第2版）","cover":"https://img3.doubanio.com/lpic/s28902360.jpg","review":"本书针对具有一定Python工作经验的程序员以及想要利用OpenCV库研究计算机视觉课题的读者。本书不要求读者具有计算机视觉或OpenCV经验，但要具有编程经验。","score":"7.8","doubanLink":"https://book.douban.com/subject/26816975/"},{"title":"Python计算机视觉编程","cover":"https://img3.doubanio.com/lpic/s27305520.jpg","review":"《python计算机视觉编程》适合的读者是：有一定编程与数学基础，想要了解计算机视觉的基本理论与算法的学生，以及计算机科学、信号处理、物理学、应用数学和统计学、神经生理学、认知科学等领域的研究人员和从业者。","score":"7.5","doubanLink":"https://book.douban.com/subject/25906843/"}]}}}},"excerpt":"<h1 id=\"直方图均衡化\"><a href=\"#直方图均衡化\" class=\"headerlink\" title=\"直方图均衡化\"></a>直方图均衡化</h1><ul>\n<li>1.实验原理<blockquote>\n<p>用直方图变换方法进行图像增强，通过改变图像的直方图来概念图像中像素的灰度，以达到图像增强的目的。</p>\n</blockquote>\n</li>\n</ul>\n<ul>\n<li>2.实验步骤<blockquote>\n<p>   1、对图像进行灰度统计，求灰度统计直方图。</p>\n<p>   2、对灰度统计直方图进行归一化。</p>\n<p>   3、求累积分布函数，求累积分布直方图。</p>\n<p>   4、对累积直方图各项进行取整扩展tk=int[(L-1)tk + 0.5].</p>\n<p>   5、确定映射对应关系，根据映射关系计算均衡化直方图。</p>\n</blockquote>\n</li>\n</ul>","more":"<ul>\n<li>3.代码</li>\n</ul>\n<blockquote>\n<p>代码采用python2.0实现   </p>\n</blockquote>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# @Time    : 2017/10/15 18:49\n# @Author  : Jasontang\n# @Site    : \n# @File    : histequa.py\n# @ToDo    : 直方图均衡化(8bit)\n\n\nfrom PIL import Image\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nmpl.rcParams[&apos;font.sans-serif&apos;] = &quot;SimHei&quot;\nmpl.rcParams[&apos;axes.unicode_minus&apos;] = False\n\n\ndef image2vector():\n    return np.array(Image.open(&quot;images/lena512.bmp&quot;, &quot;r&quot;).convert(&quot;L&quot;))\n\n\ndef equalization(data):\n    # 得到图像的高度、宽度\n    h = data.shape[0]\n    w = data.shape[1]\n    # 灰度数组\n    grayArr = np.zeros(255)\n    # 进行像素灰度统计\n    for i in range(h):\n        for j in range(w):\n            grayArr[data[i][j]] += 1\n    print grayArr.shape, grayArr.max()\n    # 归一化\n    idx = 0\n    for item in grayArr:\n        grayArr[idx] = item / (h * w)\n        idx += 1\n    # print grayArr\n    cdf = np.zeros(grayArr.shape)\n    sum = 0\n    # 计算灰度分布密度\n    # print cdf.shape\n    for i in range(len(grayArr)):\n        sum += grayArr[i]\n        cdf[i] = sum\n    L = 255\n    # print cdf\n    # 累计分布取整\n    indexArr = ((L - 1) * cdf + 0.5).astype(np.uint8)\n    # print indexArr\n    # 对灰度值进行映射（均衡化）\n    for i in range(h):\n        for j in range(w):\n            data[i, j] = indexArr[data[i, j]]\n    return grayArr, cdf, data\n\n\nif __name__ == &apos;__main__&apos;:\n    data = image2vector()\n    # print data.shape\n    plt.figure(figsize=(7, 9))\n    plt.subplot(321)\n    plt.title(u&quot;原始图像&quot;)\n    plt.imshow(data, cmap=&apos;gray&apos;)\n    plt.subplot(322)\n    plt.title(u&quot;原始灰度&quot;)\n    plt.hist(data.flatten(), normed=True, bins=256)\n    srcGray, cdf, equlArr = equalization(data)\n    plt.subplot(323)\n    plt.title(u&quot;归一化直方图&quot;)\n    plt.hist(srcGray, 255)\n    plt.subplot(324)\n    plt.title(u&quot;累积直方图&quot;)\n    plt.hist(cdf, 255)\n    plt.subplot(325)\n    plt.title(u&quot;均衡化图像&quot;)\n    plt.imshow(equlArr, cmap=&apos;gray&apos;)\n    plt.subplot(326)\n    plt.title(u&quot;均衡化的直方图&quot;)\n    plt.hist(equlArr.flatten(), normed=True, bins=256)\n    # print equlArr\n    plt.tight_layout(0.3, rect=(0, 0, 1, 0.92))\n    plt.show()\n</code></pre><ul>\n<li>4.实验结果<br><img src=\"https://raw.githubusercontent.com/Mic-JasonTang/Mic-Jasontang.github.io/master/css/images/histequa.png\" alt=\"实验结果\"></li>\n</ul>\n<ul>\n<li>5.实验总结<blockquote>\n<p>在对数据进行归一化的时候，是用每个灰度值除以像素总数。在最后通过映射关系计算均衡化直方图时，是借助求出的映射关系，直接对原图的像素点进行映射。通过均衡化能增强图像的动态范围偏小的图像的反差，达到增强图像整体对比度的效果。</p>\n</blockquote>\n</li>\n</ul>"}],"PostAsset":[],"PostCategory":[{"post_id":"cjezqafi10000f4htmvkkdxmr","category_id":"cjezqafid0004f4ht3mav2azz","_id":"cjezqafis000hf4htxzc7izmg"},{"post_id":"cjezqafi10000f4htmvkkdxmr","category_id":"cjezqafio000df4htku5c30eb","_id":"cjezqafiu000kf4htwujra7jx"},{"post_id":"cjezqafi90002f4ht0gv5hiu3","category_id":"cjezqafii0007f4ht7ewqga7t","_id":"cjezqafiv000lf4htz8f208pp"},{"post_id":"cjezqafi90002f4ht0gv5hiu3","category_id":"cjezqafir000ff4htthco9egz","_id":"cjezqafiw000nf4htf7t0c8g8"},{"post_id":"cjezqafig0006f4hticilr7fq","category_id":"cjezqafii0007f4ht7ewqga7t","_id":"cjezqafiw000of4ht66it5rqv"},{"post_id":"cjezqafig0006f4hticilr7fq","category_id":"cjezqafir000ff4htthco9egz","_id":"cjezqafix000qf4htql0drrif"}],"PostTag":[{"post_id":"cjezqafi10000f4htmvkkdxmr","tag_id":"cjezqafif0005f4ht6bbi2jdt","_id":"cjezqafin000bf4ht38gypp3g"},{"post_id":"cjezqafi10000f4htmvkkdxmr","tag_id":"cjezqafij0008f4ht6fc3pe5w","_id":"cjezqafio000cf4ht3xmk4iia"},{"post_id":"cjezqafi90002f4ht0gv5hiu3","tag_id":"cjezqafil000af4hted1be8ju","_id":"cjezqafiy000sf4htoq20uvbi"},{"post_id":"cjezqafi90002f4ht0gv5hiu3","tag_id":"cjezqafip000ef4ht2liek6s5","_id":"cjezqafiz000tf4htk11tdo4h"},{"post_id":"cjezqafi90002f4ht0gv5hiu3","tag_id":"cjezqafir000gf4hts80tqxvh","_id":"cjezqafj0000vf4httvg1n3kw"},{"post_id":"cjezqafi90002f4ht0gv5hiu3","tag_id":"cjezqafit000jf4htcd5jsbhg","_id":"cjezqafj0000wf4htbu962gll"},{"post_id":"cjezqafi90002f4ht0gv5hiu3","tag_id":"cjezqafiv000mf4htt71vuskn","_id":"cjezqafj1000yf4htmo0uhc8r"},{"post_id":"cjezqafi90002f4ht0gv5hiu3","tag_id":"cjezqafix000pf4htjs68vkis","_id":"cjezqafj1000zf4hthrdqsv42"},{"post_id":"cjezqafig0006f4hticilr7fq","tag_id":"cjezqafiy000rf4hthrbligka","_id":"cjezqafj20010f4ht8mkif46i"},{"post_id":"cjezqafig0006f4hticilr7fq","tag_id":"cjezqafil000af4hted1be8ju","_id":"cjezqafj20011f4htv95xw787"},{"post_id":"cjezqafig0006f4hticilr7fq","tag_id":"cjezqafj0000xf4ht4wg1fvfq","_id":"cjezqafj20012f4ht13mlahih"}],"Tag":[{"name":"Mnist","_id":"cjezqafif0005f4ht6bbi2jdt"},{"name":"tensorflow","_id":"cjezqafij0008f4ht6fc3pe5w"},{"name":"图像处理","_id":"cjezqafil000af4hted1be8ju"},{"name":"卷积运算","_id":"cjezqafip000ef4ht2liek6s5"},{"name":"guass","_id":"cjezqafir000gf4hts80tqxvh"},{"name":"soble","_id":"cjezqafit000jf4htcd5jsbhg"},{"name":"prewitt","_id":"cjezqafiv000mf4htt71vuskn"},{"name":"laplacian","_id":"cjezqafix000pf4htjs68vkis"},{"name":"python","_id":"cjezqafiy000rf4hthrbligka"},{"name":"直方图均衡化","_id":"cjezqafj0000xf4ht4wg1fvfq"}]}}